{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"y31_MBSNGmoj"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"A6Nvl3mfB6vz"},"source":["# Heart Rate Estimation using TAO HeartRateNet\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\"> "]},{"cell_type":"markdown","metadata":{"id":"eRpEExGlB6v1"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained model and train a model on the COHFACE dataset\n","* Run Inference on the trained model\n","* Export the retrained model to a .etlt file for deployment to DeepStream SDK\n","\n","### Table of Contents\n","\n","This notebook shows an example of non-invasive heart rate estimation using the Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1) <br>\n","    1.1 [Verify downloaded dataset](#head-1-1) <br>\n","    1.2 [Process the extracted data](#head-1-2) <br>\n","    1.3 [Download pre-trained model](#head-1-3) <br>\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>    \n","3. [Generate tfrecords from RGB videos](#head-3) <br>\n","    3.1 [Download haarcascade classifier](#head-3-1) <br>\n","    3.2 [Generate tfrecords](#head-3-2) <br>\n","4. [Provide training specification](#head-4) <br>\n","5. [Run TAO training](#head-5) <br>\n","6. [Evaluate the trained model](#head-6) <br>\n","7. [Inference](#head-7) <br>"]},{"cell_type":"markdown","metadata":{"id":"eWSYcxrjB6v2"},"source":["## 0. Set up env variables<a class=\"anchor\" id=\"head-0\"></a>\n","\n","When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n","\n","*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZa7WjI4B6v2"},"outputs":[],"source":["# Setting up env variables for cleaner command-line commands.\n","import os\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","%env EXPERIMENT_DIR=/results/heartratenet\n","%env DATA_DIR=/content/drive/MyDrive/heartratenet_data\n","%env SPECS_DIR=/content/drive/MyDrive/ColabNotebooks/tensorflow/heartratenet/specs\n","\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","!mkdir -p $EXPERIMENT_DIR/model/"]},{"cell_type":"markdown","metadata":{"id":"0ScnbOYsB6v4"},"source":["The heartratenet api uses the `$DATAIO_SPEC` and `$TRAIN_SPEC` yaml files to set up directories. \n","\n","* `$DATAIO_SPEC` is `$LOCAL_SPECS_DIR/heartratenet_data_generation.yaml`\n","* `$TRAIN_SPEC` is `$LOCAL_SPECS_DIR/heartratenet_tlt_pretrain.yaml`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hH_iDKSMB6v4"},"outputs":[],"source":["# Set up dataio and train experiment spec path and check if they exist\n","\n","os.environ[\"DATAIO_SPEC\"] = os.path.join(os.environ[\"SPECS_DIR\"], 'heartratenet_data_generation.yaml')\n","os.environ[\"TRAIN_SPEC\"] = os.path.join(os.environ[\"SPECS_DIR\"], 'heartratenet_tlt_pretrain.yaml')\n","\n","!if [ ! -f $DATAIO_SPEC ]; then echo \"Dataio spec file not found.\"; else echo \"Found dataio spec file.\";fi\n","!if [ ! -f $TRAIN_SPEC ]; then echo \"Train spec file not found.\"; else echo \"Found train spec file.\";fi"]},{"cell_type":"markdown","metadata":{"id":"KrJtHW3KB6v4"},"source":["Now, we have to make sure the environment paths selected above match the inputs to the api.\n","Go to `$DATAIO_SPEC` file and change `input_directory_path` and `data_directory_output_path` to the path specified in `$HEARTRATENET_DATA`.\n","Go to `$TRAIN_SPEC` file and change the `results_dir` to `$USER_EXPERIMENT_DIR` and also change the `checkpoint_dir` accordingly. This file is the input to the model. Next, change the `tfrecords_directory_path` to `$HEARTRATENET_DATA`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hh4WE31IB6v5"},"outputs":[],"source":["# Check to see if spec files are found and is updated.\n","try:\n","    from yaml import load, SafeLoader\n","    import os\n","    from os.path import normpath\n","    \n","    with open(os.environ.get(\"DATAIO_SPEC\")) as f:\n","        print('dataio spec found')\n","        dataio_args = load(f, Loader = SafeLoader)\n","    if normpath(dataio_args['input_directory_path'])!= normpath(os.environ.get(\"HEARTRATENET_DATA\")) or normpath(dataio_args['data_directory_output_path']) != normpath(os.environ.get(\"HEARTRATENET_DATA\")):\n","        print(normpath(dataio_args['input_directory_path']), os.environ.get(\"HEARTRATENET_DATA\") )\n","        print('Please update input_directory_path and data_directory_output_path')\n","except:\n","    print('Dataio spec is not found, please ensure there is dataio spec in proper folder')\n","    \n","try:\n","    from yaml import load\n","    import os\n","    from os.path import normpath, join\n","    \n","    with open(os.environ.get(\"TRAIN_SPEC\")) as f:\n","        print('train spec found')\n","        train_args = load(f, Loader=SafeLoader)\n","        \n","    if normpath(train_args['results_dir']) != normpath(os.environ.get(\"USER_EXPERIMENT_DIR\")):\n","        print('Please update results_dir')\n","        \n","    if normpath(train_args['dataloader']['dataset_info']['tfrecords_directory_path'])!= normpath(os.environ.get(\"HEARTRATENET_DATA\")):\n","        print('Please update the tfrecords_directory_path')\n","except:\n","    print('Train spec is not found, please ensure there is train spec in proper folder')"]},{"cell_type":"markdown","metadata":{"id":"EMsMLNpcB6v6"},"source":["## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"E3EtZPL0B6v6"},"source":["Please download COHFACE public dataset from the following website: https://www.idiap.ch/dataset/cohface\n","\n","After downloading the data, please extract the data to cohface folder and place it under `$LOCAL_DATA_DIR`."]},{"cell_type":"markdown","metadata":{"id":"e8XGtiWaB6v6"},"source":["### A. Verify downloaded dataset <a class=\"anchor\" id=\"head-1-1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8Tl-u68B6v6"},"outputs":[],"source":["# Check the dataset is present.\n","!mkdir -p $DATA_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gIiZ4U8iB6v7"},"outputs":[],"source":["!if [ ! -d $DATA_DIR/heartratenet/data ]; then echo \"Data folder not found, please download.\"; else echo \"Data folder found.\";fi"]},{"cell_type":"markdown","metadata":{"id":"GbWxQUDDB6v7"},"source":["### B. Process the extracted data <a class=\"anchor\" id=\"head-1-2\"></a>\n","\n","The `dataio` module for heartratenet expects the data to be formatted in a predefined format.\n","\n","The `dataio` spec file specifies the folders to be read in the three lists train_subjects, validation_subjects and test_subjects.\n","Place the video file under each subject in a folder named images. The path is `$LOCAL_DATA_DIR/subject_folder`.\n","\n","The ground truth is expected in the following format. For the RGB camera feed, `image_timestamps.csv` consists of frame ID and corresponding timestamp in rows `ID`,`Time`. For the pulse readings, `ground_truth.csv` consists of a timestamp and the corresponding ppg reading in rows `Time`,`PulseWaveform`. The heart rate is predicted as the dominant frequency of the ppg signal. The API takes care of sampling differences between the RGB and PPG signals. COHFACE dataset has 40 subjects, use `start_subject_id` and `end_subject_id` as input arguments to the following script to specify subjects to process, `process_cohface.py` process subjects in range `[start_subject_id, end_subject_id)`\n","\n","The following block will process the COHFACE dataset into a format consistent with heartratenet api."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eoZ1937mB6v7"},"outputs":[],"source":["%cd /content/drive/MyDrive/ColabNotebooks/tensorflow/heartratenet/\n","!python3.6 process_cohface.py -i $DATA_DIR/heartratenet/data/cohface/ \\\n","                           -o /content/cohface_processed \\\n","                           -start_subject_id 1 \\\n","                           -end_subject_id 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HG_DsKjYxjEa"},"outputs":[],"source":["#!mkdir -p /content/drive/MyDrive/heartratenet_data/cohface_processed/1/0\n","!mv /content/cohface_processed/1/0/* /content/drive/MyDrive/heartratenet_data/cohface_processed/1/0/"]},{"cell_type":"markdown","metadata":{"id":"OwCuvsVcB6v7"},"source":["### C. Download pre-trained model <a class=\"anchor\" id=\"head-1-3\"></a>\n","\n","Please follow the instructions in the following to download and verify the pretrained model for heartratenet.\n","\n","For HeartRateNet pretrained model please download model: `nvidia/tao/heartratenet:trainable_v2.0`.\n","\n","After download the pre-trained model, please place the files in `$LOCAL_EXPERIMENT_DIR/pretrain_models`\n","You will then have the following path\n","\n","* pretrained model in `$LOCAL_EXPERIMENT_DIR/pretrain_models/heartratenet_vtrainable_v2.0/model.tlt`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fnVw6__B6v7"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/content/\n","%env CLI=ngccli_cat_linux.zip\n","!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /content/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awMDfN02B6v8"},"outputs":[],"source":["# List models available in the model registry.\n","!ngc registry model list nvidia/tao/heartratenet:*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_0VEoGWqB6v8"},"outputs":[],"source":["# Create the target destination to download the model.\n","!mkdir -p $EXPERIMENT_DIR/pretrain_models/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmhoTfTOB6v8"},"outputs":[],"source":["# Download the pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/heartratenet:trainable_v2.0 \\\n","    --dest $EXPERIMENT_DIR/pretrain_models/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rkPRtyNWB6v8"},"outputs":[],"source":["!ls -rlt $EXPERIMENT_DIR/pretrain_models/heartratenet_vtrainable_v2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-14a2vmUB6v8"},"outputs":[],"source":["# Check the dataset is present\n","!if [ ! -f $EXPERIMENT_DIR/pretrain_models/heartratenet_vtrainable_v2.0/model.tlt ]; then echo 'Pretrain model file not found, please download.'; else echo 'Found Pretrain model file.';fi"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["!sh /content/drive/MyDrive/tf/setup_env.sh"]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","%env EXPERIMENT_DIR=/results/classification\n","%env DATA_DIR=/content/drive/MyDrive/tf_data/classification_data/\n","\n","# Set this path if you don't run the notebook from the samples directory.\n","# %env NOTEBOOK_ROOT=~/tao-samples/classification\n","\n","%env SPECS_DIR=/content/drive/MyDrive/ColabNotebooks/tensorflow/classification/specs\n","\n","# Showing list of specification files.\n","!ls -rlt $LOCAL_SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"lrQAguuFB6v9"},"source":["## 3. Generate tfrecords from RGB videos <a class=\"anchor\" id=\"head-3\"></a>\n","* Download haarcascade classifier and prepare directory\n","* Generate required motion and appearance maps for attention network.\n","* Create the tfrecords using the tao command"]},{"cell_type":"markdown","metadata":{"id":"mdpWERkcB6v9"},"source":["### A. Download haarcascade classifier <a class=\"anchor\" id=\"head-3-1\"></a>\n","Obtain the haarcascade classifer from (https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml)\n","\n","After downloading the haarcascade classifier, please place `haarcascade_frontalface_default.xml` in `$LOCAL_DATA_DIR`\n","\n","You will have the following path\n","\n","* haarcascade file in\n","`$LOCAL_DATA_DIR/haarcascade_frontalface_default.xml`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4rhbqdzB6v9"},"outputs":[],"source":["!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_frontalface_default.xml -P $DATA_DIR/"]},{"cell_type":"markdown","metadata":{"id":"qvrERzW6B6v-"},"source":["Note: Please make sure the file has been downloaded successfully, failure to do so will result in the rest of the notebook not being operational."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Puz8kfS1B6v-"},"outputs":[],"source":["# Check to see if haar classifier is present.\n","!if [ ! -f $DATA_DIR/haarcascade_frontalface_default.xml ]; then echo \"Classifier not found, please ensure classifier is in proper file\"; else echo \"Classifier found.\";fi"]},{"cell_type":"markdown","metadata":{"id":"wI9iWGqkB6v_"},"source":["### B. Generate tfrecords <a class=\"anchor\" id=\"head-3-2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3N2Zb3HryfI8"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/heartratenet_data/processed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"biC051h_B6v_"},"outputs":[],"source":["!tao heartratenet dataset_convert --experiment_spec_file $DATAIO_SPEC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u-Ip81RSB6wA"},"outputs":[],"source":["# Check to see if tfrecords are present.\n","!if [ ! -f $DATA_DIR/processed/train.tfrecord ]; then echo \"Did not find training file, please ensure training record is generated.\"; else echo \"Found training record\";fi\n","!if [ ! -f $DATA_DIR/processed/validation.tfrecord ]; then echo \"Did not find validation file, please ensure validation record is generated.\"; else echo \"Found validation record\";fi\n","!if [ ! -f $DATA_DIR/processed/test.tfrecord ]; then echo \"Did not find test file, please ensure test record is generated.\"; else echo \"Found test record\";fi"]},{"cell_type":"markdown","metadata":{"id":"QOiAfQbaB6wA"},"source":["## 4. Provide training specification <a class=\"anchor\" id=\"head-4\"></a>\n","* Tfrecords for the training dataset\n","    * In order to use the newly generated tfrecords for training, update the `tfrecords_directory_path` parameter of `dataset_info` section in the spec file at `$TRAIN_SPEC`\n","* Pre-trained model path\n","    * Update `checkpoint_dir` in the spec file `$TRAIN_SPEC`\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate, etc.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGv6oWuqB6wA"},"outputs":[],"source":["!cat $LOCAL_TRAIN_SPEC"]},{"cell_type":"markdown","metadata":{"id":"1GST0mPeB6wA"},"source":["## 5. Run TAO training <a class=\"anchor\" id=\"head-5\"></a>\n","* Provide the sample spec file and the output directory location for models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rE__5zz7B6wA"},"outputs":[],"source":["!tao heartratenet train -e $TRAIN_SPEC \\\n","                        -k $KEY \\\n","                        -r $EXPERIMENT_DIR/model"]},{"cell_type":"markdown","metadata":{"id":"nE_P1rSXB6wA"},"source":["## 6. Evaluate the trained model <a class=\"anchor\" id=\"head-6\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lBrRdC-qB6wB"},"outputs":[],"source":["!tao heartratenet evaluate -e $TRAIN_SPEC \\\n","                           -k $KEY \\\n","                           -m $EXPERIMENT_DIR/model/ \\\n","                           -r $EXPERIMENT_DIR/eval_results"]},{"cell_type":"markdown","metadata":{"id":"ctKp-FjsB6wB"},"source":["## 7. Inference <a class=\"anchor\" id=\"head-7\"></a>\n","* Ensure you have the required data format as indicated in the model card\n","* Modify `m` to the full model path for evaluation\n","* Modify `subject_infer_dir` and `subject` below to align with your data\n","* Modify `results_dir` to your desired result directory\n","* Modify `fps` to match inference data fps, COHFACE dataset recorded in 20fps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpVuZrr5B6wB"},"outputs":[],"source":["!tao heartratenet inference -m $EXPERIMENT_DIR/model/model.tlt \\\n","                            --subject_infer_dir $DATA_DIR \\\n","                            --subject cohface_processed/1/0 \\\n","                            --results_dir $EXPERIMENT_DIR \\\n","                            --fps 20 \\\n","                            -k $KEY \\\n","                            -c channels_first"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aoqKUHo5B6wC"},"outputs":[],"source":["import os\n","import cv2\n","import IPython.display\n","import PIL.Image\n","\n","subject_infer_dir = os.environ['LOCAL_DATA_DIR']\n","subject = 'Subject1'\n","display_freq = 30\n","results_file = os.path.join(os.environ['LOCAL_EXPERIMENT_DIR'], 'results.txt')\n","with open(results_file, 'r') as file:\n","    results = file.read()\n","\n","subject_work_dir = os.path.join(subject_infer_dir, subject, 'images')\n","cap = cv2.VideoCapture(os.path.join(subject_work_dir, '%04d.bmp'))\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if ret:\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        IPython.display.display(PIL.Image.fromarray(frame))\n","    else:\n","        break\n","print(results)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"heartratenet.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
