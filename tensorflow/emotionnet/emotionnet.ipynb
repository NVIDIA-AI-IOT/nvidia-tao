{"cells":[{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n","\n","1. Switch to CPU Instance for until Step 2 for non GPU dependent tasks\n","2. This increases your time available for the GPU dependent tasks on a Colab instance\n","2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"lc-7ea9ZZLhu"},"source":["# Emotion Classification using TAO EmotionNet\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\"> "]},{"cell_type":"markdown","metadata":{"id":"Rmgq_5X1ZLhy"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained model and train an EmotionNet model on subset of CK+ dataset\n","* Run Inference on the trained model\n","* Export the retrained model to a .etlt file for deployment for DeepStream SDK\n","\n","### Table of Contents\n","\n","This notebook shows an example of emotion classification in the Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1) <br>\n","    1.1 [Verify downloaded dataset](#head-1-1) <br>\n","    1.2 [Convert dataset labels to required json format](#head-1-2) <br>\n","    1.3 [Verify dataset conversion](#head-1-3) <br>\n","    1.4 [Download pre-trained model](#head-1-4) <br>\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>\n","3. [Generate tfrecords from labels in json format](#head-3)\n","4. [Provide training specification](#head-4)\n","5. [Run TAO training](#head-5)\n","6. [Evaluate trained models](#head-6)\n","7. [Run TAO inference](#head-7)\n"]},{"cell_type":"markdown","metadata":{"id":"e1hSLLpsZLhz"},"source":["## 0. Set up env variables and set FIXME parameters <a class=\"anchor\" id=\"head-0\"></a>\n","\n","*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*\n","\n","#### FIXME\n","1. NUM_GPUS - set this to <= number of GPU's availble on the instance\n","1. EXPERIMENT_DIR - set this path to a folder location where pretrained models, checkpoints and log files during different model actions will be saved\n","1. delete_existing_experiments - set to True to remove existing pretrained models, checkpoints and log files of a previous experiment\n","1. DATA_DIR - set this path to a folder location where you want to dataset to be present\n","1. delete_existing_data - set this to True to remove existing preprocessed and original data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1657249030914,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"u96r5OiXZLh0","outputId":"61c32126-2c0c-4508-89ec-34958dd2b9e9"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","#FIXME1\n","%env NUM_GPUS=1\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/ColabNotebooks\n","if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","    raise(\"Error, enter the path of the colab notebooks repo correctly\")\n","\n","#FIXME2\n","%env EXPERIMENT_DIR=/content/drive/MyDrive/results/emotionnet\n","#FIXME3\n","delete_existing_experiments = True\n","#FIXME4\n","%env DATA_DIR=/content/drive/MyDrive/emotionnet_data\n","#FIXME5\n","delete_existing_data = False\n","\n","if delete_existing_experiments:\n","    !rm -rf $EXPERIMENT_DIR\n","if delete_existing_data:\n","    !rm -rf $DATA_DIR\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/emotionnet/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","DATASET_SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/emotionnet/dataset_specs\"\n","%env DATASET_SPECS_DIR={DATASET_SPECS_DIR}\n","\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","!ls -rlt $DATASET_SPECS_DIR\n","\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"HyhTXR7cZLh4"},"source":["## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>\n","\n","Please download the CK+ dataset from: https://www.pitt.edu/~emotion/ck-spread.htm.\n","You will need to sign the dataset user agreement and send it to the email provided on the agreement sheet to get access to the dataset.\n","\n","After obtaining the dataset, please place the files in `$DATA_DIR`. Please rename the dataset folder to `ckplus` as `+` sign may not be a valid folder name.\n","You will then have the following path for the CK+ dataset.\n","* Input data in `$DATA_DIR/ckplus`\n","\n","You will then unzip the folder of ckplus dataset to the following folders.\n","* Image data: `$DATA_DIR/ckplus/cohn-kanade-images`\n","* Emotion label data: `$DATA_DIR/ckplus/Emotion`\n","* Landmarks label data: `$DATA_DIR/ckplus/Landmarks`\n","\n","Note: please make sure that the folder name are as listed above. "]},{"cell_type":"markdown","metadata":{"id":"_b6QlswTZLh4"},"source":["### A. Verify downloaded dataset <a class=\"anchor\" id=\"head-1-1\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1657248367742,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"MzbPgAQCZLh4","outputId":"fcd1c4b9-b17a-49b5-aa5e-5640d6928150"},"outputs":[],"source":["# Check the dataset is present\n","!if [ ! -d $DATA_DIR/ckplus/cohn-kanade-images ]; then echo 'Image Data folder not found, please download.'; else echo 'Found Image Data folder.';fi\n","!if [ ! -d $DATA_DIR/ckplus/Emotion ]; then echo 'Emotion labels folder not found, please download.'; else echo 'Found Emotion Labels folder.';fi\n","!if [ ! -d $DATA_DIR/ckplus/Landmarks ]; then echo 'Landmarks labels folder not found, please download.'; else echo 'Found Landmarks Labels folder.';fi"]},{"cell_type":"markdown","metadata":{"id":"5E19hhVDZLh5"},"source":["### B. Convert dataset labels to required json format <a class=\"anchor\" id=\"head-1-2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22500,"status":"ok","timestamp":1657253655884,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"da_9-gy7ZLh5","outputId":"134ca336-0968-4f37-f254-1d9892d5dc7d"},"outputs":[],"source":["!python3 $COLAB_NOTEBOOKS_PATH/tensorflow/emotionnet/ckplus_convert.py --root_path $DATA_DIR --dataset_folder_name ckplus --container_root_path $DATA_DIR"]},{"cell_type":"markdown","metadata":{"id":"jQ94X397ZLh5"},"source":["### C. Verify dataset conversion <a class=\"anchor\" id=\"head-1-3\"></a>\n","\n","Please use the provided conversion script `ckplus_convert.py` to convert existing `Landmarks` and `Emotion` labels from `CK+` dataset to the required json label format. \n","\n","Note: for other public datasets, please use this script as a reference to convert the labels to required format. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1657253661313,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"t-QzzYWMZLh6","outputId":"4a5b9fd9-ec4f-4564-c3d6-596c68ca86b6"},"outputs":[],"source":["# Sample json label.\n","!sed -n 1,201p $DATA_DIR/ckplus/data_factory/fiducial/S052_004_00000031_happy.json"]},{"cell_type":"markdown","metadata":{"id":"V7CXqJR5ZLh6"},"source":["### D. Download pre-trained model <a class=\"anchor\" id=\"head-1-4\"></a>\n","\n","Please follow the instructions in the following to download and verify the pretrain model for emotionnet.\n","\n","For EmotionNet pretrain model please download model: `nvidia/tao/emotionnet:trainable_v1.0`.\n","\n","After downloading the pre-trained model, please place the files in `$EXPERIMENT_DIR/pretrain_models`\n","You will then have the following path\n","\n","* pretrain model in `$EXPERIMENT_DIR/pretrain_models/emotionnet_vtrainable_v1.0/model.tlt`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGanviYZZLh6"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/ngc_content/\n","%env CLI=ngccli_cat_linux.zip\n","!sudo mkdir -p $LOCAL_PROJECT_DIR/ngccli && sudo chmod -R 777 $LOCAL_PROJECT_DIR\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4277,"status":"ok","timestamp":1657251346111,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"o-PwIPdGZLh7","outputId":"174b2ce7-67b6-4904-d624-b608de77a89a"},"outputs":[],"source":["# List models available in the model registry.\n","!ngc registry model list nvidia/tao/emotionnet:*"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":747,"status":"ok","timestamp":1657251346856,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"t7zy0WvmZLh7"},"outputs":[],"source":["# Create the target destination to download the model.\n","!mkdir -p $EXPERIMENT_DIR/pretrain_models/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10076,"status":"ok","timestamp":1657251356930,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"HBaKtvAaZLh8","outputId":"a0ff1469-07de-4e61-9f2a-5b858fc45d6c"},"outputs":[],"source":["# Download the pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/emotionnet:trainable_v1.0 \\\n","    --dest $EXPERIMENT_DIR/pretrain_models/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1657251356931,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"brxuNXNuZLh8","outputId":"a8091759-ce31-4469-ca8b-cd50b2b112d4"},"outputs":[],"source":["!ls -rlt $EXPERIMENT_DIR/pretrain_models/emotionnet_vtrainable_v1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657251356931,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Yo7yivuiZLh8","outputId":"87ec21cb-8680-49b0-b315-3ffd0530d580"},"outputs":[],"source":["# Check the dataset is present\n","!if [ ! -f $EXPERIMENT_DIR/pretrain_models/emotionnet_vtrainable_v1.0/model.tlt ]; then echo 'Pretrain model file not found, please download.'; else echo 'Found Pretrain model file.';fi"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["#FIXME\n","%env GENERAL_WHL_PATH=/content/drive/MyDrive/tf/general_whl\n","#FIXME\n","%env CODEBASE_WHL_PATH=/content/drive/MyDrive/tf/codebase_whl\n","\n","import os\n","if os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]) and os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]):\n","    if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","        os.environ[\"bash_script\"] = \"setup_env.sh\"\n","    else:\n","        os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","    !sed -i \"s|PATH_TO_GENERAL_WHL|$GENERAL_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","    !sed -i \"s|PATH_TO_CODEBASE_WHL|$CODEBASE_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","    !sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","\n","    !sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","else:\n","    raise(\"Error, enter the whl paths correctly\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if os.environ.get(\"PYTHONPATH\",\"\") == \"\":\n","    os.environ[\"PYTHONPATH\"] = \"\"\n","os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\"\n","else:\n","    os.environ[\"PYTHONPATH\"]+=\":/home_duplicate/rarunachalam/miniconda3/envs/tf_py_36/lib/python3.6/site-packages/third_party/nvml\" # FIX MINICONDA PATH"]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/ColabNotebooks\n","if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","    raise(\"Error, enter the path of the colab notebooks repo correctly\")\n","%env EXPERIMENT_DIR=/content/drive/MyDrive/results/emotionnet\n","%env DATA_DIR=/content/drive/MyDrive/emotionnet_data\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/emotionnet/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","DATASET_SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/emotionnet/dataset_specs\"\n","%env DATASET_SPECS_DIR={DATASET_SPECS_DIR}\n","\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","!ls -rlt $DATASET_SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"EIuyvHk7ZLh8"},"source":["## 3. Generate tfrecords from labels in json format <a class=\"anchor\" id=\"head-3\"></a>\n","* Create the tfrecords using the dataset_convert command\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1657253782422,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"AVeyhI5aBXzV","outputId":"143a37eb-7993-48c2-e947-4f734f807ad1"},"outputs":[],"source":["!rm -rf $DATA_DIR/post_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14039,"status":"ok","timestamp":1657253827408,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"czcEhEyGZLh8","outputId":"ad5f9438-06ab-4b12-814c-6b8ab82d7ba3","scrolled":true},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $DATASET_SPECS_DIR/dataio_config_ckplus.json\n","!tao emotionnet dataset_convert -c $DATASET_SPECS_DIR/dataio_config_ckplus.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1657253391386,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"kNYdkDRc_0KV","outputId":"10b7702e-49cc-4126-c5e9-deccf59a2d1a"},"outputs":[],"source":["!ls $DATA_DIR/ckplus/data_factory/fiducial/* | wc -l"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1657252204310,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"YRAbUJlRZLh9","outputId":"c31f7569-4010-4e42-be2a-5b92f51bff77"},"outputs":[],"source":["# Check the result folder is present\n","!mkdir -p $EXPERIMENT_DIR\n","!if [ ! -d $DATA_DIR/post_data/ckplus/Ground_Truth_DataFactory ]; then echo 'Ground truth folder not found.'; else echo 'Found Ground truth folder.';fi\n","!if [ ! -d $DATA_DIR/post_data/ckplus/GT_user_json ]; then echo 'GT user json folder not found.'; else echo 'Found GT user json folder.';fi"]},{"cell_type":"markdown","metadata":{"id":"YyrwV_2jZLh9"},"source":["## 4. Provide training specification <a class=\"anchor\" id=\"head-4\"></a>\n","* Tfrecords for the train datasets\n","    * In order to use the newly generated tfrecords for training, update the 'ground_truth_folder_name' and 'tfrecords_directory_path' parameters of 'dataset_info' section in the spec file at `$SPECS_DIR/emotionnet_tlt_pretrain.yaml`\n","* Pre-trained model path\n","    * Update \"pretrained_model_path\" in the spec file at `$SPECS_DIR/emotionnet_tlt_pretrain.yaml`\n","    * If you want to training from random weights with your own data, you can enter \"null\" for \"pretrained_model_path\" section\n","* Augmentation parameters for on the fly data augmentation\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oY9TfNvsZLh9"},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/emotionnet_tlt_pretrain.yaml\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/emotionnet_tlt_pretrain.yaml\n","!cat $SPECS_DIR/emotionnet_tlt_pretrain.yaml"]},{"cell_type":"markdown","metadata":{"id":"FiE9_6q5ZLh9"},"source":["## 5. Run TAO training <a class=\"anchor\" id=\"head-5\"></a>\n","* Provide the sample spec file and the output directory location for models\n","\n","*Note: The training may take hours to complete. Also, the remaining notebook, assumes that the training was done in single-GPU mode. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64621,"status":"ok","timestamp":1657253908139,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"F8HA0QlrZLh-","outputId":"2c93d8cd-bb8e-4972-822c-c20d8d7642e0"},"outputs":[],"source":["!tao emotionnet train -e $SPECS_DIR/emotionnet_tlt_pretrain.yaml \\\n","                      -r $EXPERIMENT_DIR/experiment_result/exp1 \\\n","                      -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1657253948289,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"S_jeOaxbZLh-","outputId":"9fc7085c-32de-4a65-cf9a-70036d6bad3a"},"outputs":[],"source":["!ls -lh $EXPERIMENT_DIR/experiment_result"]},{"cell_type":"markdown","metadata":{"id":"kLLoztJWZLh_"},"source":["## 6. Evaluate the trained model <a class=\"anchor\" id=\"head-6\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8819,"status":"ok","timestamp":1657254020762,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Dm_Cl3XoZLh_","outputId":"3e88e77b-9e86-4723-e1ac-8675af2326d2"},"outputs":[],"source":["!tao emotionnet evaluate -m $EXPERIMENT_DIR/experiment_result/exp1/model.tlt \\\n","                         -r $EXPERIMENT_DIR/experiment_result/exp1 \\\n","                         -e $SPECS_DIR/emotionnet_tlt_pretrain.yaml \\\n","                         -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657254039922,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"aas7DYaOZLiA","outputId":"ac67b73d-f136-4b1b-e045-b3a03ffa32d1"},"outputs":[],"source":["# check the Evaluation result file and summary file and is presented\n","!if [ ! -f $EXPERIMENT_DIR/experiment_result/exp1/eval_results.txt ]; then echo 'Evaluation result summary file not found, please generate.'; else echo 'Found Evaluation result summary file.';fi\n","!if [ ! -f $EXPERIMENT_DIR/experiment_result/exp1/full_results.txt ]; then echo 'Evaluation result file not found, please generate.'; else echo 'Found Evaluation result file.';fi\n","!cat  $EXPERIMENT_DIR/experiment_result/exp1/eval_results.txt"]},{"cell_type":"markdown","metadata":{"id":"7pB3B4y1ZLiA"},"source":["## 7. Visualize Inference <a class=\"anchor\" id=\"head-7\"></a>\n","\n","In this section, we run the inference tool to generate inferences on the trained models."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8992,"status":"ok","timestamp":1657254094799,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"ey3fwQCWZLiA","outputId":"1166c8b9-d348-4633-cbd2-966a8a9c679b"},"outputs":[],"source":["# Running inference for detection on n images\n","!tao emotionnet inference -e $SPECS_DIR/emotionnet_tlt_pretrain.yaml \\\n","                          -i $DATA_DIR/ckplus/data_factory/fiducial/S111_001_00000013_surprise.json \\\n","                          -m $EXPERIMENT_DIR/experiment_result/exp1/model.tlt \\\n","                          -o $EXPERIMENT_DIR \\\n","                          -k $KEY "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1657254166107,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"bCGtfPszZLiB","outputId":"be343e39-0372-4bf4-b9ea-3f1dbcfb1288"},"outputs":[],"source":["!sed -n 1,1p $EXPERIMENT_DIR/result.txt"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"emotionnet.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
