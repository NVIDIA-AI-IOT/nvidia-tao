{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"bvQMbSvU3PpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sudo apt update && sudo apt upgrade && sudo apt-get install libcudnn8 libcudnn8-dev libnccl-dev libnccl2 --allow-change-held-packages && sudo apt dist-upgrade\n","!sudo apt autoremove\n","!sudo apt install update-manager-core\n","!sudo ln -sf /usr/bin/python3.6 /usr/bin/python3\n","!export DEBIAN_FRONTEND=noninteractive # or sudo apt-get install dialog && sudo apt-get install whiptail\n","!sudo do-release-upgrade -f DistUpgradeViewNonInteractive"],"metadata":{"id":"cg6d59br3PnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!sudo add-apt-repository ppa:deadsnakes/ppa -y\n","!sudo apt-get update\n","!sudo apt-get install python3.6 -y\n","!apt install python3-pip -y\n","!apt-get install python3.6-distutils\n","!apt-get install python3.6-dev"],"metadata":{"id":"n3Y8lo3y3Plr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm /usr/bin/python\n","!ln -sf /usr/bin/python3.6 /usr/local/bin/python"],"metadata":{"id":"faH72FxI3Pks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n","!sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n","!wget https://developer.download.nvidia.com/compute/cuda/11.2.2/local_installers/cuda-repo-ubuntu2004-11-2-local_11.2.2-460.32.03-1_amd64.deb\n","!sudo dpkg -i cuda-repo-ubuntu2004-11-2-local_11.2.2-460.32.03-1_amd64.deb\n","!sudo apt-key add /var/cuda-repo-ubuntu2004-11-2-local/7fa2af80.pub\n","!sudo apt-key add /var/cuda-repo-ubuntu2004-11-2-local/3bf863cc.pub\n","!sudo apt-get update\n","!sudo apt-get -y install cuda-11.2"],"metadata":{"id":"ctfA2gQ63Pi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /tmp\n","!wget https://github.com/Kitware/CMake/releases/download/v3.14.4/cmake-3.14.4-Linux-x86_64.sh\n","!chmod +x cmake-3.14.4-Linux-x86_64.sh\n","!./cmake-3.14.4-Linux-x86_64.sh --prefix=/usr/local --exclude-subdir --skip-license\n","!rm ./cmake-3.14.4-Linux-x86_64.sh"],"metadata":{"id":"1XovBdsT3Phx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3.6 -m pip install nvidia-pyindex"],"metadata":{"id":"T0QZGGPM3Pgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3.6 -m pip install  /content/drive/MyDrive/tf/general_whl/*.whl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhwywoJy3Pe-","executionInfo":{"status":"ok","timestamp":1657262112411,"user_tz":420,"elapsed":89743,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"}},"outputId":"9fff81c5-749c-414f-b819-ce284dcc10c2"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://pypi.ngc.nvidia.com\n","Processing ./drive/MyDrive/tf/general_whl/unnecess/tensorflow-1.15.5+nv-cp36-cp36m-linux_x86_64.whl\n","Collecting gast==0.3.3\n","  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Collecting astunparse==1.6.3\n","  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting keras-applications>=1.0.8\n","  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","Collecting opt-einsum>=2.3.2\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting protobuf>=3.6.1\n","  Using cached protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n","Collecting tensorflow-estimator==1.15.1\n","  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n","Collecting astor==0.8.1\n","  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Collecting google-pasta>=0.1.6\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Processing /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc/termcolor-1.1.0-py3-none-any.whl\n","Collecting six>=1.10.0\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting h5py<=2.10.0\n","  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n","Collecting numpy<1.19.0,>=1.16.0\n","  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 26 kB/s \n","\u001b[?25hCollecting grpcio>=1.8.6\n","  Using cached grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","Collecting wheel>=0.26; python_version >= \"3\"\n","  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n","Collecting keras-preprocessing>=1.0.5\n","  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","Collecting wrapt>=1.11.1\n","  Using cached wrapt-1.14.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (74 kB)\n","Collecting absl-py>=0.9.0\n","  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n","Collecting werkzeug>=0.11.15\n","  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n","Collecting setuptools>=41.0.0\n","  Downloading setuptools-59.6.0-py3-none-any.whl (952 kB)\n","\u001b[K     |████████████████████████████████| 952 kB 71.3 MB/s \n","\u001b[?25hCollecting markdown>=2.6.8\n","  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n","Collecting dataclasses; python_version < \"3.7\"\n","  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n","Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n","  Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n","Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n","  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n","Collecting zipp>=0.5\n","  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n","\u001b[31mERROR: tf2onnx 1.9.2 has requirement flatbuffers~=1.12, but you'll have flatbuffers 2.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: nbconvert 6.0.7 has requirement pygments>=2.4.1, but you'll have pygments 2.3.1 which is incompatible.\u001b[0m\n","Installing collected packages: gast, six, wheel, astunparse, numpy, h5py, keras-applications, opt-einsum, protobuf, dataclasses, werkzeug, absl-py, setuptools, typing-extensions, zipp, importlib-metadata, markdown, grpcio, tensorboard, tensorflow-estimator, astor, google-pasta, termcolor, keras-preprocessing, wrapt, tensorflow\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Attempting uninstall: six\n","    Found existing installation: six 1.13.0\n","    Uninstalling six-1.13.0:\n","      Successfully uninstalled six-1.13.0\n","  Attempting uninstall: wheel\n","    Found existing installation: wheel 0.34.2\n","    Not uninstalling wheel at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'wheel'. No files were found to uninstall.\n","  Attempting uninstall: astunparse\n","    Found existing installation: astunparse 1.6.3\n","    Uninstalling astunparse-1.6.3:\n","      Successfully uninstalled astunparse-1.6.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.4\n","    Uninstalling numpy-1.19.4:\n","      Successfully uninstalled numpy-1.19.4\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Attempting uninstall: keras-applications\n","    Found existing installation: Keras-Applications 1.0.8\n","    Uninstalling Keras-Applications-1.0.8:\n","      Successfully uninstalled Keras-Applications-1.0.8\n","  Attempting uninstall: opt-einsum\n","    Found existing installation: opt-einsum 3.3.0\n","    Uninstalling opt-einsum-3.3.0:\n","      Successfully uninstalled opt-einsum-3.3.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.19.4\n","    Uninstalling protobuf-3.19.4:\n","      Successfully uninstalled protobuf-3.19.4\n","  Attempting uninstall: dataclasses\n","    Found existing installation: dataclasses 0.8\n","    Uninstalling dataclasses-0.8:\n","      Successfully uninstalled dataclasses-0.8\n","  Attempting uninstall: werkzeug\n","    Found existing installation: Werkzeug 2.0.3\n","    Uninstalling Werkzeug-2.0.3:\n","      Successfully uninstalled Werkzeug-2.0.3\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.1.0\n","    Uninstalling absl-py-1.1.0:\n","      Successfully uninstalled absl-py-1.1.0\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 45.2.0\n","    Not uninstalling setuptools at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'setuptools'. No files were found to uninstall.\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: zipp\n","    Found existing installation: zipp 3.6.0\n","    Uninstalling zipp-3.6.0:\n","      Successfully uninstalled zipp-3.6.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.8.3\n","    Uninstalling importlib-metadata-4.8.3:\n","      Successfully uninstalled importlib-metadata-4.8.3\n","  Attempting uninstall: markdown\n","    Found existing installation: Markdown 3.3.7\n","    Uninstalling Markdown-3.3.7:\n","      Successfully uninstalled Markdown-3.3.7\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.26.0\n","    Uninstalling grpcio-1.26.0:\n","      Successfully uninstalled grpcio-1.26.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Attempting uninstall: astor\n","    Found existing installation: astor 0.8.1\n","    Uninstalling astor-0.8.1:\n","      Successfully uninstalled astor-0.8.1\n","  Attempting uninstall: google-pasta\n","    Found existing installation: google-pasta 0.2.0\n","    Uninstalling google-pasta-0.2.0:\n","      Successfully uninstalled google-pasta-0.2.0\n","  Attempting uninstall: termcolor\n","    Found existing installation: termcolor 1.1.0\n","    Uninstalling termcolor-1.1.0:\n","      Successfully uninstalled termcolor-1.1.0\n","  Attempting uninstall: keras-preprocessing\n","    Found existing installation: Keras-Preprocessing 1.1.2\n","    Uninstalling Keras-Preprocessing-1.1.2:\n","      Successfully uninstalled Keras-Preprocessing-1.1.2\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.1\n","    Uninstalling wrapt-1.14.1:\n","      Successfully uninstalled wrapt-1.14.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 1.15.5+nv\n","    Uninstalling tensorflow-1.15.5+nv:\n","      Successfully uninstalled tensorflow-1.15.5+nv\n","Successfully installed absl-py-1.1.0 astor-0.8.1 astunparse-1.6.3 dataclasses-0.8 gast-0.3.3 google-pasta-0.2.0 grpcio-1.47.0 h5py-2.10.0 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 numpy-1.18.5 opt-einsum-3.3.0 protobuf-3.19.4 setuptools-59.6.0 six-1.16.0 tensorboard-1.15.0 tensorflow-1.15.5+nv tensorflow-estimator-1.15.1 termcolor-1.1.0 typing-extensions-4.1.1 werkzeug-2.0.3 wheel-0.37.1 wrapt-1.14.1 zipp-3.6.0\n"]}]},{"cell_type":"code","source":["!python3.6 -m pip install -r /content/drive/MyDrive/tf/requirements-pip-lean.txt -f https://download.pytorch.org/whl/torch_stable.html --extra-index-url https://developer.download.nvidia.com/compute/redist"],"metadata":{"id":"g8Qo72hj3PdL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir -p /opt/nvidia/third_party\n","!cp -r /content/drive/MyDrive/tf/nvml  /opt/nvidia/third_party/\n","!cp -r /content/drive/MyDrive/tf/keras  /opt/nvidia/third_party/\n","!cp -r /content/drive/MyDrive/tf/numba  /opt/nvidia/third_party/"],"metadata":{"id":"9ugHh2pS3Pbp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /opt/nvidia\n","!touch third_party/__init__.py\n","!touch third_party/keras/__init__.py\n","!patch -run -d /usr/local/lib/python3.6/dist-packages/numba < /opt/nvidia/third_party/numba/monkey.patch"],"metadata":{"id":"HZhSOOMN3PLE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3.6 -m pip install --force-reinstall /content/drive/MyDrive/tf/codebase_whl/*.whl"],"metadata":{"id":"LOP6SbZC3PIH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","!echo $PYTHONPATH\n","os.environ['PYTHONPATH']+=':/opt/nvidia/'\n","os.environ['PYTHONPATH']+=':/opt/nvidia/third_party/nvml'\n","!echo $PYTHONPATH"],"metadata":{"id":"f-VtrjjU3PFU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!patch -run -d /usr/local/lib/python3.6/dist-packages/keras < /opt/nvidia/third_party/keras/monkey.patch"],"metadata":{"id":"ifcuiCZ13PCt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQRtc32S3NCU"},"source":["# Object Detection using TAO FasterRCNN\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\"> "]},{"cell_type":"markdown","metadata":{"id":"bxc-enFe3NCY"},"source":[" ## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained resnet18 model and train a ResNet-18 FasterRCNN model on the KITTI dataset\n","* Prune the trained FasterRCNN model\n","* Retrain the pruned model to recover lost accuracy\n","* Run evaluation & inference on the trained model to verify the accuracy\n","* Export & deploy the model in DeepStream/TensorRT\n","* Quantization-Aware Training(QAT) workflow for the best accuracy-performance trade-off\n"," \n"," ### Table of Contents\n","\n"," This notebook shows an example use case of FasterRCNN using Train Adapt Optimize (TAO) Toolkit.\n","\n"," 0. [Set up env variables and map drives](#head-0)\n"," 1. [Install the TAO launcher](#head-1)\n"," 2. [Prepare dataset and pretrained model](#head-2)<br>\n","     2.1 [Download the dataset](#head-2-1)<br>\n","     2.2 [Verify the downloaded dataset](#head-2-2)<br>\n","     2.3 [Prepare tfrecords from kitti format dataset](#head-2-3)<br>\n","     2.4 [Download pretrained model](#head-2-4)\n"," 3. [Provide training specification](#head-3)\n"," 4. [Run TAO training](#head-4)\n"," 5. [Evaluate trained models](#head-5)\n"," 6. [Prune trained models](#head-6)\n"," 7. [Retrain pruned models](#head-7)\n"," 8. [Evaluate retrained model](#head-8)\n"," 9. [Visualize inferences](#head-9)\n"," 10. [Deploy](#head-10)\n"," 11. [QAT workflow](#head-11)<br>\n","     11.1 [Training](#head-11.1)<br>\n","     11.2 [Evaluation](#head-11.2)<br>\n","     11.3 [Pruning](#head-11.3)<br>\n","     11.4 [Retraining](#head-11.4)<br>\n","     11.5 [Evaluation of the retrained model](#head-11.5)<br>\n","     11.6 [Inference of the retrained model](#head-11.6)<br>\n","     11.7 [Deployment of the QAT model](#head-11.7)"]},{"cell_type":"markdown","metadata":{"id":"_XuMm5Pl3NCZ"},"source":[" ## 0. Set up env variables and map drives <a class=\"anchor\" id=\"head-0\"></a>\n"," \n","The following notebook requires the user to set an env variable called the `$LOCAL_PROJECT_DIR` as the path to the users workspace. More information on how to set up the dataset and the supported steps in the TAO workflow are provided in the subsequent cells."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaE4jyb63NCa"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","print(\"Please replace the variables with your own.\")\n","%env GPU_INDEX=0\n","%env KEY=tlt\n","%env EXPERIMENT_DIR=/results/faster_rcnn\n","%env DATA_DIR=/content/drive/MyDrive/pointpillars_data\n","%env SPECS_DIR=/content/drive/MyDrive/ColabNotebooks/tensorflow/faster_rcnn/specs\n","\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35dFFXXD3NCb"},"outputs":[],"source":["# Create local dir\n","!mkdir -p $DATA_DIR\n","!mkdir -p $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"okOkNPDQ3NCe"},"source":[" ## 2. Prepare dataset and pretrained model <a class=\"anchor\" id=\"head-2\"></a>"]},{"cell_type":"markdown","metadata":{"id":"8x-caoOC3NCe"},"source":[" We will be using the KITTI detection dataset for the tutorial. To find more details please visit\n"," http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d. Please download the KITTI detection images (http://www.cvlibs.net/download.php?file=data_object_image_2.zip) and labels (http://www.cvlibs.net/download.php?file=data_object_label_2.zip) to $DATA_DOWNLOAD_DIR.\n"," \n"," The data will then be extracted to have\n"," * training images in `$LOCAL_DATA_DIR/training/image_2`\n"," * training labels in `$LOCAL_DATA_DIR/training/label_2`\n"," * testing images in `$LOCAL_DATA_DIR/testing/image_2`\n"," \n","You may use this notebook with your own dataset as well. To use this example with your own dataset, please follow the same directory structure as mentioned below.\n","\n","*Note: There are no labels for the testing images, therefore we use it just to visualize inferences for the trained model.*"]},{"cell_type":"markdown","metadata":{"id":"8o588Z963NCe"},"source":["### 2.1 Download the dataset <a class=\"anchor\" id=\"head-2-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"x0_dR5AV3NCe"},"source":["Once you have gotten the download links in your email, please populate them in place of the `KITTI_IMAGES_DOWNLOAD_URL` and the `KITTI_LABELS_DOWNLOAD_URL`. This next cell, will download the data and place in `$LOCAL_DATA_DIR`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iA12qwvy3NCf"},"outputs":[],"source":["import os\n","!mkdir -p $DATA_DIR\n","os.environ[\"URL_IMAGES\"]=KITTI_IMAGES_DOWNLOAD_URL\n","!if [ ! -f $DATA_DIR/data_object_image_2.zip ]; then wget $URL_IMAGES -O $DATA_DIR/data_object_image_2.zip; else echo \"image archive already downloaded\"; fi \n","os.environ[\"URL_LABELS\"]=KITTI_LABELS_DOWNLOAD_URL\n","!if [ ! -f $DATA_DIR/data_object_label_2.zip ]; then wget $URL_LABELS -O $DATA_DIR/data_object_label_2.zip; else echo \"label archive already downloaded\"; fi "]},{"cell_type":"markdown","metadata":{"id":"M7IZ4MTi3NCf"},"source":["### 2.2 Verify the downloaded dataset <a class=\"anchor\" id=\"head-2-2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xiIZzLGf3NCf"},"outputs":[],"source":["# Check the dataset is present\n","!mkdir -p $DATA_DIR\n","!if [ ! -f $DATA_DIR/data_object_image_2.zip ]; then echo 'Image zip file not found, please download.'; else echo 'Found Image zip file.';fi\n","!if [ ! -f $DATA_DIR/data_object_label_2.zip ]; then echo 'Label zip file not found, please download.'; else echo 'Found Labels zip file.';fi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LIB6-sYe3NCg"},"outputs":[],"source":["# This may take a while: verify integrity of zip files \n","!sha256sum $DATA_DIR/data_object_image_2.zip | cut -d ' ' -f 1 | grep -xq '^351c5a2aa0cd9238b50174a3a62b846bc5855da256b82a196431d60ff8d43617$' ; \\\n","if test $? -eq 0; then echo \"images OK\"; else echo \"images corrupt, re-download!\" && rm -f $DATA_DIR/data_object_image_2.zip; fi \n","!sha256sum $DATA_DIR/data_object_label_2.zip | cut -d ' ' -f 1 | grep -xq '^4efc76220d867e1c31bb980bbf8cbc02599f02a9cb4350effa98dbb04aaed880$' ; \\\n","if test $? -eq 0; then echo \"labels OK\"; else echo \"labels corrupt, re-download!\" && rm -f $DATA_DIR/data_object_label_2.zip; fi "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mVlIz4NY3NCg"},"outputs":[],"source":["# unpack \n","!unzip -u $DATA_DIR/data_object_image_2.zip -d $DATA_DIR\n","!unzip -u $DATA_DIR/data_object_label_2.zip -d $DATA_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4irryJ133NCg"},"outputs":[],"source":["# verify\n","import os\n","\n","DATA_DIR = os.environ.get('DATA_DIR')\n","num_training_images = len(os.listdir(os.path.join(DATA_DIR, \"training/image_2\")))\n","num_training_labels = len(os.listdir(os.path.join(DATA_DIR, \"training/label_2\")))\n","num_testing_images = len(os.listdir(os.path.join(DATA_DIR, \"testing/image_2\")))\n","print(\"Number of images in the train/val set. {}\".format(num_training_images))\n","print(\"Number of labels in the train/val set. {}\".format(num_training_labels))\n","print(\"Number of images in the test set. {}\".format(num_testing_images))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8JXbe2wE3NCh"},"outputs":[],"source":["# Sample kitti label.\n","!cat $LOCAL_DATA_DIR/training/label_2/000110.txt"]},{"cell_type":"markdown","metadata":{"id":"2fKkMmHP3NCh"},"source":["### 2.3 Prepare tfrecords from kitti format dataset <a class=\"anchor\" id=\"head-2-3\"></a>\n","\n","* Update the tfrecords spec file to take in your kitti format dataset\n","* Create the tfrecords using the dataset_convert \n","* TFRecords only need to be generated once."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6knRqc5s3NCh"},"outputs":[],"source":["print(\"TFrecords conversion spec file for training\")\n","!cat $SPECS_DIR/frcnn_tfrecords_kitti_trainval.txt"]},{"cell_type":"code","source":["!python3.6 -m pip install uff"],"metadata":{"id":"1I2RIxzxezp3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQPfvUYI3NCh"},"outputs":[],"source":["# Creating a new directory for the output tfrecords dump.\n","!mkdir -p $DATA_DIR/tfrecords/kitti_trainval && rm -rf $DATA_DIR/tfrecords/kitti_trainval/*\n","#KITTI trainval\n","!faster_rcnn dataset_convert --gpu_index $GPU_INDEX -d $SPECS_DIR/frcnn_tfrecords_kitti_trainval.txt \\\n","                     -o $DATA_DIR/tfrecords/kitti_trainval/kitti_trainval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tHB7kq9S3NCh"},"outputs":[],"source":["!ls -rlt $DATA_DIR/tfrecords/kitti_trainval"]},{"cell_type":"markdown","metadata":{"id":"t5PPoZMa3NCi"},"source":[" ### 2.4 Download pre-trained model <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"umNlqIZJ3NCi"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%cd /content\n","!wget --content-disposition https://ngc.nvidia.com/downloads/ngccli_linux.zip && unzip ngccli_linux.zip && chmod u+x ngc-cli/ngc\n","os.environ[\"PATH\"] += \":/content/ngc-cli/\"\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 /content/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptqEzLk73NCi"},"outputs":[],"source":["!ngc registry model list nvidia/tao/pretrained_object_detection*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MWqFIlzz3NCi"},"outputs":[],"source":["# Download model from NGC.\n","!ngc registry model download-version nvidia/tao/pretrained_object_detection:resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"kMBFpTgq3NCi"},"outputs":[],"source":["# Copy weights to experiment directory.\n","!cp pretrained_object_detection_vresnet18/resnet_18.hdf5 $EXPERIMENT_DIR\n","!rm -rf pretrained_object_detection_vresnet18\n","!ls -rlt $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"s_gwvKUw3NCj"},"source":[" ## 3. Provide training specification <a class=\"anchor\" id=\"head-3\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LKL7rbUS3NCj"},"outputs":[],"source":["!sed -i 's/$KEY/'\"$KEY/g\" $SPECS_DIR/default_spec_resnet18.txt\n","!cat $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"markdown","metadata":{"id":"KYSOvnKE3NCk"},"source":[" ## 4. Run TAO training <a class=\"anchor\" id=\"head-4\"></a>\n"," * Provide the sample spec file for training."]},{"cell_type":"code","execution_count":36,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"eX_a-9Zy3NCk","executionInfo":{"status":"ok","timestamp":1657262132393,"user_tz":420,"elapsed":19991,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"}},"outputId":"c28cb0a1-83c0-4f6e-8346-6aac8cfee173"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-07-08 06:35:12.594633: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-07-08 06:35:12,639 [WARNING] tensorflow: Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n","Using TensorFlow backend.\n","2022-07-08 06:35:16,550 [WARNING] iva.faster_rcnn.scripts.evaluate: Failed to import TRT and/or CUDA. TensorRT optimization, export and inference will not be available.\n","2022-07-08 06:35:16,880 [WARNING] iva.faster_rcnn.scripts.export: Failed to import TRT and/or CUDA. TensorRT optimization, export and inference will not be available.\n","2022-07-08 06:35:16,881 [WARNING] iva.faster_rcnn.scripts.inference: Failed to import TRT and/or CUDA. TensorRT optimization, export and inference will not be available.\n","2022-07-08 06:35:17.309909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n","Using TensorFlow backend.\n","2022-07-08 06:35:20,223 [INFO] iva.faster_rcnn.spec_loader.spec_loader: Loading experiment spec at /content/drive/MyDrive/ColabNotebooks/tensorflow/faster_rcnn/specs/default_spec_resnet18.txt.\n","2022-07-08 06:35:20,656 [INFO] iva.common.logging.logging: Log file already exists at /workspace/tao-experiments/faster_rcnn/status.json\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:69: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","2022-07-08 06:35:20,656 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:69: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2022-07-08 06:35:20,657 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/scripts/train.py:78: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2022-07-08 06:35:20.664116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n","2022-07-08 06:35:20.664328: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x783e540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2022-07-08 06:35:20.664358: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2022-07-08 06:35:20.666149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2022-07-08 06:35:20.795225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:20.795967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x783e8c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2022-07-08 06:35:20.795996: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2022-07-08 06:35:20.796317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:20.796936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2022-07-08 06:35:20.796981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-07-08 06:35:20.818214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-07-08 06:35:20.821607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2022-07-08 06:35:20.827591: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2022-07-08 06:35:20.842261: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n","2022-07-08 06:35:20.847056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2022-07-08 06:35:20.849706: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-07-08 06:35:20.849859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:20.850561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:20.851142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n","2022-07-08 06:35:20.851190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-07-08 06:35:21.247483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-07-08 06:35:21.247541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n","2022-07-08 06:35:21.247553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n","2022-07-08 06:35:21.247876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:21.248617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:21.249224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15242 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2022-07-08 06:35:21,250 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:407: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","2022-07-08 06:35:21,251 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/utils/utils.py:407: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","2022-07-08 06:35:21,421 [INFO] root: Sampling mode of the dataloader was set to user_defined.\n","2022-07-08 06:35:21,423 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n","2022-07-08 06:35:21,423 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n","2022-07-08 06:35:21,423 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n","2022-07-08 06:35:21,423 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 2, io threads: 4, compute threads: 2, buffered batches: 4\n","2022-07-08 06:35:21,423 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 78, number of sources: 1, batch size per gpu: 8, steps: 10\n","WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f9e21482b38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f9e21482b38>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n","2022-07-08 06:35:21,517 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f9e21482b38>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f9e21482b38>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n","2022-07-08 06:35:21,540 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n","2022-07-08 06:35:21.590219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:21.591106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2022-07-08 06:35:21.591172: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-07-08 06:35:21.591278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-07-08 06:35:21.591338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2022-07-08 06:35:21.591374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2022-07-08 06:35:21.591413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n","2022-07-08 06:35:21.591441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2022-07-08 06:35:21.591470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-07-08 06:35:21.591586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:21.593831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-07-08 06:35:21.594423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n","2022-07-08 06:35:21,856 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n","2022-07-08 06:35:21,862 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n","2022-07-08 06:35:21,862 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n","WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f9e1028cc88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f9e1028cc88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n","2022-07-08 06:35:21,879 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f9e1028cc88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f9e1028cc88>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/core/build_wheel.runfiles/ai_infra/moduluspy/modulus/blocks/data_loaders/multi_source_loader/types/images2d_reference.py:427: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","2022-07-08 06:35:21,908 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/core/build_wheel.runfiles/ai_infra/moduluspy/modulus/blocks/data_loaders/multi_source_loader/types/images2d_reference.py:427: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:230: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n","\n","2022-07-08 06:35:22,702 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/data_loader/inputs_loader.py:230: The name tf.debugging.assert_less_equal is deprecated. Please use tf.compat.v1.debugging.assert_less_equal instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","2022-07-08 06:35:23,187 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n","\n","2022-07-08 06:35:23,913 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:76: The name tf.debugging.assert_less is deprecated. Please use tf.compat.v1.debugging.assert_less instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:389: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","2022-07-08 06:35:25,380 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:389: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:262: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","2022-07-08 06:35:25,704 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/utils.py:262: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:79: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n","\n","2022-07-08 06:35:29,315 [WARNING] tensorflow: From /home/tao-dev/.cache/dazel/_dazel_tao-dev/d37c8d608f4a1d45f001faf4c28b14cc/execroot/ai_infra/bazel-out/k8-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/faster_rcnn/layers/CropAndResize.py:79: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n","\n","WARNING:tensorflow:From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","2022-07-08 06:35:29,498 [WARNING] tensorflow: From /opt/nvidia/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","2022-07-08 06:35:29,532 [INFO] __main__: Loading pretrained weights from /results/faster_rcnn/resnet_18.hdf5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","2022-07-08 06:35:29,532 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","2022-07-08 06:35:29,532 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","2022-07-08 06:35:29,533 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","2022-07-08 06:35:30,159 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","2022-07-08 06:35:31.097104: F ./tensorflow/core/kernels/random_op_gpu.h:225] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: the provided PTX was compiled with an unsupported toolchain.\n","[97ffb305b3e5:68411] *** Process received signal ***\n","[97ffb305b3e5:68411] Signal: Aborted (6)\n","[97ffb305b3e5:68411] Signal code:  (-6)\n","[97ffb305b3e5:68411] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x43090)[0x7f9ec715f090]\n","[97ffb305b3e5:68411] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcb)[0x7f9ec715f00b]\n","[97ffb305b3e5:68411] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x12b)[0x7f9ec713e859]\n","[97ffb305b3e5:68411] [ 3] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(+0xc1b1788)[0x7f9e703c9788]\n","[97ffb305b3e5:68411] [ 4] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(_ZN10tensorflow7functor16FillPhiloxRandomIN5Eigen9GpuDeviceENS_6random19UniformDistributionINS4_12PhiloxRandomEfEEEclEPNS_15OpKernelContextERKS3_S6_PfxS7_+0x209)[0x7f9e6d05f529]\n","[97ffb305b3e5:68411] [ 5] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so(+0x8e4401e)[0x7f9e6d05c01e]\n","[97ffb305b3e5:68411] [ 6] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZN10tensorflow13BaseGPUDevice7ComputeEPNS_8OpKernelEPNS_15OpKernelContextE+0x3d3)[0x7f9e63518333]\n","[97ffb305b3e5:68411] [ 7] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(+0x11500b7)[0x7f9e635760b7]\n","[97ffb305b3e5:68411] [ 8] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(+0x1150723)[0x7f9e63576723]\n","[97ffb305b3e5:68411] [ 9] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZN5Eigen15ThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0x28d)[0x7f9e6362be6d]\n","[97ffb305b3e5:68411] [10] /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.1(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x4c)[0x7f9e6362897c]\n","[97ffb305b3e5:68411] [11] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xd6de4)[0x7f9ec6e2ade4]\n","[97ffb305b3e5:68411] [12] /lib/x86_64-linux-gnu/libpthread.so.0(+0x8609)[0x7f9ec7101609]\n","[97ffb305b3e5:68411] [13] /lib/x86_64-linux-gnu/libc.so.6(clone+0x43)[0x7f9ec723b133]\n","[97ffb305b3e5:68411] *** End of error message ***\n","Aborted (core dumped)\n"]}],"source":["!faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAQhIOXe3NCk"},"outputs":[],"source":["print('Model for each epoch:')\n","print('---------------------')\n","!ls -lht $LOCAL_EXPERIMENT_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEAP2h_b3NCl"},"outputs":[],"source":["print(\"For multi-GPU data parallelism, please uncomment and run this instead. Change --gpus  and --gpu_index based on your machine.\")\n","# !tao faster_rcnn train -e $SPECS_DIR/default_spec_resnet18.txt \\\n","#                    --gpus 2 \\\n","#                    --gpu_index 0 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4O8dSue3NCl"},"outputs":[],"source":["print(\"\"\"\n","For multi-GPU model parallelism, please uncomment and run this instead.\n","Also add related parameters in training_config to enable model parallelism. E.g., \n","\n","             model_parallelism: 50\n","             model_parallelism: 50\n","\n","\"\"\")\n","\n","#!tao faster_rcnn train -e $SPECS_DIR/default_spec_resnet18.txt \\\n","#                   --gpus 2 \\\n","#                   --gpu_index 0 1\\\n","#                   -np 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WwH3ETSD3NCl"},"outputs":[],"source":["print(\"For resume training from checkpoint, please uncomment and run this instead. Change/Add the 'resume_from_model' field in the spec file.\")\n","# !tao faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvImx3xf3NCl"},"outputs":[],"source":["print(\"For Automatic Mixed Precision(AMP) training, please uncomment and run this. Make sure you use the Volta or above GPU arch to enable AMP.\")\n","# !tao faster_rcnn train --gpu_index $GPU_INDEX --use_amp -e $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"markdown","metadata":{"id":"sv2xVjfO3NCm"},"source":[" ## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jkXljrR43NCm"},"outputs":[],"source":["!tao faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"markdown","metadata":{"id":"WLlXSOXK3NCm"},"source":[" ## 6. Prune trained models <a class=\"anchor\" id=\"head-6\"></a>\n"," * Specify pre-trained model\n"," * Equalization criterion\n"," * Threshold for pruning\n"," * A key to save and load the model\n"," * Output directory to store the model\n"," \n","Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is depend on the dataset. A `pth` value below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BK0qp-hd3NCn"},"outputs":[],"source":["!tao faster_rcnn prune --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18.epoch12.tlt \\\n","           -o $USER_EXPERIMENT_DIR/model_1_pruned.tlt  \\\n","           -eq union  \\\n","           -pth 0.2 \\\n","           -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmXcL8Y13NCn"},"outputs":[],"source":["!ls -lht $LOCAL_EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"cIumtfra3NCn"},"source":[" ## 7. Retrain pruned models <a class=\"anchor\" id=\"head-7\"></a>\n"," * Model needs to be re-trained to bring back accuracy after pruning\n"," * Specify re-training specification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFcqkrvS3NCo"},"outputs":[],"source":["# Here we have updated the spec file to include the newly pruned model as a pretrained weights.\n","!sed -i 's/$KEY/'\"$KEY/g\" $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n","!cat $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wMcUwa0J3NCo"},"outputs":[],"source":["# Retraining using the pruned model as pretrained weights \n","!tao faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FK5vwVly3NCo"},"outputs":[],"source":["# Listing the newly retrained model.\n","!ls -lht $LOCAL_EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"kZ47Sd3S3NCo"},"source":[" ## 8. Evaluate retrained model <a class=\"anchor\" id=\"head-8\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iyD7Ry73NCo"},"outputs":[],"source":["!tao faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"markdown","metadata":{"id":"p8zBqqtG3NCo"},"source":[" ## 9. Visualize inferences <a class=\"anchor\" id=\"head-9\"></a>\n"," In this section, we run the inference tool to generate inferences on the trained models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7pnxoyO3NCo"},"outputs":[],"source":["# Running inference for detection on n images\n","# Please go to $LOCAL_EXPERIMENT_DIR/inference_results_imgs_retrain to see the visualizations.\n","!tao faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"markdown","metadata":{"id":"fDHqp_vW3NCp"},"source":["The `inference` tool produces two outputs. \n","1. Overlain images in `$LOCAL_EXPERIMENT_DIR/inference_results_imgs_retrain`\n","2. Frame by frame bbox labels in kitti format located in `$LOCAL_EXPERIMENT_DIR/inference_dump_labels_retrain`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LzEz58_3NCp"},"outputs":[],"source":["# Simple grid visualizer\n","!pip3 install matplotlib==3.3.3\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import os\n","from math import ceil\n","valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n","\n","def visualize_images(image_dir, num_cols=4, num_images=10):\n","    output_path = os.path.join(os.environ['LOCAL_EXPERIMENT_DIR'], image_dir)\n","    num_rows = int(ceil(float(num_images) / float(num_cols)))\n","    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n","    f.tight_layout()\n","    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n","         if os.path.splitext(image)[1].lower() in valid_image_ext]\n","    for idx, img_path in enumerate(a[:num_images]):\n","        col_id = idx % num_cols\n","        row_id = idx // num_cols\n","        img = plt.imread(img_path)\n","        axarr[row_id, col_id].imshow(img) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGH3xRrM3NCp"},"outputs":[],"source":["# Visualizing the sample images.\n","OUTPUT_PATH = 'inference_results_imgs_retrain' # relative path from $LOCAL_EXPERIMENT_DIR.\n","COLS = 3 # number of columns in the visualizer grid.\n","IMAGES = 9 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]},{"cell_type":"markdown","metadata":{"id":"HWsiZjwQ3NCp"},"source":[" ## 10. Deploy! <a class=\"anchor\" id=\"head-10\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"MHA_u_wk3NCp"},"outputs":[],"source":["# Export in FP32 mode.\n","!if [ -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.etlt ]; then rm -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.etlt; fi\n","!tao faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n","                        -o $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.etlt \\\n","                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n","                        -k $KEY \\\n","                        --gen_ds_config"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"zzVYdo2U3NCp"},"outputs":[],"source":["# Export in FP16 mode.\n","# Note that the .etlt model in FP16 mode is the same as in FP32 mode.\n","!if [ -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_fp16.etlt ]; then rm -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_fp16.etlt; fi\n","!tao faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n","                        -o $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_fp16.etlt \\\n","                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n","                        -k $KEY \\\n","                        --data_type fp16 \\\n","                        --gen_ds_config"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"qr7Jav7V3NCq"},"outputs":[],"source":["# Export in INT8 mode(generate calibration cache file).\n","# Note that the .etlt model in INT8 mode is the same as in FP32 mode.\n","!if [ -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8.etlt ]; then rm -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8.etlt; fi\n","!if [ -f $LOCAL_EXPERIMENT_DIR/cal.bin ]; then rm -f $LOCAL_EXPERIMENT_DIR/cal.bin; fi\n","!tao faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n","                        -o $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8.etlt \\\n","                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n","                        -k $KEY \\\n","                        --data_type int8 \\\n","                        --batch_size 8 \\\n","                        --batches 10 \\\n","                        --cal_cache_file $USER_EXPERIMENT_DIR/cal.bin \\\n","                        --gen_ds_config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYxFuPT13NCq"},"outputs":[],"source":["# Converting to TensorRT engine(FP32) is omitted here as this is trivial.\n","# Convert to TensorRT engine(FP16).\n","# Make sure your GPU type supports the FP16 data type before running this cell.\n","!tao converter -k $KEY  \\\n","               -d 3,384,1248 \\\n","               -o NMS \\\n","               -e $USER_EXPERIMENT_DIR/trt.fp16.engine \\\n","               -m 4 \\\n","               -t fp16 \\\n","               -i nchw \\\n","               $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_fp16.etlt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeWnNFkj3NCq"},"outputs":[],"source":["# Convert to TensorRT engine(INT8).\n","# Make sure your GPU type supports the INT8 data type before running this cell.\n","!tao converter -k $KEY  \\\n","               -d 3,384,1248 \\\n","               -o NMS \\\n","               -c $USER_EXPERIMENT_DIR/cal.bin \\\n","               -e $USER_EXPERIMENT_DIR/trt.int8.engine \\\n","               -b 8 \\\n","               -m 4 \\\n","               -t int8 \\\n","               -i nchw \\\n","               $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8.etlt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElkkO8gD3NCq"},"outputs":[],"source":["print('Exported model and converted TensorRT engine:')\n","print('------------')\n","!ls -lht $LOCAL_EXPERIMENT_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cof8lH7S3NCq"},"outputs":[],"source":["# Do inference with TensorRT on the generated TensorRT engine\n","# Please go to $LOCAL_EXPERIMENT_DIR/inference_results_imgs_retrain to see the visualizations.\n","# Here we use the INT8 engine for inference, if you want to use FP16 engine instead please\n","# customize the 'trt_engine' parameter in the spec file below to point to the FP16 engine.\n","!TRT_LINES=$(grep -n 'trt_inference' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+2))) | sed -i -f - $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n","!tao faster_rcnn inference  --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"markdown","metadata":{"id":"gFA3JsV_3NCq"},"source":["The `inference` tool produces two outputs. \n","The paths to the two outputs are exactly the same as the first `inference` command."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0gi2u7n3NCq"},"outputs":[],"source":["# Visualizing the sample images from TensorRT inference.\n","OUTPUT_PATH = 'inference_results_imgs_retrain' # relative path from $LOCAL_EXPERIMENT_DIR.\n","COLS = 3 # number of columns in the visualizer grid.\n","IMAGES = 9 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3zd0-dQ3NCr"},"outputs":[],"source":["# Doing evaluation with the generated TensorRT engine\n","# modify the spec file a little for tensorrt_evaluation configuration\n","# compare the mAP below with that of `evaluate` with retrained tlt model\n","!TRT_LINES=$(grep -n 'trt_evaluation' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+2))) | sed -i -f - $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n","# do evaluation with tensorrt engine\n","!tao faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"markdown","metadata":{"id":"vuduYRR83NCr"},"source":[" ## 11. QAT workflow <a class=\"anchor\" id=\"head-11\"></a>"]},{"cell_type":"markdown","metadata":{"id":"xvcdcMkR3NCr"},"source":["In this section, we will explore the typical Quantization-Aware Training(QAT) workflow with TAO. QAT workflow is almost the same as non-QAT workflow except for two major differences:\n","1. set `enable_qat` to `True` in training and retraining spec files to enable the QAT for training/retraining\n","2. when doing export in INT8 mode, the calibration cache is extracted directly from the QAT .tlt model, so no need to specify any TensorRT INT8 calibration related arguments for `export`"]},{"cell_type":"markdown","metadata":{"id":"kkiQ1S8Q3NCr"},"source":[" ### 11.1. Training <a class=\"anchor\" id=\"head-10.1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IMscdjDZ3NCr"},"outputs":[],"source":["# set enable_qat to True in training spec file to enable QAT training\n","!sed -i 's/enable_qat: False/enable_qat: True/' $LOCAL_SPECS_DIR/default_spec_resnet18.txt\n","!cat $LOCAL_SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtoW4o_N3NCr"},"outputs":[],"source":["# run QAT training\n","!tao faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"markdown","metadata":{"id":"kAwdfc6X3NCr"},"source":[" ### 11.2. Evaluation <a class=\"anchor\" id=\"head-10.2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J36PO7Xs3NCr"},"outputs":[],"source":["!tao faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18.txt"]},{"cell_type":"markdown","metadata":{"id":"BCc0wCSS3NCr"},"source":[" ### 11.3. Pruning <a class=\"anchor\" id=\"head-10.3\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Wyx8MPn3NCr"},"outputs":[],"source":["!tao faster_rcnn prune --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18.epoch12.tlt \\\n","           -o $USER_EXPERIMENT_DIR/model_1_pruned.tlt  \\\n","           -eq union  \\\n","           -pth 0.2 \\\n","           -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"QgxRHLUm3NCr"},"source":[" ### 11.4. Retraining <a class=\"anchor\" id=\"head-10.4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dso0U9s_3NCr"},"outputs":[],"source":["# set enable_qat to True in retraining spec file to enable QAT\n","!sed -i 's/enable_qat: False/enable_qat: True/' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n","!cat $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCUXIBOx3NCs"},"outputs":[],"source":["!tao faster_rcnn train --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"markdown","metadata":{"id":"4QrxGaar3NCs"},"source":[" ### 11.5. Evaluation of the retrained model <a class=\"anchor\" id=\"head-10.5\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjOrD5qd3NCs"},"outputs":[],"source":["# disable the tensorrt evaluation config in spec file\n","!TRT_LINES=$(grep -n 'trt_evaluation' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/^/#/g\\n' $(seq $TRT_LINES $((TRT_LINES+2))) | sed -i -f - $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8iUd5jrp3NCs"},"outputs":[],"source":["# do evaluation with .tlt model\n","!tao faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"markdown","metadata":{"id":"E-xeF1cd3NCs"},"source":[" ### 11.6. Inference of the retrained model <a class=\"anchor\" id=\"head-10.6\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-T7xnQk3NCs"},"outputs":[],"source":["# disable the tensorrt inference config in spec file\n","!TRT_LINES=$(grep -n 'trt_inference' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/^/#/g\\n' $(seq $TRT_LINES $((TRT_LINES+2))) | sed -i -f - $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJJs9-Nw3NCs"},"outputs":[],"source":["# do inference with .tlt model\n","!tao faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x00vdKFL3NCs"},"outputs":[],"source":["# Visualizing the sample images\n","OUTPUT_PATH = 'inference_results_imgs_retrain' # relative path from $USER_EXPERIMENT_DIR.\n","COLS = 3 # number of columns in the visualizer grid.\n","IMAGES = 9 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]},{"cell_type":"markdown","metadata":{"id":"-mxDlmUf3NCs"},"source":[" ### 11.7. Deployment of the QAT model <a class=\"anchor\" id=\"head-10.7\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDQRM-YX3NCs"},"outputs":[],"source":["# Export in INT8 mode(generate calibration cache file).\n","# No need for calibration dataset for QAT model INT8 export\n","!if [ -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8_qat.etlt ]; then rm -f $LOCAL_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8_qat.etlt; fi\n","!if [ -f $LOCAL_EXPERIMENT_DIR/cal.bin ]; then rm -f $LOCAL_EXPERIMENT_DIR/cal.bin; fi\n","!tao faster_rcnn export --gpu_index $GPU_INDEX -m $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain.epoch12.tlt  \\\n","                        -o $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8_qat.etlt \\\n","                        -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt \\\n","                        -k $KEY \\\n","                        --data_type int8 \\\n","                        --cal_cache_file $USER_EXPERIMENT_DIR/cal.bin \\\n","                        --gen_ds_config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2uD1npW3NCs"},"outputs":[],"source":["# Convert to TensorRT engine(INT8).\n","# Make sure your GPU type supports the INT8 data type before running this cell.\n","!tao converter -k $KEY  \\\n","               -d 3,384,1248 \\\n","               -o NMS \\\n","               -c $USER_EXPERIMENT_DIR/cal.bin \\\n","               -e $USER_EXPERIMENT_DIR/trt.int8.engine \\\n","               -b 8 \\\n","               -m 4 \\\n","               -t int8 \\\n","               -i nchw \\\n","               $USER_EXPERIMENT_DIR/frcnn_kitti_resnet18_retrain_int8_qat.etlt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UhoNYu8w3NCt"},"outputs":[],"source":["print('Exported model and converted TensorRT engine:')\n","print('------------')\n","!ls -lht $LOCAL_EXPERIMENT_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u3XYbEyT3NCt"},"outputs":[],"source":["# Do inference with TensorRT on the generated TensorRT engine\n","# Please go to $LOCAL_EXPERIMENT_DIR/inference_results_imgs_retrain to see the visualizations.\n","!TRT_LINES=$(grep -n 'trt_inference' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+2))) | sed -i -f - $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n","!tao faster_rcnn inference --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALD72cKf3NCt"},"outputs":[],"source":["# Visualizing the sample images from TensorRT inference.\n","OUTPUT_PATH = 'inference_results_imgs_retrain' # relative path from $USER_EXPERIMENT_DIR.\n","COLS = 3 # number of columns in the visualizer grid.\n","IMAGES = 9 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qToUlZ8F3NCt"},"outputs":[],"source":["# Doing evaluation with the generated TensorRT engine\n","# compare the mAP below with that of `evaluate` with retrained tlt model\n","!TRT_LINES=$(grep -n 'trt_evaluation' $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt | cut -d: -f1) && printf '%ds/#//g\\n' $(seq $TRT_LINES $((TRT_LINES+2))) | sed -i -f - $LOCAL_SPECS_DIR/default_spec_resnet18_retrain_spec.txt\n","!tao faster_rcnn evaluate --gpu_index $GPU_INDEX -e $SPECS_DIR/default_spec_resnet18_retrain_spec.txt"]}],"metadata":{"file_extension":".py","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython2","version":2,"colab":{"name":"faster_rcnn.ipynb","provenance":[],"collapsed_sections":["sv2xVjfO3NCm","WLlXSOXK3NCm","cIumtfra3NCn","kZ47Sd3S3NCo","p8zBqqtG3NCo","HWsiZjwQ3NCp","vuduYRR83NCr","kkiQ1S8Q3NCr","kAwdfc6X3NCr","BCc0wCSS3NCr","QgxRHLUm3NCr","4QrxGaar3NCs","E-xeF1cd3NCs","-mxDlmUf3NCs"]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}