{"cells":[{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n","\n","1. Switch to CPU Instance for until Step 2 for non GPU dependent tasks\n","2. This increases your time available for the GPU dependent tasks on a Colab instance\n","2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"4IZtVf3cPyom"},"source":["# License Plate Recognition using TAO LPRNet\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\">\n"]},{"cell_type":"markdown","metadata":{"id":"YxZQEfTBPyoq"},"source":["## Learning Objectives\n","\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained baseline18 LPRNet model and train it on the OpenALPR benchmark dataset\n","* Run Inference on the trained model\n","* Export the trained model to a .etlt file for deployment to DeepStream\n","* Run inference on the exported. etlt model to verify deployment using TensorRT\n","\n","## Table of Contents\n","\n","This notebook shows an example usecase of LPRNet using Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1) <br>\n","    1.1 [Download pre-trained model](#head-1-1) <br>\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>\n","3. [Provide training specification](#head-3)\n","4. [Run TAO training](#head-4)\n","5. [Evaluate trained models](#head-5)\n","6. [Inferences](#head-6)"]},{"cell_type":"markdown","metadata":{"id":"y5lxlv5IPyoq"},"source":["## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n","\n","When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n","\n","*Note: Please make sure to remove any stray artifacts/files from the `$EXPERIMENT_DIR` or `$DATA_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXT1Uv__Pyor"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","%env GPU_INDEX=0\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","    raise(\"Error, enter the path of the colab notebooks repo correctly\")\n","%env EXPERIMENT_DIR=/results/lprnet\n","%env DATA_DIR=/content/drive/MyDrive/lprnet_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/lprnet/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"WI_8N9_IPyov"},"source":["## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"HvQbbU5wPyov"},"source":[" We will be using the OpenALPR benchmark dataset for the tutorial. The following script will download the dataset automatically and convert it to the format used by TAO. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-yJGnS5Pyov"},"outputs":[],"source":["# Create local dir\n","!mkdir -p $DATA_DIR\n","!mkdir -p $EXPERIMENT_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kBI24bHSPyov"},"outputs":[],"source":["%cd $COLAB_NOTEBOOKS_PATH/tensorflow/lprnet/\n","!bash download_and_prepare_data.sh $DATA_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oi9ACFA0Pyov"},"outputs":[],"source":["# verify\n","!echo $DATA_DIR\n","!ls -l $DATA_DIR/\n","!ls -l $DATA_DIR/train\n","!ls -l $DATA_DIR/train/image\n","!ls -l $DATA_DIR/train/label\n"]},{"cell_type":"markdown","metadata":{"id":"p2B28ZwpPyox"},"source":["### 1.1 Download pretrained model from NGC"]},{"cell_type":"markdown","metadata":{"id":"IU1c75iPPyox"},"source":["We will use NGC CLI to get the pre-trained models. For more details, go to https://ngc.nvidia.com and click the SETUP on the navigation bar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85pHGpdOPyoy"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/ngc_content/\n","%env CLI=ngccli_cat_linux.zip\n","!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcsQ_FWqPyoy"},"outputs":[],"source":["!ngc registry model list nvidia/tao/lprnet:*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAx-bsIDPyoy"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/pretrained_lprnet_baseline18/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8EieO4uYPyoy"},"outputs":[],"source":["# Pull pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/lprnet:trainable_v1.0 --dest $EXPERIMENT_DIR/pretrained_lprnet_baseline18"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m0ANlm3XPyoz"},"outputs":[],"source":["print(\"Check that model is downloaded into dir.\")\n","!ls -l $EXPERIMENT_DIR/pretrained_lprnet_baseline18/lprnet_vtrainable_v1.0"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["#FIXME\n","%env GENERAL_WHL_PATH=/content/drive/MyDrive/tf/general_whl\n","#FIXME\n","%env CODEBASE_WHL_PATH=/content/drive/MyDrive/tf/codebase_whl\n","\n","if os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]) and os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]):\n","    if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","        os.environ[\"bash_script\"] = \"setup_env.sh\"\n","    else:\n","        os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","    !sed -i \"s|PATH_TO_GENERAL_WHL|$GENERAL_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","    !sed -i \"s|PATH_TO_CODEBASE_WHL|$CODEBASE_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","    !sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","\n","    !sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","else:\n","    raise(\"Error, enter the whl paths correctly\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","if os.environ.get(\"PYTHONPATH\",\"\") == \"\":\n","    os.environ[\"PYTHONPATH\"] = \"\"\n","os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\"\n","else:\n","    os.environ[\"PYTHONPATH\"]+=\":/home_duplicate/rarunachalam/miniconda3/envs/tf_py_36/lib/python3.6/site-packages/third_party/nvml\" # FIX MINICONDA PATH"]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","%env GPU_INDEX=0\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","    raise(\"Error, enter the path of the colab notebooks repo correctly\")\n","%env EXPERIMENT_DIR=/results/lprnet\n","%env DATA_DIR=/content/drive/MyDrive/lprnet_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/lprnet/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"7N3YWk16Pyoz"},"source":["## 3. Provide training specification <a class=\"anchor\" id=\"head-3\"></a>\n","\n","* Note the spec $SPEC_DIR/default_sepc.txt is for training on US license plates:\n","    * the max license plate length is 8;\n","        * You can change `max_label_length` in `lpr_config` to satisfy your own dataset.\n","    * the characters of US license plates are: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, G, H, I, J, K, L, M, N, P, Q, R, S, T, U, V, W, X, Y, Z \n","        * You can change `characters_list_file` in `dataset_config` to set your own characters.\n","        * `characters_list_file` should contain all the characters in dataset. And one character takes one line. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3fLUuoaPyo0","scrolled":true},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/tutorial_spec.txt\n","!sed -i \"s|TAO_SPEC_DIR|$SPECS_DIR/|g\" $SPECS_DIR/tutorial_spec.txt\n","!cat $SPECS_DIR/tutorial_spec.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yb9OAcd7Pyo0"},"outputs":[],"source":["!cat $SPECS_DIR/us_lp_characters.txt"]},{"cell_type":"markdown","metadata":{"id":"-XifdFs5Pyo0"},"source":["## 4. Run TAO training <a class=\"anchor\" id=\"head-4\"></a>\n","* Provide the sample spec file and the output directory location for models\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnhmABuWPyo0"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_unpruned"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8wKuOHNPyo1","scrolled":true},"outputs":[],"source":["print(\"For multi-GPU, change --gpus based on your machine.\")\n","!tao lprnet train --gpus=1 --gpu_index=$GPU_INDEX \\\n","                  -e $SPECS_DIR/tutorial_spec.txt \\\n","                  -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n","                  -k $KEY \\\n","                  -m $EXPERIMENT_DIR/pretrained_lprnet_baseline18/lprnet_vtrainable_v1.0/us_lprnet_baseline18_trainable.tlt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7I87ZIdPyo1"},"outputs":[],"source":["print(\"To resume training from a checkpoint, set the -m option to be the .tlt you want to resume from and --initial_epochs to be the epoch index of the resumed checkpoint\")\n","# !tao lprnet train --gpu_index=$GPU_INDEX \\\n","#                   -e $SPECS_DIR/tutorial_spec.txt \\\n","#                   -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n","#                   -k $KEY \\\n","#                   -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/lprnet_epoch-01.tlt\n","#                   --initial_epoch 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WDkWKQQkPyo1"},"outputs":[],"source":["print('Model for each epoch:')\n","print('---------------------')\n","!ls -ltrh $EXPERIMENT_DIR/experiment_dir_unpruned/weights/"]},{"cell_type":"markdown","metadata":{"id":"dCYg-llnPyo1"},"source":["## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELV8uJr-Pyo2","scrolled":true},"outputs":[],"source":["!tao lprnet evaluate --gpu_index=$GPU_INDEX -e $SPECS_DIR/tutorial_spec.txt \\\n","                     -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/lprnet_epoch-24.tlt \\\n","                     -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"cvZE4H8KPyo2"},"source":["## 6. Inferences <a class=\"anchor\" id=\"head-6\"></a>\n","In this section, we run the lprnet inference tool to generate inferences on the trained models and print the results. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlqyTE7MPyo3"},"outputs":[],"source":["# Running inference for detection on n images\n","!tao lprnet inference --gpu_index=$GPU_INDEX -i $DATA_DIR/val/image \\\n","                      -e $SPECS_DIR/tutorial_spec.txt \\\n","                      -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/lprnet_epoch-24.tlt \\\n","                      -k $KEY "]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"lprnet.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
