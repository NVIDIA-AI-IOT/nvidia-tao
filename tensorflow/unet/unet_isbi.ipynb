{"cells":[{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n","\n","1. Switch to CPU Instance for until Step 3 for non GPU dependent tasks\n","2. This increases your time available for the GPU dependent tasks on a Colab instance\n","2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"QXehzAlY8xfJ"},"source":["# Binary Semantic Segmentation using TAO UNET\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\"> "]},{"cell_type":"markdown","metadata":{"id":"Ai_rxXaZ8xfL"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained resnet18 model and train a ResNet-18 UNet model on the ISBI dataset\n","* Run Inference on the trained model and visualize the inferences\n","* Export the trained model to a .etlt file for deployment to DeepStream\n","* Run inference on the exported .etlt model to verify deployment using TensorRT\n","\n","### Table of Contents\n","\n","This notebook shows an example use case of UNet Binary Semantic Segmentation using Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1) <br>\n","    1. [Verify downloaded dataset](#head-1-1)\n","    2. [Prepare ISBI data from TIF](#head-1-2)\n","    3. [Visualize the Groundtruth Masks](#head-1-3)\n","    4. [Download pre-trained model](#head-1-4)\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>\n","3. [Provide training specification](#head-3)\n","4. [Run TAO training](#head-4)\n","5. [Evaluate trained models](#head-5)\n","6. [Visualizing Inferences](#head-6)\n","7. [Prune trained models](#head-7)\n","8. [Retrain pruned models](#head-8)\n","9. [Evaluate retrained model](#head-9)"]},{"cell_type":"markdown","metadata":{"id":"zap3weKz8xfM"},"source":["## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n","\n","When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n","\n","*Note: Please make sure to remove any stray artifacts/files from the `$USER_EXPERIMENT_DIR` or `$DATA_DOWNLOAD_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*\n","\n","*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1657409409089,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"6mlNQ66j8xfN","outputId":"dccd517f-0eb5-4227-c3f9-a9aa6dcb869d"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%set_env KEY=nvidia_tlt\n","%set_env GPU_INDEX=0\n","\n","# Change the paths according to your directory structure\n","%set_env EXPERIMENT_DIR=/results/unet\n","%set_env DATA_DIR=/content/drive/MyDrive/unet_data\n","%set_env SPECS_DIR=/content/drive/MyDrive/ColabNotebooks/tensorflow/unet/specs\n","\n","! ls -l $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"LFh8aKeW8xfQ"},"source":["## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"xEa_jaBx8xfR"},"source":["We will be using the `ISBI Challenge: Segmentation of neuronal structures in EM stacks` dataset for the binary segmentation tutorial. The data is present in this github repository https://github.com/alexklibisz/isbi-2012/tree/master/data. The data is in .tif format. Copy the train-labels.tif, train-volume.tif, test-volume.tif files to `$DATA_DIR/isbi`. "]},{"cell_type":"markdown","metadata":{"id":"v3i0tzxb8xfR"},"source":["### A. Verify downloaded dataset <a class=\"anchor\" id=\"head-1-1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1840,"status":"ok","timestamp":1657409788144,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"S4VDCLmS8xfR","outputId":"4fd668ad-23b2-4090-d15f-431e9f39426d"},"outputs":[],"source":["# Check the .tiff files are present\n","!mkdir -p $DATA_DIR/isbi\n","!ls -l $DATA_DIR\n","!if [ ! -f $DATA_DIR/isbi/test-volume.tif ]; then echo 'test-volume.tif file not found, please download.'; else echo 'Found test-volume.tif file.';fi\n","!if [ ! -f $DATA_DIR/isbi/train-labels.tif ]; then echo 'train-labels file not found, please download.'; else echo 'Found train-labels.tif file.';fi\n","!if [ ! -f $DATA_DIR/isbi/train-volume.tif ]; then echo 'train-volume.tif file not found, please download.'; else echo 'Found train-volume.tif file.';fi"]},{"cell_type":"markdown","metadata":{"id":"hpxBZ7sQ8xfR"},"source":["### B.  Prepare ISBI data from TIF <a class=\"anchor\" id=\"head-1-2\"></a>"]},{"cell_type":"markdown","metadata":{"id":"25eQy-Dn8xfR"},"source":["Prepare the images and masks from the .tif files by running the following script."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3206,"status":"ok","timestamp":1657409797060,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"E4_1k5BC8xfS","outputId":"af36bc58-5654-45f8-b40e-3ad3fcab64e1"},"outputs":[],"source":["%cd /content/drive/MyDrive/ColabNotebooks/tensorflow/unet/\n","!bash prepare_data.sh $DATA_DIR/isbi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1448,"status":"ok","timestamp":1657409802894,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"rzliO60D8xfS","outputId":"177abe0e-1697-443c-866f-1252a919d2bc"},"outputs":[],"source":["!if [ ! -f $DATA_DIR/images/image_0.png ]; then echo 'Data prepared successfully !'; else echo 'Please verify Data Preparation.';fi\n","# Checking the files\n","!ls -l $DATA_DIR/isbi\n","!ls -l $DATA_DIR/isbi/images\n","!ls -l $DATA_DIR/isbi/masks\n","!ls -l $DATA_DIR/isbi/images/train"]},{"cell_type":"markdown","metadata":{"id":"GAsdrBRL8xfS"},"source":["### C.  Visualize the Groundtruth Masks <a class=\"anchor\" id=\"head-1-3\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1809,"status":"ok","timestamp":1657409814621,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"g0gnhA3c8xfS","outputId":"ed5bb6c4-a866-4532-e7e4-6c256049c4f8"},"outputs":[],"source":["# Run this cell to visualize the training data and the masks\n","%cd /content/drive/MyDrive/ColabNotebooks/tensorflow/unet/\n","!python3 vis_annotation.py -i $DATA_DIR/isbi/images/train -m $DATA_DIR/isbi/masks/train -o $EXPERIMENT_DIR/isbi_experiment_unpruned/vis_gt --num_classes 2 --num_images 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHpQs4cW8xfS"},"outputs":[],"source":["# Simple grid visualizer\n","%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import os\n","from math import ceil\n","valid_image_ext = ['.jpg', '.png']\n","\n","def visualize_images(image_dir, result_dir, num_cols=4, num_images=10):\n","    output_path = os.path.join(os.environ['EXPERIMENT_DIR'], result_dir, image_dir)\n","    num_rows = int(ceil(float(num_images) / float(num_cols)))\n","    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n","    f.tight_layout()\n","    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n","         if os.path.splitext(image)[1].lower() in valid_image_ext]\n","    for idx, img_path in enumerate(a[:num_images]):\n","        col_id = idx % num_cols\n","        row_id = idx // num_cols\n","        img = plt.imread(img_path)\n","        axarr[row_id, col_id].imshow(img) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":545,"output_embedded_package_id":"16TwZG2WAefizKQYX9ICC3BuevCAFMrht"},"executionInfo":{"elapsed":26350,"status":"ok","timestamp":1657409846447,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"uj7ek7xO8xfT","outputId":"462c6bcb-eaa2-4027-b9c5-54dcfac19d2a"},"outputs":[],"source":["# Visualizing the sample images.\n","OUTPUT_PATH = 'vis_gt' # relative path from $USER_EXPERIMENT_DIR.\n","COLS = 2 # number of columns in the visualizer grid.\n","IMAGES = 4 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, \"isbi_experiment_unpruned\", num_cols=COLS, num_images=IMAGES)"]},{"cell_type":"markdown","metadata":{"id":"FC4JduEv8xfT"},"source":["### D. Download pre-trained model <a class=\"anchor\" id=\"head-1-4\"></a>"]},{"cell_type":"markdown","metadata":{"id":"lcISHw6C8xfT"},"source":["We will use NGC CLI to get the pre-trained models. For more details, go to ngc.nvidia.com and click the SETUP on the navigation bar. \n","\n","*Note: When using vanilla_unet as arch for binary segmentation, pre-trained model section can be skipped. Pre-trained weights are available only for Resnet/ VGG templates*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106,"status":"ok","timestamp":1657409846986,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"0NV7O1YX8xfT","outputId":"ed8b2584-c411-4428-b124-51197e32936e"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/content/\n","%env CLI=ngccli_cat_linux.zip\n","!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70,"status":"ok","timestamp":1657409846986,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"G62plz538xfT","outputId":"d6246718-df3a-429e-d8fa-a6295bc4ccc5"},"outputs":[],"source":["!ngc registry model list nvidia/tao/pretrained_semantic_segmentation:*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"anmLCwip8xfT"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/pretrained_resnet18/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6789,"status":"ok","timestamp":1657409853765,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"x_ilqkDG8xfU","outputId":"cc086963-c441-4196-981d-2271f0db060e"},"outputs":[],"source":["# Pull pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/pretrained_semantic_segmentation:resnet18 --dest $EXPERIMENT_DIR/pretrained_resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1657409853765,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"jhdy1-QE8xfU","outputId":"812ac90f-dfd7-44e0-b768-e3cdd928714b"},"outputs":[],"source":["print(\"Check that model is downloaded into dir.\")\n","!ls -l $EXPERIMENT_DIR/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["!sh /content/drive/MyDrive/ColabNotebooks/tensorflow/setup_env.sh"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n","os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\""]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%set_env KEY=nvidia_tlt\n","%set_env GPU_INDEX=0\n","\n","# Change the paths according to your directory structure\n","%set_env EXPERIMENT_DIR=/results/unet\n","%set_env DATA_DIR=/content/drive/MyDrive/unet_data\n","%set_env SPECS_DIR=/content/drive/MyDrive/ColabNotebooks/tensorflow/unet/specs\n","\n","! ls -l $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"Ybgho3Io8xfU"},"source":["## 3. Provide ISBI training specification <a class=\"anchor\" id=\"head-3\"></a>\n","\n","* Images and Masks path\n","    * In order to use the newly generated images, masks folder update the dataset_config parameter in the spec file at `$SPECS_DIR/unet_train_resnet_unet_isbi.txt` \n","    * Update the train, val images and masks paths. The test only requires the images path. \n","* Pre-trained models\n","* Augmentation parameters for on the fly data augmentation\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rtNFFMds8xfU","scrolled":true},"outputs":[],"source":["!cat $SPECS_DIR/unet_train_resnet_unet_isbi.txt"]},{"cell_type":"markdown","metadata":{"id":"kjMxPewd8xfV"},"source":["## 4. Run TAO training <a class=\"anchor\" id=\"head-4\"></a>\n","* Provide the sample spec file and the output directory location for models\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238702,"status":"ok","timestamp":1657410390777,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"N2xF0oGB8xfV","outputId":"21f92b2e-f1bd-41f8-b84c-a71cfd8a3c2a","scrolled":true},"outputs":[],"source":["print(\"For multi-GPU, change --gpus based on your machine.\")\n","!tao unet train --gpus=1 --gpu_index=$GPU_INDEX \\\n","              -e $SPECS_DIR/unet_train_resnet_unet_isbi.txt \\\n","              -r $EXPERIMENT_DIR/isbi_experiment_unpruned \\\n","              -m $EXPERIMENT_DIR/pretrained_resnet18/pretrained_semantic_segmentation_vresnet18/resnet_18.hdf5 \\\n","              -n model_isbi \\\n","              -k $KEY "]},{"cell_type":"markdown","metadata":{"id":"4zadw16-8xfW"},"source":["Unet supports restarting from checkpoint. In case, the training job is killed prematurely, you may resume training from the closest checkpoint by simply re-running the same command line. Please do make sure to use the same number of GPUs when restarting the training."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1657410512148,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"E4SNTTvD8xfW","outputId":"d5de8624-6dec-4ec2-fd2c-931927d29de7"},"outputs":[],"source":["print('Model for every epoch at checkpoint_interval mentioned in the spec file:')\n","print('---------------------')\n","!ls -ltrh $EXPERIMENT_DIR/isbi_experiment_unpruned/\n","!ls -ltrh $EXPERIMENT_DIR/isbi_experiment_unpruned/weights"]},{"cell_type":"markdown","metadata":{"id":"X3CY0jfU8xfX"},"source":["## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>"]},{"cell_type":"markdown","metadata":{"id":"dIb1kjKm8xfX"},"source":["The last step model saved in the `$USER_EXPERIMENT_DIR/isbi_experiment_unpruned/weights` dir is used for evaluation/ inference/ export. The evaluation also creates `$EXPERIMENT_DIR/isbi_experiment_unpruned/results_tlt.json`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31774,"status":"ok","timestamp":1657410621787,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"PdJdcxQo8xfX","outputId":"77cc37e4-c82f-4de4-f4b8-71c174a8e99c","scrolled":true},"outputs":[],"source":["!tao unet evaluate --gpu_index=$GPU_INDEX -e $SPECS_DIR/unet_train_resnet_unet_isbi.txt \\\n","                 -m $EXPERIMENT_DIR/isbi_experiment_unpruned/weights/model_isbi.tlt \\\n","                 -o $EXPERIMENT_DIR/isbi_experiment_unpruned/ \\\n","                 -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1657410621788,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"aQX38tYe8xfX","outputId":"2d9c158c-b547-4e34-8027-2e39de1d7e9f"},"outputs":[],"source":["!cat $EXPERIMENT_DIR/isbi_experiment_unpruned/results_tlt.json"]},{"cell_type":"markdown","metadata":{"id":"5qLWxI_R8xfX"},"source":["## 6. Visualizing Inferences <a class=\"anchor\" id=\"head-6\"></a>\n","In this section, we run the UNet inference tool to generate inferences on the trained models and print the results. \n","\n","The following cell will run inference for segmentation and visualize masks for the images in test. The resulting visualized images will be saved in the `vis_overlay_tlt` folder and label PNG masks in `mask_labels_tlt` in the path provided to `-o` argument.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18960,"status":"ok","timestamp":1657410682177,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"zCYdFDa28xfX","outputId":"009d5f4a-5a22-4494-af59-906e1108bef5"},"outputs":[],"source":["!tao unet inference --gpu_index=$GPU_INDEX -e $SPECS_DIR/unet_train_resnet_unet_isbi.txt \\\n","                 -m $EXPERIMENT_DIR/isbi_experiment_unpruned/weights/model_isbi.tlt \\\n","                 -o $EXPERIMENT_DIR/isbi_experiment_unpruned/ \\\n","                 -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"elapsed":2657,"status":"ok","timestamp":1657410685878,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"1nVDVBEm8xfY","outputId":"f6e48123-9ce6-4a14-aa00-e105c8a15f92"},"outputs":[],"source":["# Visualizing the sample images.\n","OUTPUT_PATH = 'vis_overlay_tlt' # relative path from $USER_EXPERIMENT_DIR.\n","COLS = 2 # number of columns in the visualizer grid.\n","IMAGES = 4 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, \"isbi_experiment_unpruned\", num_cols=COLS, num_images=IMAGES)"]},{"cell_type":"markdown","metadata":{"id":"bntUfu1Q8xfY"},"source":["## 7. Prune the trained model <a class=\"anchor\" id=\"head-7\"></a>\n","* Specify pre-trained model\n","* Equalization criterion (`Applicable for resnets`)\n","* Threshold for pruning.\n","* A key to save and load the model\n","* Output directory to store the model\n","\n","*Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is dependent on the dataset. A pth value `5.2e-6` is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy.*\n","\n","* For some internal studies, we have noticed that a pth value of 0.1 is a good starting point for unet models trained on larger datasets. A larger regularization value in the first round of training will result in smaller models while pruning. Hence regularization while training and pth are hyper-parameters that needs to be tuned.*"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1657410705853,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"9ObZVGHe8xfY"},"outputs":[],"source":["# Create an output directory if it doesn't exist.\n","!mkdir -p $EXPERIMENT_DIR/isbi_experiment_pruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19267,"status":"ok","timestamp":1657410727788,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"zZwgBBnt8xfY","outputId":"7bb63d60-39e5-4b49-a0cc-13ffae9a1108"},"outputs":[],"source":["!tao unet prune \\\n","                  -e $SPECS_DIR/unet_train_resnet_unet_isbi.txt \\\n","                  -m $EXPERIMENT_DIR/isbi_experiment_unpruned/weights/model_isbi.tlt \\\n","                  -o $EXPERIMENT_DIR/isbi_experiment_pruned/model_isbi_pruned.tlt \\\n","                  -eq union \\\n","                  -pth 0.6 \\\n","                  -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_rUcSibx8xfZ"},"outputs":[],"source":["!ls -rlt $EXPERIMENT_DIR/isbi_experiment_pruned/"]},{"cell_type":"markdown","metadata":{"id":"-YFYJ8rf8xfZ"},"source":["## 8. Retrain the pruned model <a class=\"anchor\" id=\"head-8\"></a>\n","* Model needs to be re-trained to bring back accuracy after pruning\n","* Specify re-training specification with pretrained weights as pruned model.\n","\n","*Note: For retraining, please set the `load_graph` option to `true` in the model_config to load the pruned model graph. Also, if after retraining, the model shows some decrease in MIOU, it could be that the originally trained model was pruned a little too much. Please try reducing the pruning threshold (thereby reducing the pruning ratio) and use the new model to retrain.*\n","\n","*Note: Ensure to provide a different folder for saving results of retraining from the folder where pruned model is saved."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCTweMeW8xfZ"},"outputs":[],"source":["# Printing the retrain experiment file. \n","# Note: We have updated the experiment file to include the \n","# newly pruned model as a pretrained weights and, the\n","# load_graph option is set to true \n","!cat $SPECS_DIR/unet_train_resnet_unet_isbi_retrain.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":215274,"status":"ok","timestamp":1657410953379,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"73OXudNU8xfZ","outputId":"0c1414c8-337e-4624-deb8-9ce2a136e8c3"},"outputs":[],"source":["# Retraining using the pruned model as pretrained weights \n","!tao unet train --gpus=1 --gpu_index=$GPU_INDEX \\\n","              -e $SPECS_DIR/unet_train_resnet_unet_isbi_retrain.txt \\\n","              -r $EXPERIMENT_DIR/isbi_experiment_retrain \\\n","              -m $EXPERIMENT_DIR/isbi_experiment_pruned/model_isbi_pruned.tlt \\\n","              -n model_isbi_retrained \\\n","              -k $KEY "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1657410953381,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"zPRvZZ8M8xfZ","outputId":"b015a544-aa7c-43ba-ac86-0fc04711a12e"},"outputs":[],"source":["# Listing the newly retrained model.\n","!ls -rlt $EXPERIMENT_DIR/isbi_experiment_retrain/weights"]},{"cell_type":"markdown","metadata":{"id":"2UccCKyw8xfZ"},"source":["## 9. Evaluate the retrained model <a class=\"anchor\" id=\"head-9\"></a>"]},{"cell_type":"markdown","metadata":{"id":"enR8tYSP8xfZ"},"source":["This section evaluates the pruned and retrained model, using the `evaluate` command."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22037,"status":"ok","timestamp":1657410975406,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"o40w4UsR8xfZ","outputId":"bef95519-c9e8-4c10-96b0-99addb342596"},"outputs":[],"source":["!tao unet evaluate --gpu_index=$GPU_INDEX -e $SPECS_DIR/unet_train_resnet_unet_isbi_retrain.txt \\\n","                 -m $EXPERIMENT_DIR/isbi_experiment_retrain/weights/model_isbi_retrained.tlt \\\n","                 -o $EXPERIMENT_DIR/isbi_experiment_retrain/ \\\n","                 -k $KEY"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["X3CY0jfU8xfX","5qLWxI_R8xfX","bntUfu1Q8xfY","-YFYJ8rf8xfZ","2UccCKyw8xfZ","n6ZaA8D08xfZ","Wrx47_ob8xfb"],"name":"unet_isbi.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
