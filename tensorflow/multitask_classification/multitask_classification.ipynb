{"cells":[{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n","\n","1. Switch to CPU Instance for until Step 2 for non GPU dependent tasks\n","2. This increases your time available for the GPU dependent tasks on a Colab instance\n","2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"-fLctans81j_"},"source":["## Multi-task classification using TAO\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\">"]},{"cell_type":"markdown","metadata":{"id":"NQByr3Gp81kD"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained resnet10 model and train a ResNet-10 Multi-task Classification model on fashion dataset\n","* Prune the trained model\n","* Retrain the pruned model to recover lost accuracy\n","* Export the pruned model\n","* Run Inference on the trained model\n","* Export the pruned and retrained model to a .etlt file for deployment to DeepStream\n","\n","### Table of Contents\n","This notebook shows an example use case for classification using the Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1) <br>\n","     1.1 [Download the dataset](#head-1-1)<br>\n","     1.2 [Verify the downloaded dataset](#head-1-2)<br>\n","     1.3 [Data preprocessing](#head-1-3)<br>\n","     1.4 [Download pretrained model](#head-1-4)\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>\n","3. [Provide training specification](#head-3)\n","4. [Run TAO training](#head-4)\n","5. [Evaluate trained models](#head-5)\n","6. [Prune trained models](#head-6)\n","7. [Retrain pruned models](#head-7)\n","8. [Testing the model](#head-8)\n","9. [Inferences](#head-9)"]},{"cell_type":"markdown","metadata":{"id":"U1Hb0nb281kD"},"source":["## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n","When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n","\n","*Note: Please make sure to remove any stray artifacts/files from the `$EXPERIMENT_DIR` or `$DATA_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*\n","\n","*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3145,"status":"ok","timestamp":1657661822933,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"95ntdpGs81kE","outputId":"3053ba9f-96a7-4fa9-eeed-1a702f162a39"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","%env EXPERIMENT_DIR=/results/multitask_classification\n","%env DATA_DIR=/content/drive/MyDrive/multitask_classification_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/multitask_classification/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"6Sby1KDS81kG"},"source":["## 1. Prepare datasets and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"ATP81aVp81kH"},"source":["We will be using the Fashion Product Images (Small) for the tutorial. This dataset is available on Kaggle.\n"," \n","In this tutorial, our trained classification network will perform three tasks: article category classification, base color classification and target season classification."]},{"cell_type":"markdown","metadata":{"id":"Tohu4GJs81kH"},"source":["### 1.1 Download the dataset <a class=\"anchor\" id=\"head-1-1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4smLhbrz81kH"},"outputs":[],"source":["import os\n","!mkdir -p $DATA_DIR\n","!echo \"Your DATA_DIR is: $DATA_DIR\""]},{"cell_type":"markdown","metadata":{"id":"dk37hXSt81kI"},"source":["To download the dataset, you will need a Kaggle account. After login, you can download the dataset zip file here: https://www.kaggle.com/paramaggarwal/fashion-product-images-small\n","\n","The downloaded file is `archive.zip` with a subfolder called `myntradataset`. Unzip contents in this subfolder to your `DATA_DIR` created in the cell above and you should have a folder called `images` and a CSV file called `styles.csv`"]},{"cell_type":"markdown","metadata":{"id":"LpJMA9BZ81kI"},"source":["### 1.2 Verify the downloaded dataset <a class=\"anchor\" id=\"head-1-2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1657661862821,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Ffclteik81kI","outputId":"24b6182b-fc28-4f62-a1cc-7af5525b2515"},"outputs":[],"source":["# Check the dataset is present\n","!mkdir -p $DATA_DIR\n","!if [ ! -d $DATA_DIR/images ]; then echo 'images folder NOT found.'; else echo 'Found images folder.';fi\n","!if [ ! -f $DATA_DIR/styles.csv ]; then echo 'CSV file NOT found.'; else echo 'Found CSV file.';fi"]},{"cell_type":"markdown","metadata":{"id":"hPdPm5ZU81kI"},"source":["### 1.3 Data preprocessing <a class=\"anchor\" id=\"head-1-3\"></a>\n","\n","In order to make data trainable in TAO, we need to preprocess it and do train / val split.\n","\n","TAO Multitask classification requires:   \n","1. A training label CSV file containing labels for training images\n","2. A validation label CSV file containing labels for validation images\n","3. An image folder containing all train and val images (may also contain other images, the images to be used is controlled by CSV files).\n","\n","The CSV files for training / validation labels should have following patterns:\n","1. The first column should always be `fname` containing file names for images (without folder prefix)\n","2. Rest of columns should be the name of individual tasks. There're no limitations on the number of tasks\n","\n","For example, if your validation set has 2 images, the CSV should look like this:\n","\n","| fname     | base_color | category | season |\n","|-----------|------------|----------|--------|\n","| 10000.jpg | Blue       | Shoes    | Spring |\n","| 10001.jpg | White      | Bags     | Fall   |\n","\n","We also need to do train/val split. Here, we use 10% of data (random chosen) as validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"executionInfo":{"elapsed":1583,"status":"error","timestamp":1657661854728,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"kJ5KIgXc81kJ","outputId":"cffe1bb8-07a6-472a-fe1f-fc1bd09a078a"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","df = pd.read_csv(os.environ['DATA_DIR'] + '/styles.csv', error_bad_lines=False, warn_bad_lines=False)\n","df = df[['id', 'baseColour', 'subCategory', 'season']]\n","df = df.dropna()\n","category_cls = df.subCategory.value_counts()[:10].index # 10-class classification\n","season_cls = ['Spring', 'Summer', 'Fall', 'Winter'] # 4-class classification\n","color_cls = df.baseColour.value_counts()[:11].index # 11-class classification\n","\n","# Get all valid rows\n","df = df[df.subCategory.isin(category_cls) & df.season.isin(season_cls) & df.baseColour.isin(color_cls)]\n","df.columns = ['fname', 'base_color', 'category', 'season']\n","df.fname = df.fname.astype(str)\n","df.fname = df.fname + '.jpg'\n","\n","# remove entries whose image file is missing\n","all_img_files = os.listdir(os.environ['DATA_DIR'] + '/images')\n","df = df[df.fname.isin(all_img_files)]\n","\n","idx = np.arange(len(df))\n","np.random.shuffle(idx)\n","val_df = df.iloc[idx[:(len(df) // 10)]]\n","train_df = df.iloc[idx[(len(df) // 10):]]\n","\n","# Add a simple sanity check\n","assert len(val_df.season.unique()) == 4 and len(val_df.base_color.unique()) == 11 and \\\n","    len(val_df.category.unique()) == 10, 'Validation set misses some classes, re-run this cell!'\n","assert len(train_df.season.unique()) == 4 and len(train_df.base_color.unique()) == 11 and \\\n","    len(train_df.category.unique()) == 10, 'Training set misses some classes, re-run this cell!'\n","\n","# save processed data labels\n","train_df.to_csv(os.environ['DATA_DIR'] + '/train.csv', index=False)\n","val_df.to_csv(os.environ['DATA_DIR'] + '/val.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ronWbK6G81kJ"},"outputs":[],"source":["# verify\n","import pandas as pd\n","\n","print(\"Number of images in the train set. {}\".format(\n","    len(pd.read_csv(os.environ['DATA_DIR'] + '/train.csv'))\n","))\n","print(\"Number of images in the validation set. {}\".format(\n","    len(pd.read_csv(os.environ['DATA_DIR'] + '/val.csv'))\n","))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b4YA0Sd81kJ"},"outputs":[],"source":["# Sample label.\n","pd.read_csv(os.environ['DATA_DIR'] + '/val.csv').head()"]},{"cell_type":"markdown","metadata":{"id":"xpMMbpzj81kJ"},"source":["### 1.4 Download pre-trained model <a class=\"anchor\" id=\"head-1-4\"></a>"]},{"cell_type":"markdown","metadata":{"id":"i6wL_Qph81kK"},"source":[" We will use NGC CLI to get the pre-trained models. For more details, go to ngc.nvidia.com and click the SETUP on the navigation bar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nWa5FKJl81kK"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/ngc_content/\n","%env CLI=ngccli_cat_linux.zip\n","!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouDrZ83M81kK","scrolled":true},"outputs":[],"source":["!ngc registry model list nvidia/tao/pretrained_classification:*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73Lu9tBe81kK"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/pretrained_resnet10/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5758,"status":"ok","timestamp":1657414429753,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Dete-Uyh81kK","outputId":"afb5a6ac-e8f0-4ad6-e24d-cb67835708e8"},"outputs":[],"source":["# Pull pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/pretrained_classification:resnet10 --dest $EXPERIMENT_DIR/pretrained_resnet10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUvWzdzw81kK"},"outputs":[],"source":["print(\"Check that model is downloaded into dir.\")\n","!ls -l $EXPERIMENT_DIR/pretrained_resnet10/pretrained_classification_vresnet10"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["#FIXME\n","%env GENERAL_WHL_PATH=/content/drive/MyDrive/tf/general_whl\n","#FIXME\n","%env CODEBASE_WHL_PATH=/content/drive/MyDrive/tf/codebase_whl\n","\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    os.environ[\"bash_script\"] = \"setup_env.sh\"\n","else:\n","    os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","!sed -i \"s|PATH_TO_GENERAL_WHL|$GENERAL_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","!sed -i \"s|PATH_TO_CODEBASE_WHL|$CODEBASE_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","!sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","\n","!sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","if os.environ.get(\"PYTHONPATH\",\"\") == \"\":\n","    os.environ[\"PYTHONPATH\"] = \"\"\n","os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\"\n","else:\n","    os.environ[\"PYTHONPATH\"]+=\":/home_duplicate/rarunachalam/miniconda3/envs/tf_py_36/lib/python3.6/site-packages/third_party/nvml\" # FIX MINICONDA PATH"]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","%env EXPERIMENT_DIR=/results/multitask_classification\n","%env DATA_DIR=/content/drive/MyDrive/multitask_classification_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/multitask_classification/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"siMy70Qc81kK"},"source":["## 3. Provide training specification <a class=\"anchor\" id=\"head-3\"></a>\n","* Training dataset\n","* Validation dataset\n","* Pre-trained models\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxSIUs2p81kL","scrolled":true},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/mclassification_spec.cfg\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/mclassification_spec.cfg\n","!cat $SPECS_DIR/mclassification_spec.cfg"]},{"cell_type":"markdown","metadata":{"id":"8QfMI5mG81kL"},"source":["## 4. Run TAO training <a class=\"anchor\" id=\"head-4\"></a>\n","* Provide the sample spec file and the output directory location for models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9847,"status":"ok","timestamp":1657661834247,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"w3m6eaqM81kL","outputId":"610d2c51-0406-48ba-e8bd-316476bb6dd1"},"outputs":[],"source":["!tao multitask_classification train -e $SPECS_DIR/mclassification_spec.cfg \\\n","                                    -r $EXPERIMENT_DIR \\\n","                                    -k $KEY \\\n","                                    --gpus $NUM_GPUS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeDvK3pI81kM"},"outputs":[],"source":["print(\"To resume from checkpoint, please change pretrain_model_path to resume_model_path in config file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1657415366903,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"mHnBHHHz81kM","outputId":"f6d0cd5c-1df7-4004-e90a-ffb51bd7135d"},"outputs":[],"source":["# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n","!cat $EXPERIMENT_DIR/multitask_cls_training_log_resnet10.csv\n","%env EPOCH=010"]},{"cell_type":"markdown","metadata":{"id":"WPXMkTAm81kN"},"source":["## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19532,"status":"ok","timestamp":1657415386425,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"5y4wyrTm81kN","outputId":"e69c7a9f-803e-449c-f7a3-feec0d911d65","scrolled":true},"outputs":[],"source":["!tao multitask_classification evaluate -m $EXPERIMENT_DIR/weights/multitask_cls_resnet10_epoch_$EPOCH.tlt \\\n","                                       -e $SPECS_DIR/mclassification_spec.cfg \\\n","                                       -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"AyGGtsrr81kN"},"source":["## 6. Prune trained models <a class=\"anchor\" id=\"head-6\"></a>\n","* Specify pre-trained model\n","* Equalization criterion\n","* Threshold for pruning\n","\n","Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is depend on the dataset. A pth value 0.65 is just a starting point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24813,"status":"ok","timestamp":1657415411219,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"X5_dQEf281kN","outputId":"e55867a6-856c-4462-ed61-761617b826e1"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/resnet_pruned\n","!tao multitask_classification prune -m $EXPERIMENT_DIR/weights/multitask_cls_resnet10_epoch_$EPOCH.tlt \\\n","                                    -o $EXPERIMENT_DIR/resnet_pruned/resnet10_pruned.tlt \\\n","                                    -eq union \\\n","                                    -pth 0.65 \\\n","                                    -k $KEY \\\n","                                    --results_dir $EXPERIMENT_DIR/logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1657415411220,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"CoHLYAzl81kO","outputId":"8f96147a-f7a6-4a42-9b83-fde15fa2c680"},"outputs":[],"source":["print('Pruned model:')\n","print('------------')\n","!ls -rlt $EXPERIMENT_DIR/resnet_pruned"]},{"cell_type":"markdown","metadata":{"id":"yOUXQvLT81kO"},"source":["## 7. Retrain pruned models <a class=\"anchor\" id=\"head-7\"></a>\n","* Model needs to be re-trained to bring back accuracy after pruning\n","* Specify re-training specification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQO59k9c81kO"},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/mclassification_retrain_spec.cfg\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/mclassification_retrain_spec.cfg\n","!cat $SPECS_DIR/mclassification_retrain_spec.cfg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":890969,"status":"ok","timestamp":1657416302184,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"esXOGTP881kO","outputId":"fb3b2c03-2da8-429d-e8cd-b7f254c01196"},"outputs":[],"source":["!tao multitask_classification train -e $SPECS_DIR/mclassification_retrain_spec.cfg \\\n","                                    -r $EXPERIMENT_DIR/resnet_pruned \\\n","                                    -k $KEY \\\n","                                    --gpus $NUM_GPUS"]},{"cell_type":"markdown","metadata":{"id":"32_dq9v481kP"},"source":["## 8. Testing the model! <a class=\"anchor\" id=\"head-8\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169,"status":"ok","timestamp":1657416302189,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"kV806q5Y81kP","outputId":"fdf5ac16-689c-4105-aab4-9a966b311522"},"outputs":[],"source":["# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n","!cat $EXPERIMENT_DIR/resnet_pruned/multitask_cls_training_log_resnet10.csv\n","%env EPOCH=010"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17489,"status":"ok","timestamp":1657416319622,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"LJBVtYf781kP","outputId":"f0b5671c-a991-4300-ad74-18ef4bf9d975"},"outputs":[],"source":["!tao multitask_classification evaluate -m $EXPERIMENT_DIR/resnet_pruned/weights/multitask_cls_resnet10_epoch_$EPOCH.tlt \\\n","                                       -e $SPECS_DIR/mclassification_retrain_spec.cfg \\\n","                                       -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"NRF0v2-s81kP"},"source":["TAO also provides `confmat` command to generate confusion matrix of the model on an unseen dataset. Users need to provide the image folder and the dataset labels. Here, we use the validation dataset as sample."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29110,"status":"ok","timestamp":1657416348636,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"gpFxxdV081kP","outputId":"d0d469a1-9fad-43d4-e157-136cd1679f5a"},"outputs":[],"source":["!tao multitask_classification confmat -m $EXPERIMENT_DIR/resnet_pruned/weights/multitask_cls_resnet10_epoch_$EPOCH.tlt \\\n","                                      -i $DATA_DIR/images \\\n","                                      -l $DATA_DIR/val.csv \\\n","                                      -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"VOXQ4Isr81kP"},"source":["## 9. Inferences <a class=\"anchor\" id=\"head-9\"></a>"]},{"cell_type":"markdown","metadata":{"id":"vH7tAcD481kQ"},"source":["TAO provides `inference` command to infer on a single image. User needs to provide class mapping JSON file generated during training process."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":1164,"status":"ok","timestamp":1657416349720,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"NkU4c_-D81kQ","outputId":"32a9a6de-99af-48b3-fcba-6b13956ec18e"},"outputs":[],"source":["!pip3 install matplotlib==3.3.3\n","import matplotlib.pyplot as plt\n","from PIL import Image \n","import os\n","\n","DEMO_IMAGE = '1654.jpg'\n","image_path = os.path.join(os.environ.get('DATA_DIR'), 'images', DEMO_IMAGE)\n","plt.imshow(Image.open(image_path))\n","os.environ['DEMO_IMG_PATH'] = os.path.join(os.environ.get('DATA_DIR'), 'images/', DEMO_IMAGE)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12635,"status":"ok","timestamp":1657416362293,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"S8WOGiva81kQ","outputId":"dbe0d401-81d5-4373-f263-8e639ea0c153"},"outputs":[],"source":["!tao multitask_classification inference -m $EXPERIMENT_DIR/resnet_pruned/weights/multitask_cls_resnet10_epoch_$EPOCH.tlt \\\n","                                        -i $DEMO_IMG_PATH \\\n","                                        -cm $EXPERIMENT_DIR/class_mapping.json \\\n","                                        -k $KEY"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"multitask_classification.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
