{"cells":[{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n","\n","1. Switch to CPU Instance for until Step 2 for non GPU dependent tasks\n","2. This increases your time available for the GPU dependent tasks on a Colab instance\n","2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"pzntFQFG9bto"},"source":["# Instance Segmentation using TAO MaskRCNN\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\"> "]},{"cell_type":"markdown","metadata":{"id":"BaRelNDw9btr"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained resnet50 model and train a MaskRCNN model on COCO dataset\n","* Evaluate the trained model\n","* Run Inference with the trained model and visualize the result\n","* Export the trained model to a .etlt file for deployment to DeepStream\n","* Run inference on the exported. etlt model to verify deployment using TensorRT\n","\n","### Table of Contents\n","This notebook shows an example use case for instance segmentation using the Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1)\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>\n","3. [Provide training specification](#head-3)\n","4. [Run TAO training](#head-4)\n","5. [Evaluate trained models](#head-5)\n","6. [Prune trained model](#head-6)\n","7. [Retrain pruned models](#head-7)\n","8. [Evaluate retrained model](#head-8)\n","9. [Visualize inferences](#head-9)"]},{"cell_type":"markdown","metadata":{"id":"fDyiwOAQ9bts"},"source":["## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n","When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n","\n","*Note: Please make sure to remove any stray artifacts/files from the `$EXPERIMENT_DIR` or `$DATA_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*\n","\n","*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly*"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":196,"status":"ok","timestamp":1657338706629,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"atlBUHEV9btt","outputId":"c46e224b-7c34-4a46-abda-929936533655"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","except:\n","    %env GOOGLE_COLAB=0\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","%env EXPERIMENT_DIR=/results/mask_rcnn\n","%env DATA_DIR=/content/drive/MyDrive/coco_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/mask_rcnn/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"WJx_yoZ39btv"},"source":["## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"Y3fwDUWu9btw"},"source":[" We will be using the COCO dataset for the tutorial. The following script will download COCO dataset automatically and convert it to TFRecords. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1657338706815,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EW78Zi2A9btw","outputId":"0401d897-3c52-47c8-83f4-f4f6551aa5de","scrolled":true},"outputs":[],"source":["# Create local dir\n","!mkdir -p $DATA_DIR\n","!mkdir -p $EXPERIMENT_DIR\n","# Download and preprocess data\n","# !tao mask_rcnn run bash $SPECS_DIR/download_and_preprocess_coco.sh $DATA_DIR"]},{"cell_type":"markdown","metadata":{"id":"Ihz-F_DC9btw"},"source":["Note that the dataset conversion scripts provided in `specs` are intended for the standard COCO dataset. If your data doesn't have `caption` groundtruth or test set, you can modify `download_and_preprocess_coco.sh` and `create_coco_tf_record.py` by commenting out corresponding variables."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1657338706990,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"8Erlawaz9btw","outputId":"2518741e-ac57-423d-e3b3-ad10f47edafa"},"outputs":[],"source":["# verify\n","!ls -l $DATA_DIR"]},{"cell_type":"markdown","metadata":{"id":"ths8klL19btw"},"source":["### Download pretrained model from NGC"]},{"cell_type":"markdown","metadata":{"id":"nPba2vTj9btx"},"source":[" We will use NGC CLI to get the pre-trained models. For more details, go to ngc.nvidia.com and click the SETUP on the navigation bar."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1800,"status":"ok","timestamp":1657338708786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"C_GkXOAu9btx","outputId":"fd422cd7-70e2-4371-c1b9-4bd7442d529a"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/ngc_content/\n","%env CLI=ngccli_cat_linux.zip\n","!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2987,"status":"ok","timestamp":1657338711767,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"FqROYQIE9btx","outputId":"e83c655e-bef4-4140-8722-6b28fdde6bae"},"outputs":[],"source":["!ngc registry model list nvidia/tao/pretrained_instance_segmentation:*"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1657338711767,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"tNXI-Id59btx"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/pretrained_resnet50/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9335,"status":"ok","timestamp":1657338721097,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"SmzChNzr9btx","outputId":"02494668-fad4-4473-88bd-7a57093b5659"},"outputs":[],"source":["# Pull pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/pretrained_instance_segmentation:resnet50 --dest $EXPERIMENT_DIR/pretrained_resnet50"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1657338721098,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"dlYJKHq29bty","outputId":"e7882395-6c46-4bf7-d493-21e7558ee08b"},"outputs":[],"source":["print(\"Check that model is downloaded into dir.\")\n","!ls -l $EXPERIMENT_DIR/pretrained_resnet50/pretrained_instance_segmentation_vresnet50"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["#FIXME\n","%env GENERAL_WHL_PATH=/content/drive/MyDrive/tf/general_whl\n","#FIXME\n","%env CODEBASE_WHL_PATH=/content/drive/MyDrive/tf/codebase_whl\n","\n","if os.environ[\"GOOGLE_COLAB\"]:\n","    os.environ[\"bash_script\"] = \"setup_env.sh\"\n","else:\n","    os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","!sed -i \"s|PATH_TO_GENERAL_WHL|$GENERAL_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","!sed -i \"s|PATH_TO_CODEBASE_WHL|$CODEBASE_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","!sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","\n","!sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n","if os.environ[\"GOOGLE_COLAB\"]:\n","    os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\"\n","else:\n","    os.environ[\"PYTHONPATH\"]+=\":/home_duplicate/rarunachalam/miniconda3/envs/tf_py_36/lib/python3.6/site-packages/third_party/nvml\" # FIX MINICONDA PATH"]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","except:\n","    %env GOOGLE_COLAB=0\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","%env EXPERIMENT_DIR=/results/mask_rcnn\n","%env DATA_DIR=/content/drive/MyDrive/coco_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/mask_rcnn/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"-V-E7Feo9bty"},"source":["## 3. Provide training specification <a class=\"anchor\" id=\"head-3\"></a>\n","* Tfrecords for the train datasets\n","    * In order to use the newly generated tfrecords, update the dataset_config parameter in the spec file at `$SPECS_DIR/maskrcnn_train_resnet50.txt` \n","Note that the learning rate in the spec file is set for 4 GPU training. If you have N gpus, you should divide LR by 4/N.\n","* Pre-trained models\n","* Augmentation parameters for on the fly data augmentation\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n","* **Note that the sample spec is not meant to produce SOTA accuracy on COCO. To reproduce SOTA, you might want to use TAO to train an ImageNet model first and change the total_steps to 100K or above. In one experiment, we got 37+% AP and 34% mask_AP with 8GPU training for 100K.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0cOyxMq9bty","scrolled":true},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/maskrcnn_train_resnet50.txt\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/maskrcnn_train_resnet50.txt\n","!cat $SPECS_DIR/maskrcnn_train_resnet50.txt"]},{"cell_type":"markdown","metadata":{"id":"OpOx2qA09bty"},"source":["## 4. Train a MaskRCNN model <a class=\"anchor\" id=\"head-4\"></a>\n","* Provide the sample spec file and the output directory location for models\n","* Evaluation uses COCO metrics. For more info, please refer to: https://cocodataset.org/#detection-eval\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1657338721318,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"GoOCsnhI9bty"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_unpruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9098451,"status":"ok","timestamp":1657354444112,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"1sUCAZHF9bty","outputId":"ed54f8ba-c0a7-4030-d38a-90abab782dd2","scrolled":true},"outputs":[],"source":["print(\"For multi-GPU, change --gpus based on your machine.\")\n","!tao mask_rcnn train -e $SPECS_DIR/maskrcnn_train_resnet50.txt \\\n","                     -d $EXPERIMENT_DIR/experiment_dir_unpruned\\\n","                     -k $KEY \\\n","                     --gpus 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJKgusnV9btz"},"outputs":[],"source":["print(\"To resume training from a checkpoint, simply run the same training script. It will pick up from where it's left.\")\n","!tao mask_rcnn train -e $SPECS_DIR/maskrcnn_train_resnet50.txt \\\n","                     -d $EXPERIMENT_DIR/experiment_dir_unpruned\\\n","                     -k $KEY \\\n","                     --gpus 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1657354527137,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Uf_ErL3v9btz","outputId":"02455705-bd0b-4d59-9b75-fef3c684b313"},"outputs":[],"source":["print('Model for each epoch:')\n","print('---------------------')\n","!ls -ltrh $EXPERIMENT_DIR/experiment_dir_unpruned/"]},{"cell_type":"markdown","metadata":{"id":"GeQ0GmiS9btz"},"source":["## 5. Evaluate trained models <a class=\"anchor\" id=\"head-5\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1657354535465,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"w1rivlxb9btz","outputId":"1333f191-0134-430d-d50d-5ff2b91f0116"},"outputs":[],"source":["%env NUM_STEP=20000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173394,"status":"ok","timestamp":1657354710133,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"qQIc2DpO9btz","outputId":"83e1584a-8ffb-49bc-f524-604e4fde6d6e","scrolled":true},"outputs":[],"source":["!tao mask_rcnn evaluate -e $SPECS_DIR/maskrcnn_train_resnet50.txt \\\n","                        -m $EXPERIMENT_DIR/experiment_dir_unpruned/model.step-$NUM_STEP.tlt \\\n","                        -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"jJ6auUw89bt0"},"source":["## 6. Prune"]},{"cell_type":"markdown","metadata":{"id":"LYS-wXjO9bt0"},"source":["- Specify pre-trained model\n","- Equalization criterion (Only for resnets as they have element wise operations or MobileNets.)\n","- Threshold for pruning.\n","- A key to save and load the model\n","- Output directory to store the model\n","\n","Usually, you just need to adjust -pth (threshold) for accuracy and model size trade off. Higher pth gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold value depends on the dataset and the model. 0.4 in the block below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1657354710134,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"8MB5Am0K9bt0"},"outputs":[],"source":["# Create an output directory to save the pruned model.\n","!mkdir -p $EXPERIMENT_DIR/experiment_dir_pruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247736,"status":"ok","timestamp":1657354957863,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Vo9IcvWG9bt1","outputId":"17917769-bb6e-4a52-e7fe-5d20ac930e35"},"outputs":[],"source":["!tao mask_rcnn prune -m $EXPERIMENT_DIR/experiment_dir_unpruned/model.step-$NUM_STEP.tlt \\\n","                     -o $EXPERIMENT_DIR/experiment_dir_pruned \\\n","                     -pth 0.7 \\\n","                     -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1657354957863,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"srnhLp7Z9bt1","outputId":"d79e312e-43e1-4150-9616-253097301b69"},"outputs":[],"source":["!ls -l $EXPERIMENT_DIR/experiment_dir_pruned"]},{"cell_type":"markdown","metadata":{"id":"KLPxBwPk9bt1"},"source":["**Note** that you should retrain the pruned model first, as it cannot be directly used for evaluation or inference. "]},{"cell_type":"markdown","metadata":{"id":"BMFbux_J9bt2"},"source":["## 7. Retrain pruned models"]},{"cell_type":"markdown","metadata":{"id":"Bg2DGP-m9bt2"},"source":["- Model needs to be re-trained to bring back accuracy after pruning\n","- Specify re-training specification\n","- WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vN2v4lVc9bt2"},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/maskrcnn_retrain_resnet50.txt\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/maskrcnn_retrain_resnet50.txt\n","!cat $SPECS_DIR/maskrcnn_retrain_resnet50.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1657354469556,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"xHs4obTb9bt2"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_retrain"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8665,"status":"ok","timestamp":1657354966520,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"AJGiifIy9bt3","outputId":"70a03dbd-ba82-4302-8a03-eb46dc1b4cbb"},"outputs":[],"source":["!tao mask_rcnn train -e $SPECS_DIR/maskrcnn_retrain_resnet50.txt \\\n","                     -d $EXPERIMENT_DIR/experiment_dir_retrain\\\n","                     -k $KEY \\\n","                     --gpus 1"]},{"cell_type":"markdown","metadata":{"id":"q2rR7wIZ9bt3"},"source":["## 8. Evaluate retrained model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1657354478349,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"mvppaQjb9bt3","outputId":"7db89e0e-f8c6-44b0-c5ef-4042708a6b8a"},"outputs":[],"source":["%env NUM_STEP=25000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8684,"status":"ok","timestamp":1657354487029,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"a7wAaAt09bt4","outputId":"865d1986-7ee3-4e96-a641-d254f06a8740"},"outputs":[],"source":["!tao mask_rcnn evaluate -e $SPECS_DIR/maskrcnn_retrain_resnet50.txt \\\n","                        -m $EXPERIMENT_DIR/experiment_dir_retrain/model.step-$NUM_STEP.tlt \\\n","                        -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"sXp4jFSu9bt4"},"source":["## 9. Visualize inferences <a class=\"anchor\" id=\"head-9\"></a>\n","In this section, we run the `infer` tool to generate inferences on the trained models and visualize the results. The `infer` tool produces annotated image outputs. You can choose to draw bounding boxes only or draw both bboxes and masks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLvOMsks9bt4","scrolled":true},"outputs":[],"source":["# Running inference for detection on n images\n","!tao mask_rcnn inference -i $DATA_DIR/raw-data/test2017 \\\n","                         -o $EXPERIMENT_DIR/maskrcnn_annotated_images \\\n","                         -e $SPECS_DIR/maskrcnn_train_resnet50.txt \\\n","                         -m $EXPERIMENT_DIR/experiment_dir_unpruned/model.step-$NUM_STEP.tlt \\\n","                         -l $SPECS_DIR/coco_labels.txt \\\n","                         -t 0.5 \\\n","                         -k $KEY \\\n","                         --include_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ge5hsnU99bt4"},"outputs":[],"source":["# Simple grid visualizer\n","!pip3 install matplotlib==3.3.3\n","import matplotlib.pyplot as plt\n","import os\n","from math import ceil\n","valid_image_ext = ['.jpg']\n","\n","def visualize_images(image_dir, num_cols=4, num_images=10):\n","    output_path = os.path.join(os.environ['EXPERIMENT_DIR'], image_dir)\n","    num_rows = int(ceil(float(num_images) / float(num_cols)))\n","    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n","    f.tight_layout()\n","    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n","         if os.path.splitext(image)[1].lower() in valid_image_ext]\n","    for idx, img_path in enumerate(a[:num_images]):\n","        col_id = idx % num_cols\n","        row_id = idx // num_cols\n","        img = plt.imread(img_path)\n","        axarr[row_id, col_id].imshow(img) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03AP0N2l9bt4","scrolled":true},"outputs":[],"source":["# Visualizing the sample images.\n","OUTPUT_PATH = 'maskrcnn_annotated_images' # relative path from $EXPERIMENT_DIR.\n","COLS = 2 # number of columns in the visualizer grid.\n","IMAGES = 4 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["q2rR7wIZ9bt3"],"name":"maskrcnn.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
