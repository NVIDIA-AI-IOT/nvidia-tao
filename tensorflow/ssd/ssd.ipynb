{"cells":[{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Switch to CPU Instance (Advisable only for Non Colab-Pro instance)\n","\n","1. Switch to CPU Instance for until Step 2 for non GPU dependent tasks\n","2. This increases your time available for the GPU dependent tasks on a Colab instance\n","2. Change Runtime type to CPU by Runtime(Top Left tab)->Change Runtime Type->None(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"bihWWnrqjmA6"},"source":["# Object Detection using TAO SSD\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\">"]},{"cell_type":"markdown","metadata":{"id":"BPLxUkkXjmA8"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained resnet18 model and train a ResNet-18 SSD model on the KITTI dataset\n","* Prune the trained SSD model\n","* Retrain the pruned model to recover lost accuracy\n","* Export the pruned model\n","* Quantize the pruned model using QAT\n","* Run Inference on the trained model\n","* Export the pruned, quantized and retrained model to a .etlt file for deployment to DeepStream\n","\n","## Table of Contents\n","\n","This notebook shows an example usecase of SSD object detection using Train Adapt Optimize (TAO) Toolkit.\n","\n","0. [Set up env variables](#head-0)\n","1. [Prepare dataset and pre-trained model](#head-1) <br>\n","    1.1 [Download pre-trained model](#head-1-1) <br>\n","2. [Setup GPU environment](#head-2) <br>\n","    2.1 [Connect to GPU Instance](#head-2-1) <br>\n","    2.2 [Mounting Google drive](#head-2-2) <br>\n","    2.3 [Setup Python environment](#head-2-3) <br>\n","    2.4 [Reset env variables](#head-2-4) <br>\n","3. [Generate tfrecords](#head-3)\n","4. [Provide training specification](#head-4)\n","5. [Run TAO training](#head-5)\n","6. [Evaluate trained models](#head-6)\n","7. [Prune trained models](#head-7)\n","8. [Retrain pruned models](#head-8)\n","9. [Evaluate retrained model](#head-9)\n","10. [Visualize inferences](#head-10)"]},{"cell_type":"markdown","metadata":{"id":"NJqXJQOsjmA8"},"source":["## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n","\n","When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n","\n","*Note: Please make sure to remove any stray artifacts/files from the `$EXPERIMENT_DIR` or `$DATA_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1657353791123,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"ye0UdTi2jmA9","outputId":"a5e95bd1-f959-4a93-d2e3-389b563dff6b"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","%env GPU_INDEX=0\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","    raise(\"Error, enter the path of the colab notebooks repo correctly\")\n","%env EXPERIMENT_DIR=/results/ssd\n","%env DATA_DIR=/content/drive/MyDrive/kitti_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/ssd/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"7Css1XfjjmA_"},"source":["## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"GOyjuccHjmA_"},"source":[" We will be using the KITTI detection dataset for the tutorial. To find more details please visit\n"," http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d. Please download the KITTI detection images (http://www.cvlibs.net/download.php?file=data_object_image_2.zip) and labels (http://www.cvlibs.net/download.php?file=data_object_label_2.zip) to $DATA_DIR."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxW6nVNfjmBA"},"outputs":[],"source":["# Check the dataset is present\n","!if [ ! -f $DATA_DIR/data_object_image_2.zip ]; then echo 'Image zip file not found, please download.'; else echo 'Found Image zip file.';fi\n","!if [ ! -f $DATA_DIR/data_object_label_2.zip ]; then echo 'Label zip file not found, please download.'; else echo 'Found Labels zip file.';fi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vTvO973qjmBA"},"outputs":[],"source":["# unpack \n","!unzip -u $DATA_DIR/data_object_image_2.zip -d $DATA_DIR\n","!unzip -u $DATA_DIR/data_object_label_2.zip -d $DATA_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"li3_VPiujmBA"},"outputs":[],"source":["# verify\n","!ls -l $DATA_DIR/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VsG2uRBYjmBA"},"outputs":[],"source":["# Generate val dataset out of training dataset\n","!python3 $COLAB_NOTEBOOKS_PATH/tensorflow/ssd/generate_val_dataset.py --input_image_dir=$DATA_DIR/training/image_2 \\\n","                                   --input_label_dir=$DATA_DIR/training/label_2 \\\n","                                   --output_dir=$DATA_DIR/val"]},{"cell_type":"markdown","metadata":{"id":"QZ1Zhtu6jmBB"},"source":["### 1.1 Download pre-trained model <a class=\"anchor\" id=\"head-1-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"-KD7j8wgjmBB"},"source":["We will use NGC CLI to get the pre-trained models. For more details, go to [ngc.nvidia.com](ngc.nvidia.com) and click the SETUP on the navigation bar."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1526,"status":"ok","timestamp":1657353803178,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"uTJTjZ0RjmBB","outputId":"9819a354-1bf7-43c4-8dff-12d3220f2443"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/ngc_content/\n","%env CLI=ngccli_cat_linux.zip\n","!mkdir -p $LOCAL_PROJECT_DIR/ngccli\n","\n","# Remove any previously existing CLI installations\n","!rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4465,"status":"ok","timestamp":1657353807640,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Oq5ltFbXjmBC","outputId":"0ca508d3-8831-414d-e93e-a15117ffbc06"},"outputs":[],"source":["!ngc registry model list nvidia/tao/pretrained_object_detection:*"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1657353807641,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"c4Uugsa5jmBC"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/pretrained_resnet18/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16248,"status":"ok","timestamp":1657353823884,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"fktXa4j5jmBC","outputId":"89af23a4-84f1-4e11-b657-5e86711800b7"},"outputs":[],"source":["# Pull pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/pretrained_object_detection:resnet18 --dest $EXPERIMENT_DIR/pretrained_resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1657353823885,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"VsMalhpDjmBC","outputId":"9500e57d-812f-498d-e890-0a2fb9ff8c37"},"outputs":[],"source":["print(\"Check that model is downloaded into dir.\")\n","!ls -l $EXPERIMENT_DIR/pretrained_resnet18/pretrained_object_detection_vresnet18"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 2. Setup GPU environment <a class=\"anchor\" id=\"head-2\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"k7Cx1_lMded7"},"source":["### 2.1 Connect to GPU Instance <a class=\"anchor\" id=\"head-2-1\"></a>\n","\n","1. Move any data saved to the Colab Instance storage to Google Drive  \n","2. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","3.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yl8BoM0Jhzh9"},"source":["### 2.2 Mounting Google drive <a class=\"anchor\" id=\"head-2-2\"></a>\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vk2m-N4Nh0Sd"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 2.3 Setup Python environment <a class=\"anchor\" id=\"head-2-3\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["#FIXME\n","%env GENERAL_WHL_PATH=/content/drive/MyDrive/tf/general_whl\n","#FIXME\n","%env CODEBASE_WHL_PATH=/content/drive/MyDrive/tf/codebase_whl\n","\n","if os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]) and os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]):\n","    if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","        os.environ[\"bash_script\"] = \"setup_env.sh\"\n","    else:\n","        os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","    !sed -i \"s|PATH_TO_GENERAL_WHL|$GENERAL_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","    !sed -i \"s|PATH_TO_CODEBASE_WHL|$CODEBASE_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","    !sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","\n","    !sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","else:\n","    raise(\"Error, enter the whl paths correctly\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","if os.environ.get(\"PYTHONPATH\",\"\") == \"\":\n","    os.environ[\"PYTHONPATH\"] = \"\"\n","os.environ[\"PYTHONPATH\"]+=\":/opt/nvidia/\"\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    os.environ[\"PYTHONPATH\"]+=\":/usr/local/lib/python3.6/dist-packages/third_party/nvml\"\n","else:\n","    os.environ[\"PYTHONPATH\"]+=\":/home_duplicate/rarunachalam/miniconda3/envs/tf_py_36/lib/python3.6/site-packages/third_party/nvml\" # FIX MINICONDA PATH"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reset NVIDIA-DALI version for SSD\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    !python3.6 -m pip uninstall nvidia-dali-nvtf-plugin -y\n","    !python3.6 -m pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda110==0.31.0\n","    !python3.6 -m pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-tf-plugin-cuda110==0.31.0"]},{"cell_type":"markdown","metadata":{"id":"Fl8fSfXseED3"},"source":["### 2.4 Reset env variables <a class=\"anchor\" id=\"head-2-4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_T2vBdzeIcO"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","%env NUM_GPUS=1\n","%env GPU_INDEX=0\n","\n","# Change the paths according to your directory structure, these are just examples\n","%env COLAB_NOTEBOOKS_PATH=/home_duplicate/rarunachalam/colab_notebooks\n","if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","    raise(\"Error, enter the path of the colab notebooks repo correctly\")\n","%env EXPERIMENT_DIR=/results/ssd\n","%env DATA_DIR=/content/drive/MyDrive/kitti_data/\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/ssd/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Generate tfrecords <a class=\"anchor\" id=\"head-3\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NXxJ4-7EjmBA"},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/ssd_tfrecords_kitti_train.txt\n","print(\"TFRecords conversion spec file:\")\n","!cat $SPECS_DIR/ssd_tfrecords_kitti_train.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49380,"status":"ok","timestamp":1657355391590,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"sFeAnLb3jmBA","outputId":"e94f3e83-6a37-412d-ecd1-599d670a1e69"},"outputs":[],"source":["# Creating a new directory for the output tfrecords dump.\n","print(\"Converting the training set to TFRecords.\")\n","!mkdir -p $DATA_DIR/tfrecords && rm -rf $DATA_DIR/tfrecords/*\n","!tao ssd dataset_convert \\\n","         -d $SPECS_DIR/ssd_tfrecords_kitti_train.txt \\\n","         -o $DATA_DIR/tfrecords/kitti_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1657353801656,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"hoRSysB8jmBB","outputId":"09951e98-51bf-4701-81ad-a3ba0d58e407"},"outputs":[],"source":["!ls -rlt $DATA_DIR/tfrecords/"]},{"cell_type":"markdown","metadata":{"id":"WLR-1tuNjmBC"},"source":["## 4. Provide training specification <a class=\"anchor\" id=\"head-4\"></a>\n","* Dataset for the train datasets\n","    * In order to use the newly generated dataset, update the dataset_config parameter in the spec file at `$SPECS_DIR/ssd_train_resnet18_kitti.txt` \n","* Augmentation parameters for on the fly data augmentation\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n","* Whether to use quantization aware training (QAT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qdkP0X5djmBC"},"outputs":[],"source":["# To enable QAT training on sample spec file, uncomment following lines\n","# !sed -i \"s/enable_qat: false/enable_qat: true/g\" $SPECS_DIR/ssd_train_resnet18_kitti.txt\n","# !sed -i \"s/enable_qat: false/enable_qat: true/g\" $SPECS_DIR/ssd_retrain_resnet18_kitti.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A0r2pEtgjmBC"},"outputs":[],"source":["# By default, the sample spec file disables QAT training. You can force non-QAT training by running lines below\n","# !sed -i \"s/enable_qat: true/enable_qat: false/g\" $SPECS_DIR/ssd_train_resnet18_kitti.txt\n","# !sed -i \"s/enable_qat: true/enable_qat: false/g\" $SPECS_DIR/ssd_retrain_resnet18_kitti.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1657353824204,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"tuNXvEXIjmBD","outputId":"f476d455-1083-4d57-b1c6-3b889f5b05eb"},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/ssd_train_resnet18_kitti.txt\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/ssd_train_resnet18_kitti.txt\n","!cat $SPECS_DIR/ssd_train_resnet18_kitti.txt"]},{"cell_type":"markdown","metadata":{"id":"DrBlpkKpjmBD"},"source":["## 5. Run TAO training <a class=\"anchor\" id=\"head-5\"></a>\n","* Provide the sample spec file and the output directory location for models\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1657353824205,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"YrhPhqlijmBD"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_unpruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166631,"status":"ok","timestamp":1657353990818,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"qa3ZQggijmBE","outputId":"7515dda1-f25b-43d8-9c3d-db97b7fd36b6","scrolled":true},"outputs":[],"source":["print(\"To run with multigpu, please change --gpus based on the number of available GPUs in your machine.\")\n","!tao ssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n","               -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n","               -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n","               -k $KEY \\\n","               -m $EXPERIMENT_DIR/pretrained_resnet18/pretrained_object_detection_vresnet18/resnet_18.hdf5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7u6qujV0jmBE"},"outputs":[],"source":["print(\"To resume from checkpoint, please uncomment and run this instead. Change last two arguments accordingly.\")\n","# !tao ssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n","#                -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n","#                -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n","#                -k $KEY \\\n","#                -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_001.tlt \\\n","#                --initial_epoch 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j-IWYxtXjmBE"},"outputs":[],"source":["print('Model for each epoch:')\n","print('---------------------')\n","!ls -ltrh $EXPERIMENT_DIR/experiment_dir_unpruned/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1657353990819,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"hiieRHDnjmBF","outputId":"66773cb7-f304-44e3-8354-0457b83053b4"},"outputs":[],"source":["# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n","!cat $EXPERIMENT_DIR/experiment_dir_unpruned/ssd_training_log_resnet18.csv\n","%env EPOCH=010"]},{"cell_type":"markdown","metadata":{"id":"KOpridJOjmBF"},"source":["## 6. Evaluate trained models <a class=\"anchor\" id=\"head-6\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194470,"status":"ok","timestamp":1657354185278,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"uKgBW8BcjmBF","outputId":"4c5170d1-2b52-4caa-9e73-4ea018efe9bd","scrolled":true},"outputs":[],"source":["!tao ssd evaluate --gpu_index=$GPU_INDEX \\\n","                  -e $SPECS_DIR/ssd_train_resnet18_kitti.txt \\\n","                  -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n","                  -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"6n9rR-RTjmBG"},"source":["## 7. Prune trained models <a class=\"anchor\" id=\"head-7\"></a>\n","* Specify pre-trained model\n","* Equalization criterion (`Only for resnets as they have element wise operations or MobileNets.`)\n","* Threshold for pruning.\n","* A key to save and load the model\n","* Output directory to store the model\n","\n","Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold value depends on the dataset and the model. `0.5` in the block below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1657354185279,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"jc4bFeCfjmBG"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_pruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60962,"status":"ok","timestamp":1657354246235,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"rYIHXWuvjmBG","outputId":"a7c8d253-d255-4482-f507-4113dab76d07","scrolled":true},"outputs":[],"source":["!tao ssd prune --gpu_index=$GPU_INDEX \\\n","               -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n","               -o $EXPERIMENT_DIR/experiment_dir_pruned/ssd_resnet18_pruned.tlt \\\n","               -eq intersection \\\n","               -pth 0.1 \\\n","               -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1657354246236,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"RTujmW7LjmBG","outputId":"4c6d8b34-bc1a-4e92-e28a-9431a980e4a6"},"outputs":[],"source":["!ls -rlt $EXPERIMENT_DIR/experiment_dir_pruned/"]},{"cell_type":"markdown","metadata":{"id":"n4nEXJG0jmBH"},"source":["## 8. Retrain pruned models <a class=\"anchor\" id=\"head-8\"></a>\n","* Model needs to be re-trained to bring back accuracy after pruning\n","* Specify re-training specification\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1657354246236,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Z51so1ShjmBH","outputId":"1cdf2f62-c937-47db-fe48-606a3d4a5011","scrolled":true},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/ssd_retrain_resnet18_kitti.txt\n","!sed -i \"s|EXPERIMENT_DIR_PATH|$EXPERIMENT_DIR/|g\" $SPECS_DIR/ssd_retrain_resnet18_kitti.txt\n","# Printing the retrain spec file. \n","# Here we have updated the spec file to include the newly pruned model as a pretrained weights.\n","!cat $SPECS_DIR/ssd_retrain_resnet18_kitti.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":247,"status":"ok","timestamp":1657354246476,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"T1ErduKSjmBH"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_retrain"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":654589,"status":"ok","timestamp":1657354901062,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"WGrsXx9TjmBH","outputId":"87846c3a-5077-4f4a-c6a8-b044526a9c76"},"outputs":[],"source":["# Retraining using the pruned model as pretrained weights \n","!tao ssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n","               -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n","               -r $EXPERIMENT_DIR/experiment_dir_retrain \\\n","               -m $EXPERIMENT_DIR/experiment_dir_pruned/ssd_resnet18_pruned.tlt \\\n","               -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":348,"status":"ok","timestamp":1657354901394,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"8c98BrCSjmBI","outputId":"e076e342-8739-41c0-82df-941aa42198cd"},"outputs":[],"source":["# Listing the newly retrained model.\n","!ls -rlt $EXPERIMENT_DIR/experiment_dir_retrain/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1657354901395,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"WaDE0B3XjmBI","outputId":"0f68807b-efb6-45d4-d966-1a08bf07f808"},"outputs":[],"source":["# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n","!cat $EXPERIMENT_DIR/experiment_dir_retrain/ssd_training_log_resnet18.csv\n","%env EPOCH=080"]},{"cell_type":"markdown","metadata":{"id":"iHkBcw7LjmBI"},"source":["## 9. Evaluate retrained model <a class=\"anchor\" id=\"head-9\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173444,"status":"ok","timestamp":1657355075654,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"jImKa-GgjmBI","outputId":"cf84f617-8b6b-422d-ecc2-a7fef8db516c"},"outputs":[],"source":["!tao ssd evaluate --gpu_index=$GPU_INDEX \\\n","                  -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n","                  -m $EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n","                  -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"0_JKMIsUjmBI"},"source":["## 10. Visualize inferences <a class=\"anchor\" id=\"head-10\"></a>\n","In this section, we run the `infer` tool to generate inferences on the trained models and visualize the results."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6924,"status":"ok","timestamp":1657355082561,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"5yvQblo9jmBI"},"outputs":[],"source":["# Copy some test images\n","!mkdir -p $DATA_DIR/test_samples\n","!cp $DATA_DIR/testing/image_2/000* $DATA_DIR/test_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174371,"status":"ok","timestamp":1657355256915,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"qFQmEPWHjmBI","outputId":"4803dffa-71ea-4291-f43d-9ca29aa27214"},"outputs":[],"source":["# Running inference for detection on n images\n","!tao ssd inference --gpu_index=$GPU_INDEX -i $DATA_DIR/test_samples \\\n","                   -o $EXPERIMENT_DIR/ssd_infer_images \\\n","                   -e $SPECS_DIR/ssd_retrain_resnet18_kitti.txt \\\n","                   -m $EXPERIMENT_DIR/experiment_dir_retrain/weights/ssd_resnet18_epoch_$EPOCH.tlt \\\n","                   -l $EXPERIMENT_DIR/ssd_infer_labels \\\n","                   -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"1zYok3phjmBI"},"source":["The `tao` inference tool produces two outputs. \n","1. Overlain images in `$EXPERIMENT_DIR/ssd_infer_images`\n","2. Frame by frame bbox labels in kitti format located in `$EXPERIMENT_DIR/ssd_infer_labels`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"executionInfo":{"elapsed":18362,"status":"ok","timestamp":1657355275261,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"7X1Rava8jmBI","outputId":"a778a9c7-6ffe-4d5f-ac13-76a4ca1c3acb"},"outputs":[],"source":["# Simple grid visualizer\n","import matplotlib.pyplot as plt\n","import os\n","from math import ceil\n","valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n","\n","def visualize_images(image_dir, num_cols=4, num_images=10):\n","    output_path = os.path.join(os.environ['EXPERIMENT_DIR'], image_dir)\n","    num_rows = int(ceil(float(num_images) / float(num_cols)))\n","    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n","    f.tight_layout()\n","    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n","         if os.path.splitext(image)[1].lower() in valid_image_ext]\n","    for idx, img_path in enumerate(a[:num_images]):\n","        col_id = idx % num_cols\n","        row_id = idx // num_cols\n","        img = plt.imread(img_path)\n","        axarr[row_id, col_id].imshow(img) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":505,"output_embedded_package_id":"16jQPdMjAHhCv5A_VkNYP4ey7MvNB_09Y"},"executionInfo":{"elapsed":66736,"status":"ok","timestamp":1657355342224,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"H48lVM1mjmBJ","outputId":"8111c6b2-34cf-486d-a06b-c31ec8f9ce98"},"outputs":[],"source":["# Visualizing the sample images.\n","OUTPUT_PATH = 'ssd_infer_images' # relative path from $EXPERIMENT_DIR.\n","COLS = 3 # number of columns in the visualizer grid.\n","IMAGES = 9 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"ssd.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
