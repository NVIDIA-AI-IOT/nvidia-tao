{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Get the TensorRT tar file before running this Notebook\n","\n","1. Visit https://developer.nvidia.com/tensorrt\n","2. Clicking `Download now` from step one directs you to https://developer.nvidia.com/nvidia-tensorrt-download where you have to Login/Join Now for Nvidia Developer Program Membership\n","3. Now, in the download page: Choose TensorRT 8 in available versions\n","4. Agree to Terms and Conditions\n","5. Click on TensorRT 8.5 GA to expand the available options\n","6. Click on 'TensorRT 8.5 GA for Linux x86_64 and CUDA 11.0, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6, 11.7 and 11.8 TAR Package' to dowload the TAR file\n","7. Upload the the tar file to your Google Drive"]},{"cell_type":"markdown","metadata":{"id":"LGLBrzF8hKgS"},"source":["## Connect to GPU Instance\n","\n","1. Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","1. Then click on Connect (Top Right)"]},{"cell_type":"markdown","metadata":{"id":"SjpjyNg5c2V9"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18056,"status":"ok","timestamp":1658620835786,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"EvUVkYw0hzqG","outputId":"a8f580a7-bd55-4a9c-8620-c0795752fbc9"},"outputs":[],"source":["import sys\n","if 'google.colab' in sys.modules:\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","else:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"g2uGuU_OioRo"},"source":["# Object Detection using TAO DSSD\n","\n","Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n","\n","Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n","\n","<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png\" width=\"1080\">"]},{"cell_type":"markdown","metadata":{"id":"4KxgRpNgioRr"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","\n","* Take a pretrained resnet18 model and train a ResNet-18 DSSD model on the KITTI dataset\n","* Prune the trained DSSD model\n","* Retrain the pruned model to recover lost accuracy\n","* Export the pruned model\n","* Quantize the pruned model using QAT\n","* Run Inference on the trained model\n","* Export the pruned, quantized and retrained model to a .etlt file for deployment to DeepStream\n","\n","## Table of Contents\n","\n","This notebook shows an example usecase of DSSD object detection using Train Adapt Optimize (TAO) Toolkit.\n","\n","1. [Set up env variables](#head-1)\n","2. [Prepare dataset and pre-trained model](#head-2) <br>\n","    2.1 [Download pre-trained model](#head-2-1) <br>\n","3. [Setup GPU environment](#head-3) <br>\n","    3.1 [Setup Python environment](#head-3-1) <br>\n","3. [Provide training specification](#head-3)\n","4. [Run TAO training](#head-4)\n","5. [Evaluate trained models](#head-5)\n","6. [Prune trained models](#head-6)\n","7. [Retrain pruned models](#head-7)\n","8. [Evaluate retrained model](#head-8)\n","9. [Visualize inferences](#head-9)\n","10. [Model Export](#head-10)\n","11. [Verify deployed model](#head-11)"]},{"cell_type":"markdown","metadata":{"id":"3sXyuuRRioRs"},"source":["#### Note\n","1. This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` accordingly\n","1. This notebook uses KITTI dataset by default, which should be around ~12 GB. If you are limited by Google-Drive storage, we recommend to:\n","\n","    i. Download the dataset onto the local system\n","\n","    ii. Run the utility script at $COLAB_NOTEBOOKS/tensorflow/utils/generate_kitti_subset.py in your local system\n","\n","    iii. This generates a subset of kitti dataset with number of sample images you wish for\n","\n","    iv. Upload this subset onto Google Drive\n","\n","1. Using the default config/spec file provided in this notebook, each weight file size of dssd created during training will be ~157 MB\n","\n","## 1. Set up env variables and set FIXME parameters <a class=\"anchor\" id=\"head-1\"></a>\n","\n","*Note: This notebook currently is by default set up to run training using 1 GPU. To use more GPU's please update the env variable `$NUM_GPUS` and `$GPU_INDEX` accordingly*\n","\n","#### FIXME\n","1. NUM_GPUS - set this to <= number of GPU's availble on the instance\n","1. GPU_INDEX - set to to the indices of the GPU available on the instance\n","1. COLAB_NOTEBOOKS_PATH - for Google Colab environment, set this path where you want to clone the repo to; for local system environment, set this path to the already cloned repo\n","1. EXPERIMENT_DIR - set this path to a folder location where pretrained models, checkpoints and log files during different model actions will be saved\n","1. delete_existing_experiments - set to True to remove existing pretrained models, checkpoints and log files of a previous experiment\n","1. DATA_DIR - set this path to a folder location where you want to dataset to be present\n","1. delete_existing_data - set this to True to remove existing preprocessed and original data\n","1. trt_tar_path - set this path of the uploaded TensorRT tar.gz file after browser download\n","1. trt_untar_folder_path - set to path of the folder where the TensoRT tar.gz file has to be untarred into\n","1. trt_version - set this to the version of TRT you have downloaded"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235,"status":"ok","timestamp":1657215838993,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"edxytcC9ioRt","outputId":"b484a253-bd95-4a27-f557-16a47dcb0a9a"},"outputs":[],"source":["# Setting up env variables for cleaner command line commands.\n","import os\n","\n","%env TAO_DOCKER_DISABLE=1\n","\n","%env KEY=nvidia_tlt\n","#FIXME1\n","%env NUM_GPUS=1\n","#FIXME2\n","%env GPU_INDEX=0\n","\n","#FIXME3\n","%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive/nvidia-tao\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    if not os.path.exists(os.path.join(os.environ[\"COLAB_NOTEBOOKS_PATH\"])):\n","\n","      !git clone https://github.com/NVIDIA-AI-IOT/nvidia-tao.git $COLAB_NOTEBOOKS_PATH\n","else:\n","    if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","        raise Exception(\"Error, enter the path of the colab notebooks repo correctly\")\n","\n","#FIXME4\n","%env EXPERIMENT_DIR=/content/drive/MyDrive/results/dssd\n","#FIXME5\n","delete_existing_experiments = True\n","#FIXME6\n","%env DATA_DIR=/content/drive/MyDrive/kitti_data/\n","#FIXME7\n","delete_existing_data = False\n","\n","if delete_existing_experiments:\n","    !sudo rm -rf $EXPERIMENT_DIR\n","if delete_existing_data:\n","    !sudo rm -rf $DATA_DIR\n","\n","SPECS_DIR=f\"{os.environ['COLAB_NOTEBOOKS_PATH']}/tensorflow/dssd/specs\"\n","%env SPECS_DIR={SPECS_DIR}\n","# Showing list of specification files.\n","!ls -rlt $SPECS_DIR\n","\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","!sudo mkdir -p $EXPERIMENT_DIR && sudo chmod -R 777 $EXPERIMENT_DIR"]},{"cell_type":"markdown","metadata":{"id":"7hJlUyZLioRy"},"source":["## 2. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-2\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["We will be using NVIDIA created Synthetic Object detection data based on KITTI dataset format in this notebook. To find more details about kitti format, please visit [here](https://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d).\n","\n","**If using custom dataset; it should follow this dataset structure**\n","```\n","$DATA_DIR/training\n","├── images\n","│   ├── image_name_1.jpg\n","│   ├── image_name_2.jpg\n","|   ├── ...\n","└── labels\n","    ├── image_name_1.txt\n","    ├── image_name_2.txt\n","    ├── ...\n","$DATA_DIR/val\n","├── images\n","│   ├── image_name_5.jpg\n","│   ├── image_name_6.jpg\n","|   ├── ...\n","└── labels\n","    ├── image_name_5.txt\n","    ├── image_name_6.txt\n","    ├── ...\n","```\n","The file name should be same for images and labels folders"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### 2.1 Download the dataset <a class=\"anchor\" id=\"head-2-1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python3 -m pip install awscli\n","!aws s3 cp --no-sign-request s3://tao-object-detection-synthetic-dataset/tao_od_synthetic_train.tar.gz $DATA_DIR/\n","!aws s3 cp --no-sign-request s3://tao-object-detection-synthetic-dataset/tao_od_synthetic_val.tar.gz $DATA_DIR/\n","\n","!mkdir -p $DATA_DIR/train/ && rm -rf $DATA_DIR/train/*\n","!mkdir -p $DATA_DIR/val/ && rm -rf $DATA_DIR/val/*\n","\n","!tar -xzf $DATA_DIR/tao_od_synthetic_train.tar.gz -C $DATA_DIR/train/\n","!tar -xzf $DATA_DIR/tao_od_synthetic_val.tar.gz -C $DATA_DIR/val/"]},{"cell_type":"markdown","metadata":{"id":"yzxMVeO4ioR1"},"source":["### 2.1 Download pre-trained model <a class=\"anchor\" id=\"head-2-1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"od49hQomioR1"},"source":["We will use NGC CLI to get the pre-trained models. For more details, go to [ngc.nvidia.com](ngc.nvidia.com) and click the SETUP on the navigation bar."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2030,"status":"ok","timestamp":1657216691173,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Vs7NCnu5ioR1","outputId":"8254116b-aa95-4f97-d165-35a40fe610c5"},"outputs":[],"source":["# Installing NGC CLI on the local machine.\n","## Download and install\n","%env LOCAL_PROJECT_DIR=/ngc_content/\n","%env CLI=ngccli_cat_linux.zip\n","!sudo mkdir -p $LOCAL_PROJECT_DIR/ngccli && sudo chmod -R 777 $LOCAL_PROJECT_DIR\n","\n","# Remove any previously existing CLI installations\n","!sudo rm -rf $LOCAL_PROJECT_DIR/ngccli/*\n","!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $LOCAL_PROJECT_DIR/ngccli\n","!unzip -u -q \"$LOCAL_PROJECT_DIR/ngccli/$CLI\" -d $LOCAL_PROJECT_DIR/ngccli/\n","!rm $LOCAL_PROJECT_DIR/ngccli/*.zip \n","os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"LOCAL_PROJECT_DIR\", \"\"), os.getenv(\"PATH\", \"\"))\n","!cp /usr/lib/x86_64-linux-gnu/libstdc++.so.6 $LOCAL_PROJECT_DIR/ngccli/ngc-cli/libstdc++.so.6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2086,"status":"ok","timestamp":1657216693252,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"ByEYZaP4ioR1","outputId":"336eb9c3-d57b-4e44-fff8-6b61bf8d1081"},"outputs":[],"source":["!ngc registry model list nvidia/tao/pretrained_object_detection:*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTJABK5AioR2"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/pretrained_resnet18/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7208,"status":"ok","timestamp":1657216700746,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"3Yno8U5DioR2","outputId":"8b94f188-53f5-4a05-853f-b44ed073dbee"},"outputs":[],"source":["# Pull pretrained model from NGC\n","!ngc registry model download-version nvidia/tao/pretrained_object_detection:resnet18 --dest $EXPERIMENT_DIR/pretrained_resnet18"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234,"status":"ok","timestamp":1657216700977,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Rhk40eJMioR2","outputId":"c88657a7-f1ee-4dba-9723-7c8f51bdb4a1"},"outputs":[],"source":["print(\"Check that model is downloaded into dir.\")\n","!ls -l $EXPERIMENT_DIR/pretrained_resnet18/pretrained_object_detection_vresnet18"]},{"cell_type":"markdown","metadata":{"id":"_26rCobXcri1"},"source":["## 3. Setup GPU environment <a class=\"anchor\" id=\"head-3\"></a>\n"]},{"cell_type":"markdown","metadata":{"id":"MBV_YWiTc_KM"},"source":["### 3.1 Setup Python environment <a class=\"anchor\" id=\"head-3-1\"></a>\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2Xygw-y8fjm"},"outputs":[],"source":["# FIXME 8: set this path of the uploaded TensorRT tar.gz file after browser download\n","trt_tar_path=\"/content/drive/MyDrive/TensorRT-8.5.1.7.Linux.x86_64-gnu.cuda-11.8.cudnn8.6.tar.gz\"\n","\n","import os\n","if not os.path.exists(trt_tar_path):\n","  raise Exception(\"TAR file not found in the provided path\")\n","\n","# FIXME 9: set to path of the folder where the TensoRT tar.gz file has to be untarred into\n","%env trt_untar_folder_path=/content/trt_untar\n","# FIXME 10: set this to the version of TRT you have downloaded\n","%env trt_version=8.5.1.7\n","\n","!mkdir -p $trt_untar_folder_path\n","\n","import os\n","\n","untar = True\n","for fname in os.listdir(os.environ.get(\"trt_untar_folder_path\", None)):\n","  if fname.startswith(\"TensorRT-\"+os.environ.get(\"trt_version\")) and not fname.endswith(\".tar.gz\"):\n","    untar = False\n","\n","if untar:\n","  !tar -xzf $trt_tar_path -C /content/trt_untar"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    os.environ[\"bash_script\"] = \"setup_env.sh\"\n","else:\n","    os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","!sed -i \"s|PATH_TO_TRT|$trt_untar_folder_path|g\"$COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","!sed -i \"s|TRT_VERSION|$trt_version|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","!sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script\n","\n","!sh $COLAB_NOTEBOOKS_PATH/tensorflow/$bash_script"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Generate tfrecords <a class=\"anchor\" id=\"head-4\"></a>\n","* Create the tfrecords on the dataset split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1657216480564,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"XIq1ozybioR0","outputId":"8c8308b8-b44d-4dd7-9605-3b11980926f7"},"outputs":[],"source":["print(\"TFRecords conversion spec file:\")\n","!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/dssd_tfrecords_kitti_train.txt\n","!cat $SPECS_DIR/dssd_tfrecords_kitti_train.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":72471,"status":"ok","timestamp":1657216689146,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"egGmwc9eioR0","outputId":"4e1c002b-d82b-4fcf-f42e-dff6f61a2e05"},"outputs":[],"source":["# Creating a new directory for the output tfrecords dump.\n","print(\"Converting the training set to TFRecords.\")\n","!mkdir -p $DATA_DIR/tfrecords && sudo rm -rf $DATA_DIR/tfrecords/*\n","!tao model dssd dataset_convert \\\n","          -d $SPECS_DIR/dssd_tfrecords_kitti_train.txt \\\n","          -o $DATA_DIR/tfrecords/kitti_train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1657216689147,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"BReDMNySioR1","outputId":"6a02fe68-07b6-48f1-bf5e-4085c67da50a"},"outputs":[],"source":["!ls -rlt $DATA_DIR/tfrecords/"]},{"cell_type":"markdown","metadata":{"id":"vm5mXwoPioR2"},"source":["## 5. Provide training specification <a class=\"anchor\" id=\"head-5\"></a>\n","* Dataset for the train datasets\n","    * In order to use the newly generated dataset, update the dataset_config parameter in the spec file at `$SPECS_DIR/dssd_train_resnet18_kitti.txt` \n","* Augmentation parameters for on the fly data augmentation\n","* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc.\n","* Whether to use quantization aware training (QAT)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rfUJ5xwuioR2"},"outputs":[],"source":["# To enable QAT training on sample spec file, uncomment following lines\n","# !sed -i \"s/enable_qat: false/enable_qat: true/g\" $SPECS_DIR/dssd_train_resnet18_kitti.txt\n","# !sed -i \"s/enable_qat: false/enable_qat: true/g\" $SPECS_DIR/dssd_retrain_resnet18_kitti.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-awRcUdhioR2"},"outputs":[],"source":["# By default, the sample spec file disables QAT training. You can force non-QAT training by running lines below\n","# !sed -i \"s/enable_qat: true/enable_qat: false/g\" $SPECS_DIR/dssd_train_resnet18_kitti.txt\n","# !sed -i \"s/enable_qat: true/enable_qat: false/g\" $SPECS_DIR/dssd_retrain_resnet18_kitti.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1657216778573,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"GgZUJxhqioR3","outputId":"a792b650-401f-4cce-e486-7dedf5eaa46c"},"outputs":[],"source":["!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/dssd_train_resnet18_kitti.txt\n","!cat $SPECS_DIR/dssd_train_resnet18_kitti.txt"]},{"cell_type":"markdown","metadata":{"id":"O_184X2eioR3"},"source":["## 6. Run TAO training <a class=\"anchor\" id=\"head-6\"></a>\n","* Provide the sample spec file and the output directory location for models\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTx9TUSVioR3"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_unpruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":480668,"status":"ok","timestamp":1657219300078,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"aNUbpcgFioR4","outputId":"e3e21a4e-d426-401a-ec12-728f6e0beadc","scrolled":true},"outputs":[],"source":["print(\"To run with multigpu, please change --gpus based on the number of available GPUs in your machine.\")\n","!tao model dssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n","                -e $SPECS_DIR/dssd_train_resnet18_kitti.txt \\\n","                -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n","                -k $KEY \\\n","                -m $EXPERIMENT_DIR/pretrained_resnet18/pretrained_object_detection_vresnet18/resnet_18.hdf5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USzxJ-vAioR4"},"outputs":[],"source":["print(\"To resume from checkpoint, please uncomment and run this instead. Change last two arguments accordingly.\")\n","# !tao model dssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n","#                 -e $SPECS_DIR/dssd_train_resnet18_kitti.txt \\\n","#                 -r $EXPERIMENT_DIR/experiment_dir_unpruned \\\n","#                 -k $KEY \\\n","#                 -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/dssd_resnet18_epoch_001.tlt \\\n","#                 --initial_epoch 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":218,"status":"ok","timestamp":1657217435912,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"AdSMOUMlioR4","outputId":"c82cb5b9-1510-428b-d23d-43c75d18ebd7"},"outputs":[],"source":["print('Model for each epoch:')\n","print('---------------------')\n","!ls -ltrh $EXPERIMENT_DIR/experiment_dir_unpruned/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1657217439747,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"jf2nbHfSioR5","outputId":"b330e05d-cf57-45b2-d10d-f0c56a3ae61d"},"outputs":[],"source":["# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n","!cat $EXPERIMENT_DIR/experiment_dir_unpruned/dssd_training_log_resnet18.csv\n","%env EPOCH=080"]},{"cell_type":"markdown","metadata":{"id":"g2tQal0aioR5"},"source":["## 7. Evaluate trained models <a class=\"anchor\" id=\"head-7\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":387403,"status":"ok","timestamp":1657217836924,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"PxfXn82YioR6","outputId":"82da3ad2-d52d-4cfa-d43f-6d2289217cfc","scrolled":true},"outputs":[],"source":["!tao model dssd evaluate --gpu_index=$GPU_INDEX \\\n","                   -e $SPECS_DIR/dssd_train_resnet18_kitti.txt \\\n","                   -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n","                   -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"QerCwV08ioR6"},"source":["## 8. Prune trained models <a class=\"anchor\" id=\"head-8\"></a>\n","* Specify pre-trained model\n","* Equalization criterion (`Only for resnets as they have element wise operations or MobileNets.`)\n","* Threshold for pruning.\n","* A key to save and load the model\n","* Output directory to store the model\n","\n","Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold value depends on the dataset and the model. `0.5` in the block below is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5dfwiGDioR6"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_pruned"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227032,"status":"ok","timestamp":1657218063952,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"Baao_w77ioR6","outputId":"7de45677-626f-4987-d4ba-9b662b347219","scrolled":true},"outputs":[],"source":["!tao model dssd prune --gpu_index=$GPU_INDEX \\\n","                -m $EXPERIMENT_DIR/experiment_dir_unpruned/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n","                -o $EXPERIMENT_DIR/experiment_dir_pruned/dssd_resnet18_pruned.tlt \\\n","                -eq intersection \\\n","                -pth 0.1 \\\n","                -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1657218063953,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"JPZBiOQfioR7","outputId":"20a19dac-eb3e-404c-ec32-1909f9c572f9"},"outputs":[],"source":["!ls -rlt $EXPERIMENT_DIR/experiment_dir_pruned/"]},{"cell_type":"markdown","metadata":{"id":"5TsGZuI1ioR7"},"source":["## 9. Retrain pruned models <a class=\"anchor\" id=\"head-9\"></a>\n","* Model needs to be re-trained to bring back accuracy after pruning\n","* Specify re-training specification\n","* WARNING: training will take several hours or one day to complete"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1657218144907,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"QhIoWzqKioR7","outputId":"10bf195a-e8f4-4056-fd14-e13dd9d1f2b3","scrolled":true},"outputs":[],"source":["# Printing the retrain spec file. \n","# Here we have updated the spec file to include the newly pruned model as a pretrained weights.\n","!sed -i \"s|TAO_DATA_PATH|$DATA_DIR/|g\" $SPECS_DIR/dssd_retrain_resnet18_kitti.txt\n","!cat $SPECS_DIR/dssd_retrain_resnet18_kitti.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9hdYqTBcioR8"},"outputs":[],"source":["!mkdir -p $EXPERIMENT_DIR/experiment_dir_retrain"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2341908,"status":"ok","timestamp":1657221695805,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"UCk2trYvioR8","outputId":"a76cc547-c9f3-4666-ceba-761f374f02ee"},"outputs":[],"source":["# Retraining using the pruned model as pretrained weights \n","!tao model dssd train --gpus 1 --gpu_index=$GPU_INDEX \\\n","                -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n","                -r $EXPERIMENT_DIR/experiment_dir_retrain \\\n","                -m $EXPERIMENT_DIR/experiment_dir_pruned/dssd_resnet18_pruned.tlt \\\n","                -k $KEY"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1657221695807,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"hoTu20FXioR8","outputId":"74dc5921-6b3e-4bb1-c61a-fed46e56b417"},"outputs":[],"source":["# Listing the newly retrained model.\n","!ls -rlt $EXPERIMENT_DIR/experiment_dir_retrain/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":438,"status":"ok","timestamp":1657221696238,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"_JnJtPjxioR8","outputId":"a6be66a6-a8fe-442b-ba15-60902a0dd58a"},"outputs":[],"source":["# Now check the evaluation stats in the csv file and pick the model with highest eval accuracy.\n","!cat $EXPERIMENT_DIR/experiment_dir_retrain/dssd_training_log_resnet18.csv\n","%env EPOCH=080"]},{"cell_type":"markdown","metadata":{"id":"eY2VSBliioR8"},"source":["## 10. Evaluate retrained model <a class=\"anchor\" id=\"head-10\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":658379,"status":"ok","timestamp":1657222354615,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"TBgkiq58ioR9","outputId":"7c96795e-ccef-4cc1-bd84-0a24d91bba16"},"outputs":[],"source":["!tao model dssd evaluate --gpu_index=$GPU_INDEX \\\n","                   -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n","                   -m $EXPERIMENT_DIR/experiment_dir_retrain/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n","                   -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"_wNtOD_pioR9"},"source":["## 11. Visualize inferences <a class=\"anchor\" id=\"head-11\"></a>\n","In this section, we run the `infer` tool to generate inferences on the trained models and visualize the results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1657222753490,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"FMuaDFMxLBpN","outputId":"be0e7543-ed0c-4c71-ce8e-5e3d6800ad0d"},"outputs":[],"source":["!ls $DATA_DIR/val/images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3qZmr3nioR9"},"outputs":[],"source":["# Copy some test images\n","!mkdir -p $DATA_DIR/test_samples\n","!cp $DATA_DIR/val/images/* $DATA_DIR/test_samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":645776,"status":"ok","timestamp":1657223420358,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"OtHoENcJioR9","outputId":"1c7fb35c-ec78-4b72-9262-6548f9f55ad1"},"outputs":[],"source":["# Running inference for detection on n images\n","!tao model dssd inference --gpu_index=$GPU_INDEX -i $DATA_DIR/test_samples \\\n","                    -o $EXPERIMENT_DIR/dssd_infer_images \\\n","                    -e $SPECS_DIR/dssd_retrain_resnet18_kitti.txt \\\n","                    -m $EXPERIMENT_DIR/experiment_dir_retrain/weights/dssd_resnet18_epoch_$EPOCH.tlt \\\n","                   -l $EXPERIMENT_DIR/dssd_infer_labels \\\n","                   -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"hrsEbvkKioR9"},"source":["The `tao` inference tool produces two outputs. \n","1. Overlain images in `$EXPERIMENT_DIR/dssd_infer_images`\n","2. Frame by frame bbox labels in kitti format located in `$EXPERIMENT_DIR/dssd_infer_labels`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":8203,"status":"ok","timestamp":1657223428541,"user":{"displayName":"tao-team-google-admins nvidia","userId":"12428471056663112246"},"user_tz":420},"id":"6WJrVLzOioR9","outputId":"a1a7f1cf-c4a9-4ea8-eb34-71f8f25c262c"},"outputs":[],"source":["# Simple grid visualizer\n","import matplotlib.pyplot as plt\n","import os\n","from math import ceil\n","valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n","\n","def visualize_images(image_dir, num_cols=4, num_images=10):\n","    output_path = os.path.join(os.environ['EXPERIMENT_DIR'], image_dir)\n","    num_rows = int(ceil(float(num_images) / float(num_cols)))\n","    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n","    f.tight_layout()\n","    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n","         if os.path.splitext(image)[1].lower() in valid_image_ext]\n","    for idx, img_path in enumerate(a[:num_images]):\n","        col_id = idx % num_cols\n","        row_id = idx // num_cols\n","        img = plt.imread(img_path)\n","        axarr[row_id, col_id].imshow(img) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwA5_EI3ioR9"},"outputs":[],"source":["# Visualizing the sample images.\n","OUTPUT_PATH = 'dssd_infer_images' # relative path from $EXPERIMENT_DIR.\n","COLS = 3 # number of columns in the visualizer grid.\n","IMAGES = 9 # number of images to visualize.\n","\n","visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["4KxgRpNgioRr"],"name":"dssd.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
