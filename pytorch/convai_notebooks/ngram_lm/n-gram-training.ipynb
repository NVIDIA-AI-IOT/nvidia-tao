{"cells":[{"cell_type":"markdown","metadata":{"id":"FZE3alXMetm4"},"source":["# N-gram Language Modelling using Transfer Learning Toolkit"]},{"cell_type":"markdown","metadata":{"id":"LnN_pvXLetm6"},"source":["*Transfer learning* is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task.\n","\n","**Train Adapt Optimize (TAO) Toolkit** is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data. Developers, researchers and software partners building Conversational AI and Vision AI can leverage TAO Toolkit to avoid the hassle of training from scratch, and significantly accelerate their workflow.\n","\n","<center><img src=\"https://developer.nvidia.com/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png\"><\\center>"]},{"cell_type":"markdown","metadata":{"id":"XR9dljZbetm6"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO Toolkit to:\n","- Pre-process/convert a dataset for the [**Language Modelling**](#isc-task-description) task.\n","- [**Train/Finetune**](#isc-training) a [N-gram language model](https://web.stanford.edu/~jurafsky/slp3/3.pdf) on the [Librispeech LM Normalized](https://www.openslr.org/11/) dataset\n","- Run [**Inference**](#isc-inference) and [**Evaluate**](#evaluation) our trained model on the [Librispeech dev-clean](https://www.openslr.org/12/) dataset\n","- [**Export**](#isc-export-riva) in a format suitable for deployment in [Riva](https://developer.nvidia.com/riva).\n","\n","The earlier sections in the notebook give a brief introduction to the N-gram Language Modelling task, the datasets used for training and evaluating our N-gram language model. If you are already familiar with these, and want to jump right in, you can start at section on [Data Preparation](#isc-prepare-data).\n","\n","#### Note\n","1. This notebook uses Librispeech LM dataset by default, which should be around ~4.6 GB.\n","1. Using the default config/spec file provided in this notebook, each weight file size of n_gram created during training will be ~7 MB"]},{"cell_type":"markdown","metadata":{"id":"f7yRMFrnfMEr"},"source":["## Connect to a GPU Runtime\n","\n","1.   Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","2.   Then click on Connect (Top Right)\n"]},{"cell_type":"markdown","metadata":{"id":"J3zPYQdNe-cc"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyqAV947e_Hp"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"IctCqDzBfDJw"},"source":["## Setup Python Environment\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"markdown","metadata":{},"source":["#### FIXME\n","1. COLAB_NOTEBOOKS_PATH - for Google Colab environment, set this path where you want to clone the repo to; for local system environment, set this path to the already cloned repo\n","1. DATA_DIR - set this path to a folder location where you want to dataset to be present\n","1. SPECS_DIR - set this path to a folder location where the configuration/spec files will be saved\n","1. RESULTS_DIR - set this path to a folder location where pretrained models, checkpoints and log files during different model actions will be saved"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsF_BUsxt0Lx","scrolled":true,"tags":[]},"outputs":[],"source":["import os\n","#FIXME1\n","%env COLAB_NOTEBOOKS_PATH=/content/drive/MyDrive\n","if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","    if not os.path.exists(os.path.join(os.environ[\"COLAB_NOTEBOOKS_PATH\"],\"nvidia-tao\")):\n","        !git clone https://github.com/NVIDIA-AI-IOT/nvidia-tao.git $COLAB_NOTEBOOKS_PATH\n","else:\n","    if not os.path.exists(os.environ[\"COLAB_NOTEBOOKS_PATH\"]):\n","        raise Exception(\"Error, enter the path of the colab notebooks repo correctly\")\n","\n","!sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/pytorch/$bash_script\n","!sh $COLAB_NOTEBOOKS_PATH/pytorch/$bash_script\n"]},{"cell_type":"markdown","metadata":{"id":"yXf0pf-Retm8"},"source":["---\n","<a id='isc-task-description'></a>\n","## Language Modelling\n","\n","### Task Description\n","\n","Language modelling returns a probability distribution over a sequence of words. Besides assigning a probability to a sequence of words, the language models also assign a probability for the likelihood of a given word (or a sequence of words) that follows a sequence of words. <br>\n","\n","> The sentence:  **all of a sudden I notice three guys standing on the sidewalk**\n","> would be scored higher than \n","> the sentence: **on guys all I of notice sidewalk three a sudden standing the** by the language model. <br>\n","\n","A language model trained on large corpus can significantly improve the accuracy of an Automatic Speech Recognition system as suggested in many recent research."]},{"cell_type":"markdown","metadata":{"id":"p3t5ev8Retm8"},"source":["### N-gram Language Model\n","There are primarily two types of Language Models\n","\n","- **N-gram Language Models**: These models use frequency of n-grams to learn the probability distribution over words. Two benefits of N-gram Language Model are simplicity and scalability – with larger n, a model can store more context with a well-understood space–time tradeoff, enabling small experiments to scale up efficiently.\n","- **Neural Language Models**: They use different kinds of Neural Networks to model the probability distribution over words, and have surpassed the N-gram language models in the ability to model language, but are generally slower to evaluate.\n","\n","In this notebook, we will show how to train, evaluate and optionally finetune a [N-gram language model](https://web.stanford.edu/~jurafsky/slp3/3.pdf) leveraging TAO Toolkit."]},{"cell_type":"markdown","metadata":{"id":"8MQLuoTuetnA"},"source":["---\n","### Set Relevant Paths\n","Please set these paths according to your environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzOg84xietm_"},"outputs":[],"source":["%env TAO_DOCKER_DISABLE=1\n","\n","# The data is saved here\n","#FIXME2\n","DATA_DIR='/data/lm'\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR\n","\n","# The configuration files are stored here\n","#FIXME3\n","SPECS_DIR='/specs/lm'\n","!sudo mkdir -p $SPECS_DIR && sudo chmod -R 777 $SPECS_DIR\n","\n","# The results are saved at this path\n","#FIXME4\n","RESULTS_DIR='/results/lm'\n","!sudo mkdir -p $RESULTS_DIR && sudo chmod -R 777 $RESULTS_DIR\n","\n","# Set your encryption key, and use the same key for all commands\n","KEY='tlt_encode'"]},{"cell_type":"markdown","metadata":{"id":"gMKxx0rwetm9"},"source":["---\n","<a id='isc-prepare-data'></a>\n","### Preparing the dataset\n","#### Librispeech LM Normalized dataset\n","For this tutorial, we use the normalized version of `Librispeech LM` dataset to train our N-gram language model. The normalized version of `Librispeech LM` dataset is available [here](https://www.openslr.org/11/).\n","\n","#### Librispeech dev-clean dataset\n","For this tutorial, we also use the clean version of `Librispeech` development set to evaluate our N-gram language model. The clean version of `Librispeech` development set is available [here](https://www.openslr.org/12/)."]},{"cell_type":"markdown","metadata":{"id":"6t__HFEuetm9"},"source":["#### Downloading the dataset"]},{"cell_type":"markdown","metadata":{"id":"UBMt7SE4etm9"},"source":["#### Librispeech LM Normalized dataset\n","The training data is publicly available [here](https://www.openslr.org/resources/11/librispeech-lm-corpus.tgz) and can be downloaded directly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nm6JUBXJetm9"},"outputs":[],"source":["# NOTE: Ensure that wget and unzip utilities are available. If not, please install them\n","!wget 'https://www.openslr.org/resources/11/librispeech-lm-norm.txt.gz' -P $DATA_DIR\n","\n","# Extract the data\n","!gzip -dk $DATA_DIR/librispeech-lm-norm.txt.gz"]},{"cell_type":"markdown","metadata":{"id":"anLUGIWoetm-"},"source":["#### Librispeech dev-clean dataset\n","The evaluation data is publicly available [here](https://www.openslr.org/resources/12/dev-clean.tar.gz) and can be downloaded directly. We provided a Python script to download and preprocess the dataset for users"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"POKzXjYsetm-"},"outputs":[],"source":["\"\"\"\n","Scripts to download and preprocess LibriSpeech dev-clean\n","\"\"\"\n","from multiprocessing import Pool\n","import numpy\n","import os\n","\n","LOG_STR = \" To regenerate this file, please, remove it.\"\n","\n","def find_transcript_files(dir):\n","    files = []\n","    for dirpath, _, filenames in os.walk(dir):\n","        for filename in filenames:\n","            if filename.endswith(\".trans.txt\"):\n","                files.append(os.path.join(dirpath, filename))\n","    return files\n","\n","def transcript_to_list(file):\n","    audio_path = os.path.dirname(file)\n","    ret = []\n","    with open(file, \"r\") as f:\n","        for line in f:\n","            file_id, trans = line.strip().split(\" \", 1)\n","            audio_file = os.path.abspath(os.path.join(audio_path, file_id + \".flac\"))\n","            duration = 0  # We are not using the audio\n","            ret.append([file_id, audio_file, str(duration), trans.lower()])\n","\n","    return ret\n","\n","\n","if __name__ == \"__main__\":\n","    \n","    name = \"dev-clean\"\n","    data_path = os.path.join(DATA_DIR, \"eval_data\")\n","    text_path = os.path.join(DATA_DIR, \"text\")\n","    lists_path = os.path.join(DATA_DIR, \"lists\")\n","    os.makedirs(data_path, exist_ok=True)\n","    os.makedirs(text_path, exist_ok=True)\n","    os.makedirs(lists_path, exist_ok=True)\n","    data_http = \"http://www.openslr.org/resources/12/\"\n","\n","    # Download the audio data\n","    print(\"Downloading the evaluation data.\", flush=True)\n","    if not os.path.exists(os.path.join(data_path, \"LibriSpeech\", name)):\n","        print(\"Downloading and unpacking {}...\".format(name))\n","        cmd = \"\"\"wget -c {http}{name}.tar.gz -P {path};\n","                 yes n 2>/dev/null | gunzip {path}/{name}.tar.gz;\n","                 tar -C {path} -xf {path}/{name}.tar\"\"\"\n","        os.system(cmd.format(path=data_path, http=data_http, name=name))\n","    else:\n","        log_str = \"{} part of data exists, skip its downloading and unpacking\"\n","        print(log_str.format(name) + LOG_STR, flush=True)\n","\n","    # Prepare the audio data\n","    print(\"Converting data into necessary format.\", flush=True)\n","    word_dict = {}\n","    word_dict[name] = set()\n","    src = os.path.join(data_path, \"LibriSpeech\", name)\n","    assert os.path.exists(src), \"Unable to find the directory - '{src}'\".format(\n","        src=src\n","    )\n","\n","    dst_list = os.path.join(lists_path, name + \".lst\")\n","    if os.path.exists(dst_list):\n","        print(\n","            \"Path {} exists, skip its generation.\".format(dst_list) + LOG_STR,\n","            flush=True,\n","        )\n","        \n","\n","    print(\"Analyzing {src}...\".format(src=src), flush=True)\n","    transcript_files = find_transcript_files(src)\n","    transcript_files.sort()\n","\n","    print(\"Writing to {dst}...\".format(dst=dst_list), flush=True)\n","    with Pool(processes=8) as p:\n","        samples = list(p.imap(transcript_to_list, transcript_files))\n","\n","    with open(dst_list, \"w\") as fout:\n","        for sp in samples:\n","            for s in sp:\n","                word_dict[name].update(s[-1].split(\" \"))\n","                s[0] = name + \"-\" + s[0]\n","                fout.write(\" \".join(s) + \"\\n\")\n","\n","    current_path = os.path.join(text_path, name + \".txt\")\n","    if not os.path.exists(current_path):\n","        with open(os.path.join(lists_path, name + \".lst\"), \"r\") as flist, open(\n","            os.path.join(text_path, name + \".txt\"), \"w\"\n","        ) as fout:\n","            for line in flist:\n","                fout.write(\" \".join(line.strip().split(\" \")[3:]) + \"\\n\")\n","    else:\n","        print(\n","            \"Path {} exists, skip its generation.\".format(current_path) + LOG_STR,\n","            flush=True,\n","        )\n","\n","print(\"Done!\", flush=True)\n"]},{"cell_type":"markdown","metadata":{"id":"cSEoHKm7etm-"},"source":["For the sake of reducing the time this demo takes, we reduce the number of lines of the training dataset. Feel free to modify the number of used lines."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ka9SISJetm-"},"outputs":[],"source":["# Use a random 10,000 lines for training\n","!shuf -n 10000 $DATA_DIR/librispeech-lm-norm.txt  > $DATA_DIR/reduced_training.txt"]},{"cell_type":"markdown","metadata":{"id":"bhRDJlqCetm_"},"source":["---\n","## TAO Toolkit workflow\n","The rest of the notebook exemplifies the simplicity of the TAO Toolkit workflow. Users with basic knowledge of Deep Learning can get started building their own custom models using a simple specification file. It's essentially just one command each to run data preprocessing, training, fine-tuning, evaluation, inference, and export! All configurations happen through YAML spec files <br>"]},{"cell_type":"markdown","metadata":{"id":"xdmjEjwwetnA"},"source":["---\n","### Configuration/Specification Files"]},{"cell_type":"markdown","metadata":{"id":"AdiLXByuetnA"},"source":["The essence of all commands in TAO Toolkit lies in the YAML spec files. There are sample spec files already available for you to use directly or as reference to create your own.  Through these spec files, you can tune many knobs like the model, dataset, hyperparameters etc. Each command (like train, finetune, evaluate etc.) should have a dedicated spec file with configurations pertinent to it. <br>\n","\n","Here is an example of the training spec file:\n","\n","---\n","```\n","model:\n","  intermediate: True\n","  order: 2\n","  pruning:\n","    - 0\n","training_ds:\n","  is_tarred: false\n","  is_file: true\n","  data_file: ???\n","\n","vocab_file: \"\"\n","encryption_key: \"tlt_encode\"\n","...\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"H-SgLSAfetnA"},"source":["---\n","### Downloading Specs\n","We can proceed to downloading the spec files. The user may choose to modify/rewrite these specs, or even individually override them through the launcher. You can download the default spec files by using the `download_specs` command. <br>\n","\n","The -o argument indicating the folder where the default specification files will be downloaded, and -r that instructs the script where to save the logs. **Make sure the -o points to an empty folder!**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jY5rqS5letnB"},"outputs":[],"source":["!tao n_gram download_specs \\\n","    -r $RESULTS_DIR \\\n","    -o $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"s8kMmZAqetnB"},"source":["---\n","### Data Convert\n"]},{"cell_type":"markdown","metadata":{"id":"5uA51iGyetnC"},"source":["In preparation for training/fine-tuning, we need to preprocess the dataset. `tao n_gram dataset_convert` command can be used in conjunction with appropriate configuration in the spec file. Here is the sample `dataset_convert.yaml` spec file we use:\n","```\n","# Dataset. Available options: [assistant]\n","dataset_name: assistant\n","\n","# Extension of the files containing in dataset\n","extension: ???\n","\n","# Path to the folder containing the dataset source files.\n","source_data_dir: ???\n","\n","# Path to the output folder.\n","target_data_file: ???\n","\n","```\n"," We encourage you to take a look at the .yaml spec files we provide!\n","As we show below, you can override the `source_data_dir` and `target_data_dir` options with appropriate paths."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UM0tn-rcetnC"},"outputs":[],"source":["# Preprocess training data (Librispeech LM Normalized)\n","!tao n_gram dataset_convert \\\n","            -e $SPECS_DIR/dataset_convert.yaml \\\n","            -r $RESULTS_DIR/dataset_convert \\\n","            extension=*.txt \\\n","            source_data_dir=$DATA_DIR/reduced_training.txt \\\n","            target_data_file=$DATA_DIR/preprocessed.txt\n","\n","# Preprocess evaluation data (Librispeech dev-clean)\n","!tao n_gram dataset_convert \\\n","            -e $SPECS_DIR/dataset_convert.yaml \\\n","            -r $RESULTS_DIR/dataset_convert \\\n","            extension=*.txt \\\n","            source_data_dir=$DATA_DIR/text/dev-clean.txt \\\n","            target_data_file=$DATA_DIR/preprocessed_dev_clean.txt"]},{"cell_type":"markdown","metadata":{"id":"t9-U3V9HetnC"},"source":["The command preprocess training and evaluation dataset using basic text preprocessings include convert lowercase, normalization, remove punctuation, ... and write the results into files named `preprocessed.txt` and `preprocessed_dev_clean.txt` for training and evaluation correspondingly. In both `preprocessed.txt` and `preprocessed_dev_clean.txt`, each preprocessed sentence corresponds to a new line."]},{"cell_type":"markdown","metadata":{"id":"g25871xZetnD"},"source":["---\n","<a id='isc-training'></a>\n","### Training / Fine-tuning\n"]},{"cell_type":"markdown","metadata":{"id":"jztoGzG4etnD"},"source":["Training a model using TAO Toolkit is as simple as configuring your spec file and running the train command. The code cell below uses the train.yaml spec file available for users as reference. The spec file configurations can easily be overridden using the tao-launcher CLI as shown below. For instance, below we override `model.order`, `model.pruning` and `training_ds.data_file` configurations to suit our needs. <br>\n","\n","For training a N-gram language model in TAO Toolkit, we use the `tao n_gram train` command with the following args:\n","- `-e`: Path to the spec file\n","- `-k`: User specified encryption key to use while saving/loading the model\n","- `-r`: Path to a folder where the outputs should be written. Make sure this is mapped in tlt_mounts.json\n","- Any overrides to the spec file eg. `model.order`\n","<br>\n","\n","\n","More details about these arguments are present in the [TAO Toolkit Getting Started Guide](https://docs.nvidia.com/tao/tao-toolkit/text/overview.html) <br>\n","`Note:` All file paths correspond to the destination mounted directory that is visible in the TAO Toolkit docker container used in backend.<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRC27xOhetnD"},"outputs":[],"source":["!tao n_gram train \\\n","            -e $SPECS_DIR/train.yaml \\\n","            -r $RESULTS_DIR/train \\\n","            training_ds.data_file=$DATA_DIR/preprocessed.txt \\\n","            model.order=3 \\\n","            model.pruning=[0,0,1]"]},{"cell_type":"markdown","metadata":{"id":"uUYSnW2oetnD"},"source":["The train command produces 3 files called `train_n_gram.arpa`, `train_n_gram.vocab` and `train_n_gram.kenlm_intermediate` saved at `$RESULTS_DIR/train/checkpoints`."]},{"cell_type":"markdown","metadata":{"id":"VBpc0lEfetnD"},"source":["---\n","<a id='evaluation'></a>\n","### Evaluation\n","The evaluation spec .yaml is as simple as:\n","\n","```\n","# Name of the .arpa or .binary file where trained model will be restored from.\n","restore_from: ???\n","\n","test_ds:\n","  data_file: ???\n","  \n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fvpY8mPetnD"},"outputs":[],"source":["!tao n_gram evaluate \\\n","     -e $SPECS_DIR/evaluate.yaml \\\n","     -r $RESULTS_DIR/evaluate \\\n","     restore_from=$RESULTS_DIR/train/checkpoints/train_n_gram.arpa \\\n","     test_ds.data_file=$DATA_DIR/preprocessed_dev_clean.txt"]},{"cell_type":"markdown","metadata":{"id":"k3WanmyuetnE"},"source":["The output of Evaluation give us the perplexity of the N-gram language model on the evaluation (Librispeech dev-clean) dataset!"]},{"cell_type":"markdown","metadata":{"id":"IGqEpkx6etnE"},"source":["---\n","<a id='isc-inference'></a>\n","### Inference\n","Inference using a trained `.arpa` or `.binary` model uses the `tao n_gram infer` command.  <br>\n","The infer.yaml is also very simple, and we can directly give inputs for the model to run inference.\n","```\n","# \"Simulate\" user input:\n","input_batch:\n","  - 'set alarm for seven thirty am'\n","  - 'lower volume by fifty percent'\n","  - 'what is my schedule for tomorrow'\n","\n","restore_from: ???\n","\n","```\n","\n","We encourage you to try out your own inputs as an exercise!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0rK0uTqetnE"},"outputs":[],"source":["!tao n_gram infer \\\n","            -e $SPECS_DIR/infer.yaml \\\n","            -r $RESULTS_DIR/infer \\\n","            restore_from=$RESULTS_DIR/train/checkpoints/train_n_gram.arpa"]},{"cell_type":"markdown","metadata":{"id":"7o13OEgHetnF"},"source":["This command returns the log likelihood, perplexity and all n-grams for each of the input sequences that users provided."]},{"cell_type":"markdown","metadata":{"id":"bUFxoteWetnF"},"source":["---\n","### What's Next?"]},{"cell_type":"markdown","metadata":{"id":"fWdaHUBRetnF"},"source":["You could use TAO Toolkit to build custom models for your own applications, or you could deploy the custom model to Nvidia Riva!"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"n-gram-training.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
