{"cells":[{"cell_type":"markdown","metadata":{"id":"lPWFP7g1Pql5"},"source":["## Joint Intent Detection and Slot Filling using Train Adapt Optimize (TAO) Toolkit"]},{"cell_type":"markdown","metadata":{"id":"9zY3pvGMPql7"},"source":["*Transfer learning* is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task.\n","\n","**Train Adapt Optimize (TAO) Toolkit ** is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data. Developers, researchers and software partners building Conversational AI and Vision AI can leverage TAO to avoid the hassle of training from scratch, and significantly accelerate their workflow. \n","\n","<center><img src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\"><\\center>"]},{"cell_type":"markdown","metadata":{"id":"4_pIwzViPql8"},"source":["## Learning Objectives\n","In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n","- Pre-process/convert a dataset for the [**Joint Intent and Slot Classification**](#isc-task-description).\n","- Take a [BERT](https://arxiv.org/pdf/1810.04805.pdf) model and [**Train/Finetune**](#isc-training) it on the [NLU Evaluation](https://github.com/xliuhw/NLU-Evaluation-Data) dataset\n","- Run [**Inference**](#isc-inference)\n","\n","The earlier sections in the notebook give a brief introduction to the Intent and Slot Classification task, the NLU Evaluation dataset and BERT. If you are already familiar with these, and want to jump right in, you can start at section on [Data Preparation](#isc-prepare-data)."]},{"cell_type":"markdown","metadata":{"id":"QVZjzYB7Pql-"},"source":["---\n","<a id='isc-task-description'></a>\n","### Joint Intent Detection and Slot Filling - Task Description\n","\n","Understanding the intent in natural language (Intent Classification) and extracting values of pertinent attributes or specific pieces of information from a sentence (Slot Filling) are two essential tasks in Natural Language Understanding (NLU). For example: <br>\n","\n","> In the query:  *What is the weather in Santa Clara tomorrow morning?*\n","> we would like to classify the query as a `weather` Intent,\n","> and detect `Santa Clara` as a location slot and tomorrow morning as a `date_time` slot. Intents and Slots names are usually task specific and defined as labels in the training data. This is a fundamental step that is executed in any task-driven Conversational Assistant. <br>\n","\n","Recent research has shown the proficiency of BERT models in this task. TAO provides the capability to train a BERT model and perform inference for both intent detection and slot filling together."]},{"cell_type":"markdown","metadata":{"id":"GQp6C3DgPql-"},"source":["### BERT Model\n","In this notebook, we will show how to use a pre-trained [BERT](https://arxiv.org/pdf/1810.04805.pdf) (Bidirectional Encoder Representations from Transformers) model for Joint Intent and Slot Classification leveraging TAO. The BERT model has made major breakthroughs in Natural Language Understanding in recent years. For most applications, the model is typically trained in two phases, pre-training and fine-tuning. \n","- The BERT core model can be pre-trained on large, generic datasets to generate dense vector representations of input sentence(s). \n","- It can be quickly fine-tuned to perform a wide variety of tasks such as question/answering, sentiment analysis, or named entity recognition.\n","\n","The figure below shows a high-level block diagram of pre-training and fine-tuning BERT.\n","<center><img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/05/bert-model-625x268.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"RTrLdQ0EPql_"},"source":["In alignment with the above, for pre-training we can take one of two approaches. We can either pre-train the BERT model with our own data, or use a model pre-trained by Nvidia. After we obtain a pre-trained model, the next step would be to fine-tune it for the Intent and Slot Classification task and run inference on the fine-tuned model."]},{"cell_type":"markdown","metadata":{"id":"h9Vk0VwdPql_"},"source":["<center><img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2020/06/Fig4revised-625x340.png\"></center>"]},{"cell_type":"markdown","metadata":{"id":"jBdjK77dKOQn"},"source":["## Connect to a GPU Runtime\n","\n","1.   Change Runtime type to GPU by Runtime(Top Left tab)->Change Runtime Type->GPU(Hardware Accelerator)\n","2.   Then click on Connect (Top Right)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"38R-3LAixO-h"},"source":["## Mounting Google drive\n","Mount your Google drive storage to this Colab instance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dt69GSQgo5f3"},"outputs":[],"source":["try:\n","    import google.colab\n","    %env GOOGLE_COLAB=1\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","except:\n","    %env GOOGLE_COLAB=0\n","    print(\"Warning: Not a Colab Environment\")"]},{"cell_type":"markdown","metadata":{"id":"iMrKJGSaxnmE"},"source":["## Setup Python Environment\n","Setup the environment necessary to run the TAO Networks by running the bash script"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GsF_BUsxt0Lx"},"outputs":[],"source":["#FIXME\n","%env GENERAL_WHL_PATH=/content/drive/MyDrive/tf/general_whl\n","#FIXME\n","%env CODEBASE_WHL_PATH=/content/drive/MyDrive/tf/codebase_whl\n","\n","if os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]) and os.path.exists(os.environ[\"GENERAL_WHL_PATH\"]):\n","    if os.environ[\"GOOGLE_COLAB\"] == \"1\":\n","        os.environ[\"bash_script\"] = \"setup_env.sh\"\n","    else:\n","        os.environ[\"bash_script\"] = \"setup_env_desktop.sh\"\n","\n","    !sed -i \"s|PATH_TO_GENERAL_WHL|$GENERAL_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/pytorch/$bash_script\n","    !sed -i \"s|PATH_TO_CODEBASE_WHL|$CODEBASE_WHL_PATH|g\" $COLAB_NOTEBOOKS_PATH/pytorch/$bash_script\n","    !sed -i \"s|PATH_TO_COLAB_NOTEBOOKS|$COLAB_NOTEBOOKS_PATH|g\" $COLAB_NOTEBOOKS_PATH/pytorch/$bash_script\n","\n","    !sh $COLAB_NOTEBOOKS_PATH/pytorch/$bash_script\n","else:\n","    raise(\"Error, enter the whl paths correctly\")"]},{"cell_type":"markdown","metadata":{"id":"_im1yBqtPql_"},"source":["---\n","<a id='isc-prepare-data'></a>\n","### Preparing the dataset\n","#### The NLU Evaluation Dataset\n","For this tutorial, we use a virtual assistant interaction in home domain - `NLU Evaluation` dataset. The NLU dataset is available [here](https://github.com/xliuhw/NLU-Evaluation-Data). It was collected and annotated for various NLU tasks by Liu et. al in their IWSDS 2019 [paper](https://arxiv.org/abs/1903.05566), and more information about this dataset is present in the Github README."]},{"cell_type":"markdown","metadata":{"id":"07iLiH25Pql_"},"source":["#### Downloading the dataset"]},{"cell_type":"markdown","metadata":{"id":"ArNGypVrPql_"},"source":["The data is available in the github [repo](https://github.com/xliuhw/NLU-Evaluation-Data) and can be downloaded directly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UhrwbTRNPqmA"},"outputs":[],"source":["# IMPORTANT NOTE: Set path to a folder where you want you data and results to be saved\n","DATA_DIR = \"/content/data\"\n","!sudo mkdir -p $DATA_DIR && sudo chmod -R 777 $DATA_DIR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szvSnkBAPqmA"},"outputs":[],"source":["# NOTE: Ensure that wget and unzip utilities are available. If not, please install them\n","!wget 'https://github.com/xliuhw/NLU-Evaluation-Data/archive/master.zip' -P $DATA_DIR\n","\n","# Extract the data\n","!unzip $DATA_DIR/master.zip -d $DATA_DIR"]},{"cell_type":"markdown","metadata":{"id":"kI0Glj93PqmA"},"source":["---\n","## TAO workflow\n","The rest of the notebook shows what a sample TAO workflow looks like."]},{"cell_type":"markdown","metadata":{"id":"H6CLDF0tPqmB"},"source":["---\n","### Configuration/Specification Files"]},{"cell_type":"markdown","metadata":{"id":"we6I7d8IPqmB"},"source":["The essence of all commands in TAO lies in the YAML spec files. There are sample spec files already available for you to use directly or as reference to create your own.  Through these spec files, you can tune many knobs like the model, dataset, hyperparameters, optimizer etc. Each command (like train, finetune, evaluate etc.) should have a dedicated spec file with configurations pertinent to it. <br>\n","\n","Here is an example of the training spec file:\n","\n","---\n","```\n","# Name of the file where trained model will be saved.\n","save_to: trained-model.tlt\n","\n","optim:\n","  name: adam\n","  lr: 2e-5\n","  # optimizer arguments\n","  betas: [0.9, 0.999]\n","  weight_decay: 0.01\n","\n","  # scheduler setup\n","  sched:\n","    name: WarmupAnnealing\n","    # Scheduler params\n","    warmup_steps: null\n","    warmup_ratio: 0.1\n","    last_epoch: -1\n","    # pytorch lightning args\n","    monitor: val_loss\n","    reduce_on_plateau: false\n","\n","model:\n","  class_balancing: null # choose from [null, weighted_loss]. weighted_loss enables the weighted class balancing of the loss, may be used for handling unbalanced classes\n","  intent_loss_weight: 0.6 # relation of intent to slot loss in total loss (between 0 to 1)\n","  pad_label: -1 # if -1 not slot token will be used\n","  ignore_extra_tokens: false\n","  ignore_start_end: true # do not use first and last token for slot training\n","\n","  tokenizer:\n","      tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece\n","      vocab_file: null # path to vocab file \n","      tokenizer_model: null # only used if tokenizer is sentencepiece\n","      special_tokens: null\n","\n","  language_model:\n","    max_seq_length: 50\n","    pretrained_model_name: bert-base-uncased\n","    lm_checkpoint: null\n","    config_file: null # json file, precedence over config\n","    config: null\n","\n","  head:\n","    num_output_layers: 2\n","    fc_dropout: 0.1\n","...\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"fdfTGE_-PqmB"},"source":["---\n","### Set Relevant Paths\n","Please set these paths according to your environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pRMreAKuPqmC"},"outputs":[],"source":["%env TAO_DOCKER_DISABLE=1\n","\n","# The configuration files are stored here\n","SPECS_DIR='/content/specs/intent_slot_classification'\n","!sudo mkdir -p $SPECS_DIR && sudo chmod -R 777 $SPECS_DIR\n","\n","# The results are saved at this path\n","RESULTS_DIR='/content/results/intent_slot_classification'\n","!sudo mkdir -p $RESULTS_DIR && sudo chmod -R 777 $RESULTS_DIR\n","\n","# Set your encryption key, and use the same key for all commands\n","KEY='tlt_encode'"]},{"cell_type":"markdown","metadata":{"id":"w1fWxikKPqmC"},"source":["---\n","### Downloading Specs\n","We can proceed to downloading the spec files. The user may choose to modify/rewrite these specs, or even individually override them through the launcher. You can download the default spec files by using the `download_specs` command. <br>\n","\n","The -o argument indicating the folder where the default specification files will be downloaded, and -r that instructs the script where to save the logs. **Make sure the -o points to an empty folder!**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4ljTW8DPqmC"},"outputs":[],"source":["!tao intent_slot_classification download_specs \\\n","    -r $RESULTS_DIR \\\n","    -o $SPECS_DIR"]},{"cell_type":"markdown","metadata":{"id":"3WhOA6mFPqmC"},"source":["---\n","### Data Convert\n"]},{"cell_type":"markdown","metadata":{"id":"40LCwGzxPqmC"},"source":["In preparation for training/fine-tuning, we need to preprocess the dataset. `tao intent_slot_classification dataset_convert` command can be used in conjunction with appropriate configuration in the spec file. Here is the sample `dataset_convert.yaml` spec file we use:\n","```\n","# Dataset. Available options: [assistant]\n","dataset_name: assistant\n","\n","# Path to the folder containing the dataset source files.\n","source_data_dir: ???\n","\n","# Path to the output folder.\n","target_data_dir: ???\n","\n","```\n"," We encourage you to take a look at the .yaml spec files we provide!\n","As we show below, you can override the `source_data_dir` and `target_data_dir` options with appropriate paths."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVG2sZH4PqmD"},"outputs":[],"source":["!tao intent_slot_classification dataset_convert \\\n","                                -e $SPECS_DIR/dataset_convert.yaml \\\n","                                -r $RESULTS_DIR/dataset_convert \\\n","                                source_data_dir=$DATA_DIR/NLU-Evaluation-Data-master \\\n","                                target_data_dir=$DATA_DIR/NLU-Evaluation-Data-processed"]},{"cell_type":"markdown","metadata":{"id":"zDM2YyLjPqmE"},"source":["The command writes the processed assistant commands along with train/val splits dataset at the specific `target_data_dir`. With this dataset, it found 64 intents and 55 slot types."]},{"cell_type":"markdown","metadata":{"id":"Vx5rwNYHPqmE"},"source":["---\n","<a id='isc-training'></a>\n","### Training / Fine-tuning\n"]},{"cell_type":"markdown","metadata":{"id":"Z0NAisDEPqmE"},"source":["Training a model using TAO is as simple as configuring your spec file and running the train command. The code cell below uses the train.yaml spec file available for users as reference. It is configured by default to use the pretrained `bert-base-uncased` model. For this task, you will almost always use the pretrained BERT language models, and train for this task with your custom data. In this sense, this step could also be thought of as fine-tuning. Typically, to get good results you may need to train the model for 20-50 epochs depending on the size of the data.  Training with your own data will take about 15-30 mins on a single GPU. Since this is a demonstration, we train for just 1 epoch below.\n","\n","The spec file configurations can easily be overridden using the tao-launcher CLI as shown below. For instance, below we override the `data_dir`, `trainer.max_epochs`, `training_ds.num_workers` and `validation_ds.num_workers` configurations to suit our needs. <br>\n","\n","For training a Joint Intent Detection and Slot Classification model in TAO, we use the `tao intent_slot_classification train` command with the following args:\n","- `-e`: Path to the spec file\n","- `-g`: Number of GPUs to use\n","- `-k`: User specified encryption key to use while saving/loading the model\n","- `-r`: Path to a folder where the outputs should be written. Make sure this is mapped in tlt_mounts.json\n","- Any overrides to the spec file eg. `trainer.max_epochs`\n","<br>\n","\n","\n","More details about these arguments are present in the [TAO Getting Started Guide](https://docs.nvidia.com/tao/tao-toolkit/index.html) <br>\n","`Note:` All file paths correspond to the destination mounted directory that is visible in the TAO docker container used in backend.<br>\n","\n","`Note:` If you wish to proceed with a trained dataset for better inference results, you can find a .nemo model [here](\n","https://ngc.nvidia.com/catalog/collections/nvidia:nemotrainingframework).\n","\n","Simply re-name the .nemo file to .tlt and pass it through the finetune pipeline.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"puW7V_JCPqmF"},"outputs":[],"source":["!tao intent_slot_classification train \\\n","                                -e $SPECS_DIR/train.yaml \\\n","                                -g 1 \\\n","                                -k $KEY \\\n","                                -r $RESULTS_DIR/train \\\n","                                data_dir=$DATA_DIR/NLU-Evaluation-Data-processed \\\n","                                trainer.max_epochs=1 \\\n","                                training_ds.num_workers=4 \\\n","                                validation_ds.num_workers=4"]},{"cell_type":"markdown","metadata":{"id":"_C3Nf8H4PqmF"},"source":["The train command produces a .tlt file called `trained-model.tlt` saved at `$RESULTS_DIR/train/checkpoints/trained-model.tlt`."]},{"cell_type":"markdown","metadata":{"id":"yTUIXYZJPqmF"},"source":["---\n","<a id='evaluation'></a>\n","### Evaluation\n","The evaluation spec .yaml is as simple as:\n","\n","```\n","# Name of the .tlt file where trained model will be restored from.\n","restore_from: trained-model.tlt\n","\n","data_dir: ???\n","\n","test_ds:\n","  prefix: test\n","  batch_size: 32\n","  shuffle: false\n","  num_samples: -1\n","  num_workers: 2\n","  drop_last: false\n","  pin_memory: false\n","\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihVIQM0cPqmF"},"outputs":[],"source":["!tao intent_slot_classification evaluate \\\n","                                -e $SPECS_DIR/evaluate.yaml \\\n","                                -g 1 \\\n","                                -m $RESULTS_DIR/train/checkpoints/trained-model.tlt \\\n","                                -k $KEY \\\n","                                -r $RESULTS_DIR/evaluate \\\n","                                data_dir=$DATA_DIR/NLU-Evaluation-Data-processed"]},{"cell_type":"markdown","metadata":{"id":"Xc7mKDFZPqmG"},"source":["The output of Evaluation should give the precision, recall, and f1 report for intents and slots. Remember that we had trained for just 1 epoch since this is a demonstration!"]},{"cell_type":"markdown","metadata":{"id":"Wi1c9e_uPqmG"},"source":["---\n","<a id='isc-inference'></a>\n","### Inference\n","Inference using a .tao trained or fine-tuned model uses the `tao intent_slot_classification infer` command.  <br>\n","The infer.yaml is also very simple, and we can directly give inputs for the model to run inference.\n","```\n","# \"Simulate\" user input:\n","input_batch:\n","  - 'set alarm for seven thirty am'\n","  - 'lower volume by fifty percent'\n","  - 'what is my schedule for tomorrow'\n","\n","```\n","\n","We encourage you to try out your own inputs as an exercise!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8J2bIGsPqmH"},"outputs":[],"source":["!tao intent_slot_classification infer \\\n","                                -e $SPECS_DIR/infer.yaml \\\n","                                -g 1 \\\n","                                -m $RESULTS_DIR/train/checkpoints/trained-model.tlt \\\n","                                -r $RESULTS_DIR/infer \\\n","                                -k $KEY"]},{"cell_type":"markdown","metadata":{"id":"83PetacLPqmH"},"source":["This command returns the predicted intents and slots for each of the input sequences. Of course, these intents and slots are what it was trained on. You may see a full list of intents and slots in the processed data directory."]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["lPWFP7g1Pql5","4_pIwzViPql8","GQp6C3DgPql-"],"name":"intent-slot-classification-training.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
